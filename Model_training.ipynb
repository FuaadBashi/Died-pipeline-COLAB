{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1uC1cj4J87B9PK6mu0km8kL9CmORm0Hpk",
      "authorship_tag": "ABX9TyO7X7ktvQVPUQUTRNBwyhNa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "756c20460b7e40d1b98d745790b11d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2025cc5f00e94a538e27650c9e97bf24",
              "IPY_MODEL_b4d61828098d4b9896df2382d025ef12",
              "IPY_MODEL_1947788d4a5c4c5a896191af2e2663ca"
            ],
            "layout": "IPY_MODEL_631a20e46f834288b1ed4860d70fd32d"
          }
        },
        "2025cc5f00e94a538e27650c9e97bf24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70137857e7944aba9cc86d55f99d1b58",
            "placeholder": "​",
            "style": "IPY_MODEL_5742c76066f04b2eaf086768296a366b",
            "value": "config.json: 100%"
          }
        },
        "b4d61828098d4b9896df2382d025ef12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f63f13bfd4c42829dc5fe8503de7148",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_265377e687ea439e86b871db6dfe5876",
            "value": 385
          }
        },
        "1947788d4a5c4c5a896191af2e2663ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44ac7093534f412cbbb3fb7bedfac1e2",
            "placeholder": "​",
            "style": "IPY_MODEL_79796e4b8557457eb8bfe69a1674d69b",
            "value": " 385/385 [00:00&lt;00:00, 18.8kB/s]"
          }
        },
        "631a20e46f834288b1ed4860d70fd32d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70137857e7944aba9cc86d55f99d1b58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5742c76066f04b2eaf086768296a366b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f63f13bfd4c42829dc5fe8503de7148": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "265377e687ea439e86b871db6dfe5876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44ac7093534f412cbbb3fb7bedfac1e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79796e4b8557457eb8bfe69a1674d69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "176ca1349ff94979b12b933a0ec0dc14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71c7fe0c772140dba19bca15cee41644",
              "IPY_MODEL_dc7039a0c90444909a25cec2e440f1b4",
              "IPY_MODEL_847f26ad7c90497ca232498fc935a3dc"
            ],
            "layout": "IPY_MODEL_373ff990cbeb4a7b849dc2dc0d9867ee"
          }
        },
        "71c7fe0c772140dba19bca15cee41644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11871c97b780477dbe903af16ff03063",
            "placeholder": "​",
            "style": "IPY_MODEL_bc053dda28924386acf6ccbd1883d72b",
            "value": "vocab.txt: "
          }
        },
        "dc7039a0c90444909a25cec2e440f1b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_139bc287ca654bf99384af62f72c4455",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc7bdecfc07c4879af8c4193ee523c85",
            "value": 1
          }
        },
        "847f26ad7c90497ca232498fc935a3dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f0505f5bee34f3387b5d62577e049a1",
            "placeholder": "​",
            "style": "IPY_MODEL_668eae2c2572404ca784c9af4c4cdded",
            "value": " 213k/? [00:00&lt;00:00, 7.68MB/s]"
          }
        },
        "373ff990cbeb4a7b849dc2dc0d9867ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11871c97b780477dbe903af16ff03063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc053dda28924386acf6ccbd1883d72b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "139bc287ca654bf99384af62f72c4455": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "bc7bdecfc07c4879af8c4193ee523c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f0505f5bee34f3387b5d62577e049a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "668eae2c2572404ca784c9af4c4cdded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cecebb426e1d40ccad39069efe6a1f00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85c0b1e01ca94de0ac2dd4f4f5e65abd",
              "IPY_MODEL_f3dc2527aca24e548ecfdb0943489170",
              "IPY_MODEL_3daa5b7e0e9048369c37b145ac30b980"
            ],
            "layout": "IPY_MODEL_627f6d1032f84081ade71fe894c72e85"
          }
        },
        "85c0b1e01ca94de0ac2dd4f4f5e65abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d9d0984ef8b41faaa31bc2036288115",
            "placeholder": "​",
            "style": "IPY_MODEL_2e1c8145a44045c99617c590b9d92fe7",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "f3dc2527aca24e548ecfdb0943489170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed89f92dcce64ab296f509177a4d8e6f",
            "max": 435778770,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef7eafb321b04719b292f684d4bcdcf1",
            "value": 435778770
          }
        },
        "3daa5b7e0e9048369c37b145ac30b980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6d711eb9c9647c3b35a9db0d1a07fa7",
            "placeholder": "​",
            "style": "IPY_MODEL_555859519f04456091f56a14570f2490",
            "value": " 436M/436M [00:01&lt;00:00, 289MB/s]"
          }
        },
        "627f6d1032f84081ade71fe894c72e85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d9d0984ef8b41faaa31bc2036288115": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e1c8145a44045c99617c590b9d92fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed89f92dcce64ab296f509177a4d8e6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef7eafb321b04719b292f684d4bcdcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6d711eb9c9647c3b35a9db0d1a07fa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "555859519f04456091f56a14570f2490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e509448c025544228463266d0a5ba85a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c424177280204ff29e87660302050165",
              "IPY_MODEL_941f206b8d894d148c70e12f65b6d29e",
              "IPY_MODEL_1f86def15a7848e8bc8463acd44cf685"
            ],
            "layout": "IPY_MODEL_892f62f01f8c46a6ab5df1b448a2997b"
          }
        },
        "c424177280204ff29e87660302050165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cec3dca14d4414b8a196a7be6a2613b",
            "placeholder": "​",
            "style": "IPY_MODEL_41f492d122cc4c488849b520874843f0",
            "value": "model.safetensors: 100%"
          }
        },
        "941f206b8d894d148c70e12f65b6d29e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_106648618223433183d434f635fd52a9",
            "max": 435755888,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86210416c17841b381cc6621ac23ecda",
            "value": 435755888
          }
        },
        "1f86def15a7848e8bc8463acd44cf685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82656fb0f68644c1a2543972a56e06b0",
            "placeholder": "​",
            "style": "IPY_MODEL_fbdb0e7da91642da81ba9038763b797f",
            "value": " 436M/436M [00:01&lt;00:00, 285MB/s]"
          }
        },
        "892f62f01f8c46a6ab5df1b448a2997b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cec3dca14d4414b8a196a7be6a2613b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41f492d122cc4c488849b520874843f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "106648618223433183d434f635fd52a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86210416c17841b381cc6621ac23ecda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82656fb0f68644c1a2543972a56e06b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbdb0e7da91642da81ba9038763b797f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7060f25e1b534a988ffd3feb2b96308f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdf2ce0957224045971cf62ffd76d8b4",
              "IPY_MODEL_55a6833c42cd49abb249f26d7683f7ec",
              "IPY_MODEL_f1236f6c75f8496d81bbd8ea1c4b7131"
            ],
            "layout": "IPY_MODEL_2bb79c52a9e24e019f6d61794486423d"
          }
        },
        "cdf2ce0957224045971cf62ffd76d8b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08b1b3acebdd4667bf5f66f822e8da24",
            "placeholder": "​",
            "style": "IPY_MODEL_79f2001fae29429b939e7cff03bf3777",
            "value": "config.json: 100%"
          }
        },
        "55a6833c42cd49abb249f26d7683f7ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3af82634ab1042a48ef1d677bdf120b2",
            "max": 313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a8a36a9009745e482e6311d09aa4085",
            "value": 313
          }
        },
        "f1236f6c75f8496d81bbd8ea1c4b7131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94cd8012674d4f538166b0cb7f4b29a7",
            "placeholder": "​",
            "style": "IPY_MODEL_5d1f3a30c63e4ac7b0f1f86e9f5f5148",
            "value": " 313/313 [00:00&lt;00:00, 29.2kB/s]"
          }
        },
        "2bb79c52a9e24e019f6d61794486423d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08b1b3acebdd4667bf5f66f822e8da24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79f2001fae29429b939e7cff03bf3777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3af82634ab1042a48ef1d677bdf120b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a8a36a9009745e482e6311d09aa4085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94cd8012674d4f538166b0cb7f4b29a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d1f3a30c63e4ac7b0f1f86e9f5f5148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e790ae874bf40c594d11a988e920dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4d5e15793e1493bacb3dfd957ad176a",
              "IPY_MODEL_87f567cf1e9d482ebd05796f88d4a0ac",
              "IPY_MODEL_8224f8b43a7d4dd7b1cd1875533e2cde"
            ],
            "layout": "IPY_MODEL_6d5babb6111e4402a0fc688938ae42b1"
          }
        },
        "d4d5e15793e1493bacb3dfd957ad176a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d79bdb92ccf840edae1c15d3d11218ac",
            "placeholder": "​",
            "style": "IPY_MODEL_23b93e545614463ba22d2b1b2a179338",
            "value": "vocab.txt: "
          }
        },
        "87f567cf1e9d482ebd05796f88d4a0ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03432e998c7247d1ab2d055d58a77a6f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16d50a0ddff64d70b737d579771302cc",
            "value": 1
          }
        },
        "8224f8b43a7d4dd7b1cd1875533e2cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a2e50fee595402da8bb8d292623d6af",
            "placeholder": "​",
            "style": "IPY_MODEL_77ab0795b2e748d7970fadb835f1f946",
            "value": " 213k/? [00:00&lt;00:00, 9.16MB/s]"
          }
        },
        "6d5babb6111e4402a0fc688938ae42b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d79bdb92ccf840edae1c15d3d11218ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23b93e545614463ba22d2b1b2a179338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03432e998c7247d1ab2d055d58a77a6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "16d50a0ddff64d70b737d579771302cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a2e50fee595402da8bb8d292623d6af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77ab0795b2e748d7970fadb835f1f946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "278ab93deb5644e7ab2822d5e6b300c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c991996ec7343d9bbe99cdad45f4438",
              "IPY_MODEL_170af0a0ccc7497da7bec26732e9d61e",
              "IPY_MODEL_2dc57a3402ea4658b8a599a192ee3b0c"
            ],
            "layout": "IPY_MODEL_9293125ce439480cae47e0eecb2b21c9"
          }
        },
        "8c991996ec7343d9bbe99cdad45f4438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5262ea7261d445d5802db2972a27e978",
            "placeholder": "​",
            "style": "IPY_MODEL_44ad21276ce54c09bc4a75d4d1961107",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "170af0a0ccc7497da7bec26732e9d61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c0c27b44c5a461eac70744d90ef2bee",
            "max": 435780550,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a39400d7f5994c1fb356db394f06c7ab",
            "value": 435780550
          }
        },
        "2dc57a3402ea4658b8a599a192ee3b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af605a154cbb4883ab6463067960a219",
            "placeholder": "​",
            "style": "IPY_MODEL_218cee290434448e8920301afad7e555",
            "value": " 436M/436M [00:05&lt;00:00, 101MB/s]"
          }
        },
        "9293125ce439480cae47e0eecb2b21c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5262ea7261d445d5802db2972a27e978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44ad21276ce54c09bc4a75d4d1961107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c0c27b44c5a461eac70744d90ef2bee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a39400d7f5994c1fb356db394f06c7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af605a154cbb4883ab6463067960a219": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "218cee290434448e8920301afad7e555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd98354f512546309171d00e3a1f7809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b0c1cffddcb4feba95d5c6525a729e5",
              "IPY_MODEL_de0f1ab282d3420d9781450c1cc32a8a",
              "IPY_MODEL_bcc6c95f8b1d486fac02fa18fc139a44"
            ],
            "layout": "IPY_MODEL_fbd0a0947cbd4d26b9ebcd292abee8e9"
          }
        },
        "1b0c1cffddcb4feba95d5c6525a729e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb0eb6b26d344d639d7d61a4f0424a1c",
            "placeholder": "​",
            "style": "IPY_MODEL_c3e0dded00224d2e8da43a631b8b75eb",
            "value": "model.safetensors: 100%"
          }
        },
        "de0f1ab282d3420d9781450c1cc32a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c925cc3ffc34eb1ade406e18799ec75",
            "max": 435755944,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3b1dceac692477480e5b22acf4e0e59",
            "value": 435755944
          }
        },
        "bcc6c95f8b1d486fac02fa18fc139a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e969c84cf1e4c21a248f142a1d1d1b0",
            "placeholder": "​",
            "style": "IPY_MODEL_17e81d64f9e145f5855948020ac24f2a",
            "value": " 436M/436M [00:01&lt;00:00, 251MB/s]"
          }
        },
        "fbd0a0947cbd4d26b9ebcd292abee8e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb0eb6b26d344d639d7d61a4f0424a1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e0dded00224d2e8da43a631b8b75eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c925cc3ffc34eb1ade406e18799ec75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3b1dceac692477480e5b22acf4e0e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e969c84cf1e4c21a248f142a1d1d1b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17e81d64f9e145f5855948020ac24f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "056d9c7eed3c4496adc555b0801d5432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9233486bced4ecfbce29be9fee70e65",
              "IPY_MODEL_e654fe9276fb4711b1c50846567b941f",
              "IPY_MODEL_e4fc6c12d48449ee9c56e63fc4ed020b"
            ],
            "layout": "IPY_MODEL_d437cfd510284a28b8d5fba2ae7617bd"
          }
        },
        "d9233486bced4ecfbce29be9fee70e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70839a3cc4e84a79a4656738d2e00277",
            "placeholder": "​",
            "style": "IPY_MODEL_a2d2d1958d1346248e69eea941848b15",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e654fe9276fb4711b1c50846567b941f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b48883c438c4e35b6ef0e9690085a68",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6c6cf4ec9b04cddbc61c0cb146b06a6",
            "value": 25
          }
        },
        "e4fc6c12d48449ee9c56e63fc4ed020b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ea7ef98387f43639438c5baf9c60adc",
            "placeholder": "​",
            "style": "IPY_MODEL_15aabb785e9d43f9bb12e6a75a8beab9",
            "value": " 25.0/25.0 [00:00&lt;00:00, 557B/s]"
          }
        },
        "d437cfd510284a28b8d5fba2ae7617bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70839a3cc4e84a79a4656738d2e00277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d2d1958d1346248e69eea941848b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b48883c438c4e35b6ef0e9690085a68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6c6cf4ec9b04cddbc61c0cb146b06a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ea7ef98387f43639438c5baf9c60adc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15aabb785e9d43f9bb12e6a75a8beab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56c79bbf88cd407eb53f9a3f21e1dfa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ae4381c782241b9aabe9b8a70226734",
              "IPY_MODEL_76fbc04b528346c8a2fdb6aa358c261f",
              "IPY_MODEL_61ea90d0f3c343b8be703d240d608acf"
            ],
            "layout": "IPY_MODEL_95bf3a1791e74452b2579c008499fe29"
          }
        },
        "4ae4381c782241b9aabe9b8a70226734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fac8a16a41a243e789997f2cb834f07f",
            "placeholder": "​",
            "style": "IPY_MODEL_930cc6c2f13c465280dfad5ae9611ce2",
            "value": "config.json: 100%"
          }
        },
        "76fbc04b528346c8a2fdb6aa358c261f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ebcaaa67c35491c8fc507a06b2d051e",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db6878db60b6445ea3f9a8fe24f4a663",
            "value": 482
          }
        },
        "61ea90d0f3c343b8be703d240d608acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38724773137e40f0bca1e448ca383fcb",
            "placeholder": "​",
            "style": "IPY_MODEL_606b5f45a2964632bbf5142f73acc7de",
            "value": " 482/482 [00:00&lt;00:00, 11.9kB/s]"
          }
        },
        "95bf3a1791e74452b2579c008499fe29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fac8a16a41a243e789997f2cb834f07f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "930cc6c2f13c465280dfad5ae9611ce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ebcaaa67c35491c8fc507a06b2d051e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db6878db60b6445ea3f9a8fe24f4a663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38724773137e40f0bca1e448ca383fcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "606b5f45a2964632bbf5142f73acc7de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d6ad8ba0e6546ecaf9bb4e2b94908da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dae606f0d42543d7941ddf1d48cefd77",
              "IPY_MODEL_b61b90a3066e4e92b2a1c38952342261",
              "IPY_MODEL_68a76fa291da46f2834e7c33f9b8d3ca"
            ],
            "layout": "IPY_MODEL_3e981b4aad684dfb81b5e4c1d8401994"
          }
        },
        "dae606f0d42543d7941ddf1d48cefd77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f340c15c6ca4660ac1a47eb649e885f",
            "placeholder": "​",
            "style": "IPY_MODEL_1b81f65b9bff474fb493327dd378c9d0",
            "value": "vocab.json: 100%"
          }
        },
        "b61b90a3066e4e92b2a1c38952342261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ac6767c38e24a66bbb68ee3107c51c9",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a51c401c85f24a1eadc7963d37b5a362",
            "value": 898823
          }
        },
        "68a76fa291da46f2834e7c33f9b8d3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3660f6147dc49aea2faf96b5cdfa3b8",
            "placeholder": "​",
            "style": "IPY_MODEL_5065d2cb1fbb424cad20a669dfe788cf",
            "value": " 899k/899k [00:00&lt;00:00, 21.2MB/s]"
          }
        },
        "3e981b4aad684dfb81b5e4c1d8401994": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f340c15c6ca4660ac1a47eb649e885f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b81f65b9bff474fb493327dd378c9d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ac6767c38e24a66bbb68ee3107c51c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a51c401c85f24a1eadc7963d37b5a362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3660f6147dc49aea2faf96b5cdfa3b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5065d2cb1fbb424cad20a669dfe788cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf065832626a4dbeb7c22ec70418b28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b60b94fcb7c4d69a9f13591fbf2c2ad",
              "IPY_MODEL_9cd7ea096bfc49e3b5140c4a8700b787",
              "IPY_MODEL_13309b6b6e15447e881298f78cd0cbd5"
            ],
            "layout": "IPY_MODEL_6cbfa495807746f0a0d4f104674ff6a9"
          }
        },
        "6b60b94fcb7c4d69a9f13591fbf2c2ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6b3df4c1e7140e199ff996ff56cf965",
            "placeholder": "​",
            "style": "IPY_MODEL_6cdd42fb99d746a3b158dfada9431aab",
            "value": "merges.txt: 100%"
          }
        },
        "9cd7ea096bfc49e3b5140c4a8700b787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8041ddd57f8a465d84c8385911aeb7b6",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e2b65cbd5af42d281aa90325075ea69",
            "value": 456318
          }
        },
        "13309b6b6e15447e881298f78cd0cbd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec98586036e94144bba34e12708ec01b",
            "placeholder": "​",
            "style": "IPY_MODEL_ff55dd2391324048a8acd131498f118e",
            "value": " 456k/456k [00:00&lt;00:00, 1.06MB/s]"
          }
        },
        "6cbfa495807746f0a0d4f104674ff6a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6b3df4c1e7140e199ff996ff56cf965": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cdd42fb99d746a3b158dfada9431aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8041ddd57f8a465d84c8385911aeb7b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e2b65cbd5af42d281aa90325075ea69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec98586036e94144bba34e12708ec01b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff55dd2391324048a8acd131498f118e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8475ad31d49d412ea9e4425058fcca1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd707dcd856f4ad58940a98244fedccd",
              "IPY_MODEL_99513b776c6749168da25f34a98ac602",
              "IPY_MODEL_72daf3bf1b7f4f6bb95f3cbdd59b7034"
            ],
            "layout": "IPY_MODEL_fa6bdb685a3c4d8cb3b5625ce9020016"
          }
        },
        "bd707dcd856f4ad58940a98244fedccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_126057c2f56840c19dea4060b5d4b7b5",
            "placeholder": "​",
            "style": "IPY_MODEL_9adc4ae24fc94b4d9804b56f5dd2169e",
            "value": "tokenizer.json: 100%"
          }
        },
        "99513b776c6749168da25f34a98ac602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f842b533fbe84c2aba70b3b76fddccd7",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94522c9d53bc4ef7923641064203f3b9",
            "value": 1355863
          }
        },
        "72daf3bf1b7f4f6bb95f3cbdd59b7034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_110208b2927a458b92b6366931b2e910",
            "placeholder": "​",
            "style": "IPY_MODEL_a68075ef19e34305a5f726e62ad2ee1f",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 1.51MB/s]"
          }
        },
        "fa6bdb685a3c4d8cb3b5625ce9020016": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "126057c2f56840c19dea4060b5d4b7b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9adc4ae24fc94b4d9804b56f5dd2169e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f842b533fbe84c2aba70b3b76fddccd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94522c9d53bc4ef7923641064203f3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "110208b2927a458b92b6366931b2e910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a68075ef19e34305a5f726e62ad2ee1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43ba427b52914ddca8a64aa896832c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3fc80adf6954a3c91492247500e7165",
              "IPY_MODEL_30cb17eb203a4181a688ab62a59210e1",
              "IPY_MODEL_0ef0627666d64a328328afaacc3c0aef"
            ],
            "layout": "IPY_MODEL_3e870db6ba2045a3948dccebc1fc5b74"
          }
        },
        "d3fc80adf6954a3c91492247500e7165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_573c8fb781b448fd9b20938c14916b4b",
            "placeholder": "​",
            "style": "IPY_MODEL_adcf595557dd45b0a0e1e519a133b3df",
            "value": "model.safetensors: 100%"
          }
        },
        "30cb17eb203a4181a688ab62a59210e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b6322e70a2840f08d610c37d8e2f0d9",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6ac830427b74ef9af5bf89d0a1d4e95",
            "value": 1421700479
          }
        },
        "0ef0627666d64a328328afaacc3c0aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78b6aedefd49473896caeaefe3480d4d",
            "placeholder": "​",
            "style": "IPY_MODEL_a7357b0117384f319a011b17651c191c",
            "value": " 1.42G/1.42G [00:33&lt;00:00, 36.2MB/s]"
          }
        },
        "3e870db6ba2045a3948dccebc1fc5b74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "573c8fb781b448fd9b20938c14916b4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adcf595557dd45b0a0e1e519a133b3df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b6322e70a2840f08d610c37d8e2f0d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6ac830427b74ef9af5bf89d0a1d4e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78b6aedefd49473896caeaefe3480d4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7357b0117384f319a011b17651c191c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FuaadBashi/Died-pipeline-COLAB/blob/main/Model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9zZ7egHVM0Ni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f09a323-2505-48b7-8c4c-21d94600f3a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch transformers seqeval datasets\n",
        "\n",
        "\n",
        "import os, json, random\n",
        "import numpy as np\n",
        "import torch\n",
        "from collections import Counter\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from collections import Counter\n",
        "from transformers import (AutoTokenizer, AutoModelForTokenClassification,\n",
        "                          TrainingArguments, Trainer, EarlyStoppingCallback)\n",
        "from sklearn.utils import resample\n",
        "from seqeval.metrics import f1_score, classification_report\n",
        "from datasets import Dataset as HFDataset\n",
        "\n",
        "!pip install -q torch transformers seqeval datasets\n",
        "\n",
        "import json, random\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset as TorchDataset\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "from collections import Counter, defaultdict\n",
        "from transformers import (AutoTokenizer, AutoModelForTokenClassification,\n",
        "                         TrainingArguments, Trainer, EarlyStoppingCallback)\n",
        "from torch.utils.data import Dataset as TorchDataset\n",
        "from seqeval.metrics import f1_score, precision_score, recall_score\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch.nn.functional as F\n",
        "# ─── ClinicalBERT Fine-tuning for PHI De-Identification ───────────────────────────────"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# ENHANCED ClinicalBERT - LOCATION & PHONE Optimization\n",
        "# =========================\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "from collections import Counter, defaultdict\n",
        "from transformers import (AutoTokenizer, AutoModelForTokenClassification,\n",
        "                         TrainingArguments, Trainer, EarlyStoppingCallback)\n",
        "from torch.utils.data import Dataset as TorchDataset\n",
        "from seqeval.metrics import f1_score, precision_score, recall_score\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# -------------------------\n",
        "# 1) Enhanced Seed & Device Setup\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"✅ Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3}GB\")\n",
        "\n",
        "# -------------------------\n",
        "# 2) Load and Validate Data\n",
        "# -------------------------\n",
        "def load_and_validate_data(filepath):\n",
        "    \"\"\"Load data with validation checks\"\"\"\n",
        "    with open(filepath) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    valid_data = []\n",
        "    for i, entry in enumerate(data):\n",
        "        if len(entry[\"tokens\"]) == len(entry[\"labels\"]):\n",
        "            valid_data.append(entry)\n",
        "        else:\n",
        "            print(f\"⚠️ Skipping entry {i}: token-label mismatch\")\n",
        "\n",
        "    return valid_data\n",
        "\n",
        "train_data = load_and_validate_data('/content/train.json')\n",
        "val_data = load_and_validate_data('/content/val.json')\n",
        "test_data = load_and_validate_data('/content/test.json')\n",
        "\n",
        "train_tokens = [e[\"tokens\"] for e in train_data]\n",
        "train_labels = [e[\"labels\"] for e in train_data]\n",
        "val_tokens = [e[\"tokens\"] for e in val_data]\n",
        "val_labels = [e[\"labels\"] for e in val_data]\n",
        "test_tokens = [e[\"tokens\"] for e in test_data]\n",
        "\n",
        "print(f\"✅ Data loaded - Train: {len(train_tokens)} | Val: {len(val_tokens)} | Test: {len(test_tokens)}\")\n",
        "\n",
        "# -------------------------\n",
        "# 3) Enhanced Label Cleaning\n",
        "# -------------------------\n",
        "def clean_and_normalize_labels(labels):\n",
        "    \"\"\"Clean labels with detailed tracking\"\"\"\n",
        "    out = []\n",
        "    changes = defaultdict(int)\n",
        "\n",
        "    for l in labels:\n",
        "        if l in [\"B-AGE\", \"I-AGE\"]:\n",
        "            out.append(\"O\")\n",
        "            changes[\"AGE_removed\"] += 1\n",
        "        elif l in [\"B-DOCTOR\", \"I-DOCTOR\"]:\n",
        "            out.append(l.replace(\"DOCTOR\", \"NAME\"))\n",
        "            changes[\"DOCTOR_to_NAME\"] += 1\n",
        "        elif l in [\"B-PATIENT\", \"I-PATIENT\"]:\n",
        "            out.append(l.replace(\"PATIENT\", \"NAME\"))\n",
        "            changes[\"PATIENT_to_NAME\"] += 1\n",
        "        else:\n",
        "            out.append(l)\n",
        "    return out, changes\n",
        "\n",
        "# Process labels\n",
        "total_changes = defaultdict(int)\n",
        "cleaned_train_labels = []\n",
        "cleaned_val_labels = []\n",
        "\n",
        "for labels in train_labels:\n",
        "    clean_labels, changes = clean_and_normalize_labels(labels)\n",
        "    cleaned_train_labels.append(clean_labels)\n",
        "    for k, v in changes.items():\n",
        "        total_changes[k] += v\n",
        "\n",
        "for labels in val_labels:\n",
        "    clean_labels, changes = clean_and_normalize_labels(labels)\n",
        "    cleaned_val_labels.append(clean_labels)\n",
        "\n",
        "train_labels = cleaned_train_labels\n",
        "val_labels = cleaned_val_labels\n",
        "\n",
        "print(\"📊 Label cleaning statistics:\")\n",
        "for change, count in total_changes.items():\n",
        "    print(f\"   {change}: {count}\")\n",
        "\n",
        "target_labels = [\n",
        "    \"B-DATE\", \"I-DATE\", \"B-HOSPITAL\", \"I-HOSPITAL\", \"B-ID\", \"I-ID\",\n",
        "    \"B-LOCATION\", \"I-LOCATION\", \"B-NAME\", \"I-NAME\", \"B-PHONE\", \"I-PHONE\", \"O\"\n",
        "]\n",
        "\n",
        "label_to_id = {l: i for i, l in enumerate(target_labels)}\n",
        "id_to_label = {i: l for l, i in label_to_id.items()}\n",
        "\n",
        "# -------------------------\n",
        "# 4) TARGETED Data Augmentation for LOCATION & PHONE\n",
        "# -------------------------\n",
        "def analyze_rare_entities(tokens_list, labels_list):\n",
        "    \"\"\"Analyze LOCATION and PHONE entities specifically\"\"\"\n",
        "    entity_stats = defaultdict(lambda: {\"count\": 0, \"samples\": [], \"contexts\": []})\n",
        "\n",
        "    for sample_idx, (tokens, labels) in enumerate(zip(tokens_list, labels_list)):\n",
        "        sample_has_location = False\n",
        "        sample_has_phone = False\n",
        "\n",
        "        for i, label in enumerate(labels):\n",
        "            if label != \"O\":\n",
        "                entity_type = label[2:] if label.startswith((\"B-\", \"I-\")) else label\n",
        "\n",
        "                if entity_type in [\"LOCATION\", \"PHONE\"]:\n",
        "                    entity_stats[entity_type][\"count\"] += 1\n",
        "                    entity_stats[entity_type][\"samples\"].append(sample_idx)\n",
        "\n",
        "                    # Capture wider context for rare entities\n",
        "                    start = max(0, i-5)\n",
        "                    end = min(len(tokens), i+6)\n",
        "                    context = \" \".join(tokens[start:end])\n",
        "                    entity_stats[entity_type][\"contexts\"].append(context)\n",
        "\n",
        "                    if entity_type == \"LOCATION\":\n",
        "                        sample_has_location = True\n",
        "                    elif entity_type == \"PHONE\":\n",
        "                        sample_has_phone = True\n",
        "\n",
        "        # Track samples containing rare entities\n",
        "        if sample_has_location:\n",
        "            entity_stats[\"LOCATION\"][\"samples\"].append(sample_idx)\n",
        "        if sample_has_phone:\n",
        "            entity_stats[\"PHONE\"][\"samples\"].append(sample_idx)\n",
        "\n",
        "    return entity_stats\n",
        "\n",
        "def aggressive_oversample_rare_entities(tokens_list, labels_list, entity_stats):\n",
        "    \"\"\"Aggressively oversample LOCATION and PHONE entities\"\"\"\n",
        "    aug_tokens, aug_labels = [], []\n",
        "\n",
        "    rare_entities = [\"LOCATION\", \"PHONE\"]\n",
        "\n",
        "    for entity in rare_entities:\n",
        "        if entity not in entity_stats or entity_stats[entity][\"count\"] == 0:\n",
        "            print(f\"⚠️ No {entity} entities found in training data\")\n",
        "            continue\n",
        "\n",
        "        unique_samples = list(set(entity_stats[entity][\"samples\"]))\n",
        "        current_count = entity_stats[entity][\"count\"]\n",
        "\n",
        "        print(f\"🎯 Targeting {entity}:\")\n",
        "        print(f\"   Current instances: {current_count}\")\n",
        "        print(f\"   Samples with {entity}: {len(unique_samples)}\")\n",
        "\n",
        "        if len(unique_samples) == 0:\n",
        "            continue\n",
        "\n",
        "        # Extremely aggressive oversampling for rare entities\n",
        "        target_multiplier = max(20, 100 // len(unique_samples))  # At least 20x, more if very few samples\n",
        "\n",
        "        print(f\"   📈 Oversampling {entity}: {len(unique_samples)} samples × {target_multiplier}\")\n",
        "\n",
        "        # Oversample each unique sample multiple times\n",
        "        for _ in range(target_multiplier):\n",
        "            for sample_idx in unique_samples:\n",
        "                if sample_idx < len(tokens_list):\n",
        "                    aug_tokens.append(tokens_list[sample_idx])\n",
        "                    aug_labels.append(labels_list[sample_idx])\n",
        "\n",
        "    return aug_tokens, aug_labels\n",
        "\n",
        "# Analyze and oversample rare entities\n",
        "entity_stats = analyze_rare_entities(train_tokens, train_labels)\n",
        "print(\"🔍 Analyzing rare entities...\")\n",
        "\n",
        "for entity in [\"LOCATION\", \"PHONE\"]:\n",
        "    if entity in entity_stats:\n",
        "        print(f\"   {entity}: {entity_stats[entity]['count']} instances\")\n",
        "        if entity_stats[entity]['contexts']:\n",
        "            print(f\"   Sample contexts: {entity_stats[entity]['contexts'][:3]}\")\n",
        "\n",
        "print(\"\\n🚀 Applying aggressive oversampling for LOCATION & PHONE...\")\n",
        "aug_tokens, aug_labels = aggressive_oversample_rare_entities(train_tokens, train_labels, entity_stats)\n",
        "\n",
        "train_tokens.extend(aug_tokens)\n",
        "train_labels.extend(aug_labels)\n",
        "\n",
        "print(f\"✅ Aggressive oversampling complete: +{len(aug_tokens)} samples\")\n",
        "print(f\"   Total training samples: {len(train_tokens)}\")\n",
        "\n",
        "# -------------------------\n",
        "# 5) EXTREME Class Weights for Rare Entities\n",
        "# -------------------------\n",
        "def calculate_extreme_weights_for_rare(labels_list):\n",
        "    \"\"\"Calculate extreme class weights focusing on LOCATION & PHONE\"\"\"\n",
        "    flat_labels = [lbl for seq in labels_list for lbl in seq]\n",
        "    counts = Counter(flat_labels)\n",
        "    total = len(flat_labels)\n",
        "\n",
        "    weights = {}\n",
        "    for label in target_labels:\n",
        "        count = counts.get(label, 1)\n",
        "\n",
        "        if label == \"O\":\n",
        "            weights[label] = 0.3  # Moderate O-class reduction\n",
        "        elif \"LOCATION\" in label or \"PHONE\" in label:\n",
        "            # EXTREME weights for LOCATION and PHONE\n",
        "            base_weight = total / (len(target_labels) * count)\n",
        "            weights[label] = min(base_weight * 5.0, 25.0)  # 5x multiplier, cap at 25\n",
        "            print(f\"🎯 Extreme weight for {label}: {weights[label]:.2f}\")\n",
        "        else:\n",
        "            # Standard weights for other entities\n",
        "            base_weight = total / (len(target_labels) * count)\n",
        "            weights[label] = min(base_weight * 1.2, 6.0)\n",
        "\n",
        "    return weights\n",
        "\n",
        "# -------------------------\n",
        "# 6) Enhanced Dataset with Pattern Recognition\n",
        "# -------------------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\", use_fast=True)\n",
        "\n",
        "class EnhancedNERDataset(TorchDataset):\n",
        "    def __init__(self, tokens, labels, tokenizer, label_to_id, max_len=256):\n",
        "        self.tokens, self.labels = tokens, labels\n",
        "        self.tok, self.l2id, self.max_len = tokenizer, label_to_id, max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        words, labs = self.tokens[idx], self.labels[idx]\n",
        "\n",
        "        # Ensure consistency\n",
        "        min_len = min(len(words), len(labs))\n",
        "        words = words[:min_len]\n",
        "        labs = labs[:min_len]\n",
        "\n",
        "        # Handle long sequences\n",
        "        if len(words) > self.max_len - 2:\n",
        "            words = words[:self.max_len - 2]\n",
        "            labs = labs[:self.max_len - 2]\n",
        "\n",
        "        # Enhanced encoding for rare entity detection\n",
        "        enc = self.tok(words, is_split_into_words=True, truncation=True,\n",
        "                       max_length=self.max_len, padding=\"max_length\")\n",
        "\n",
        "        # Align labels with subword tokens\n",
        "        wids = enc.word_ids()\n",
        "        aligned = []\n",
        "        prev_wid = None\n",
        "\n",
        "        for wid in wids:\n",
        "            if wid is None:\n",
        "                aligned.append(-100)\n",
        "            elif wid != prev_wid:\n",
        "                if wid < len(labs):\n",
        "                    label = labs[wid]\n",
        "                    aligned.append(self.l2id.get(label, self.l2id[\"O\"]))\n",
        "                else:\n",
        "                    aligned.append(self.l2id[\"O\"])\n",
        "            else:\n",
        "                aligned.append(-100)\n",
        "            prev_wid = wid\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(enc[\"input_ids\"], dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(enc[\"attention_mask\"], dtype=torch.long),\n",
        "            \"labels\": torch.tensor(aligned, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# -------------------------\n",
        "# 7) Focal Loss Trainer for Rare Entity Focus\n",
        "# -------------------------\n",
        "class FocalLossTrainer(Trainer):\n",
        "    def __init__(self, class_weights=None, focal_gamma=3.0, label_to_id=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.class_weights = class_weights\n",
        "        self.focal_gamma = focal_gamma  # Higher gamma for harder focus on rare entities\n",
        "        self.label_to_id = label_to_id or {}\n",
        "\n",
        "    def focal_loss(self, logits, labels):\n",
        "        \"\"\"Enhanced focal loss with extreme focus on rare entities\"\"\"\n",
        "        ce_loss = F.cross_entropy(logits, labels, weight=self.class_weights, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "\n",
        "        # Adaptive alpha based on label rarity\n",
        "        alpha = torch.ones_like(labels, dtype=torch.float)\n",
        "\n",
        "        # Get rare entity label IDs\n",
        "        rare_label_ids = [\n",
        "            self.label_to_id.get(\"B-LOCATION\", -1),\n",
        "            self.label_to_id.get(\"I-LOCATION\", -1),\n",
        "            self.label_to_id.get(\"B-PHONE\", -1),\n",
        "            self.label_to_id.get(\"I-PHONE\", -1)\n",
        "        ]\n",
        "\n",
        "        # Apply high alpha for rare entities\n",
        "        for label_id in rare_label_ids:\n",
        "            if label_id != -1:  # Valid label ID\n",
        "                alpha = torch.where(labels == label_id, 0.9, alpha)\n",
        "\n",
        "        focal_loss = alpha * (1 - pt) ** self.focal_gamma * ce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Filter active positions\n",
        "        active_loss = labels.view(-1) != -100\n",
        "        active_logits = logits.view(-1, logits.size(-1))[active_loss]\n",
        "        active_labels = labels.view(-1)[active_loss]\n",
        "\n",
        "        if len(active_labels) == 0:\n",
        "            return torch.tensor(0.0, requires_grad=True, device=logits.device)\n",
        "\n",
        "        # Use focal loss for better rare entity detection\n",
        "        loss = self.focal_loss(active_logits, active_labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# -------------------------\n",
        "# 8) Enhanced Metrics Tracking\n",
        "# -------------------------\n",
        "def compute_enhanced_metrics(p):\n",
        "    \"\"\"Enhanced metrics with specific tracking for LOCATION & PHONE\"\"\"\n",
        "    predictions = np.argmax(p.predictions, axis=-1)\n",
        "    labels = p.label_ids\n",
        "\n",
        "    true_labels, pred_labels = [], []\n",
        "\n",
        "    for pred_seq, label_seq in zip(predictions, labels):\n",
        "        true_seq, pred_seq_clean = [], []\n",
        "\n",
        "        for pred, label in zip(pred_seq, label_seq):\n",
        "            if label != -100:\n",
        "                true_seq.append(id_to_label[label])\n",
        "                pred_seq_clean.append(id_to_label[pred])\n",
        "\n",
        "        if true_seq:\n",
        "            true_labels.append(true_seq)\n",
        "            pred_labels.append(pred_seq_clean)\n",
        "\n",
        "    if not true_labels:\n",
        "        return {\"f1\": 0.0, \"precision\": 0.0, \"recall\": 0.0}\n",
        "\n",
        "    # Overall metrics\n",
        "    f1 = f1_score(true_labels, pred_labels)\n",
        "    precision = precision_score(true_labels, pred_labels)\n",
        "    recall = recall_score(true_labels, pred_labels)\n",
        "\n",
        "    # Specific metrics for rare entities\n",
        "    entity_metrics = {}\n",
        "    for entity in [\"LOCATION\", \"PHONE\"]:\n",
        "        entity_true = []\n",
        "        entity_pred = []\n",
        "\n",
        "        for true_seq, pred_seq in zip(true_labels, pred_labels):\n",
        "            et = [label if entity in label else 'O' for label in true_seq]\n",
        "            ep = [label if entity in label else 'O' for label in pred_seq]\n",
        "            entity_true.append(et)\n",
        "            entity_pred.append(ep)\n",
        "\n",
        "        try:\n",
        "            entity_f1 = f1_score(entity_true, entity_pred)\n",
        "            entity_metrics[f\"{entity.lower()}_f1\"] = entity_f1\n",
        "            print(f\"📊 {entity} F1 during training: {entity_f1:.4f}\")\n",
        "        except:\n",
        "            entity_metrics[f\"{entity.lower()}_f1\"] = 0.0\n",
        "\n",
        "    return {\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        **entity_metrics\n",
        "    }\n",
        "\n",
        "# -------------------------\n",
        "# 9) Enhanced Training Configuration\n",
        "# -------------------------\n",
        "def train_enhanced_model():\n",
        "    \"\"\"Train with enhanced focus on LOCATION & PHONE\"\"\"\n",
        "\n",
        "    # Calculate extreme weights\n",
        "    weight_dict = calculate_extreme_weights_for_rare(train_labels)\n",
        "    class_weights = torch.tensor([weight_dict[label] for label in target_labels],\n",
        "                               dtype=torch.float).to(device)\n",
        "\n",
        "    print(\"\\n⚖️ Enhanced class weights (LOCATION & PHONE focus):\")\n",
        "    for label, weight in zip(target_labels, class_weights.cpu().numpy()):\n",
        "        if \"LOCATION\" in label or \"PHONE\" in label:\n",
        "            print(f\"   🎯 {label}: {weight:.2f} (BOOSTED)\")\n",
        "        else:\n",
        "            print(f\"   {label}: {weight:.2f}\")\n",
        "\n",
        "    # Enhanced training arguments\n",
        "    args = TrainingArguments(\n",
        "        output_dir=\"./outputs/clinicalbert_location_phone_enhanced\",\n",
        "        learning_rate=1.5e-5,              # Slightly lower for stability with extreme weights\n",
        "        per_device_train_batch_size=2,     # Smaller batch for more frequent updates\n",
        "        gradient_accumulation_steps=8,     # Maintain effective batch size\n",
        "        per_device_eval_batch_size=4,\n",
        "        num_train_epochs=12,               # More epochs due to data augmentation\n",
        "        warmup_ratio=0.15,                 # More warmup for stability\n",
        "        lr_scheduler_type=\"cosine_with_restarts\",\n",
        "        weight_decay=0.01,\n",
        "        max_grad_norm=0.5,                 # Lower grad norm for stability\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"eval_f1\",\n",
        "        greater_is_better=True,\n",
        "        fp16=True,\n",
        "        dataloader_pin_memory=True,\n",
        "        dataloader_num_workers=2,\n",
        "        seed=SEED,\n",
        "        report_to=\"none\",\n",
        "        logging_steps=50,\n",
        "        save_total_limit=5,\n",
        "        eval_accumulation_steps=4,\n",
        "        prediction_loss_only=False\n",
        "    )\n",
        "\n",
        "    # Initialize fresh model\n",
        "    model = AutoModelForTokenClassification.from_pretrained(\n",
        "        \"emilyalsentzer/Bio_ClinicalBERT\",\n",
        "        num_labels=len(target_labels),\n",
        "        id2label=id_to_label,\n",
        "        label2id=label_to_id,\n",
        "        hidden_dropout_prob=0.2,          # Slightly higher dropout for regularization\n",
        "        attention_probs_dropout_prob=0.2\n",
        "    )\n",
        "\n",
        "    # Create enhanced datasets\n",
        "    train_ds = EnhancedNERDataset(train_tokens, train_labels, tokenizer, label_to_id)\n",
        "    val_ds = EnhancedNERDataset(val_tokens, val_labels, tokenizer, label_to_id)\n",
        "\n",
        "    # Create focal loss trainer\n",
        "    trainer = FocalLossTrainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_ds,\n",
        "        eval_dataset=val_ds,\n",
        "        processing_class=tokenizer,\n",
        "        compute_metrics=compute_enhanced_metrics,\n",
        "        class_weights=class_weights,\n",
        "        focal_gamma=3.0,  # High gamma for extreme focus\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=4)]\n",
        "    )\n",
        "\n",
        "    print(\"🚀 Starting LOCATION & PHONE enhanced training...\")\n",
        "    print(f\"📊 Enhanced Configuration:\")\n",
        "    print(f\"   • Learning rate: 1.5e-5 (stable)\")\n",
        "    print(f\"   • Epochs: 12 (extended)\")\n",
        "    print(f\"   • Batch size: 2 (frequent updates)\")\n",
        "    print(f\"   • Focal loss gamma: 3.0 (extreme focus)\")\n",
        "    print(f\"   • LOCATION/PHONE samples: {len(aug_tokens)} additional\")\n",
        "\n",
        "    try:\n",
        "        train_results = trainer.train()\n",
        "        trainer.save_model(\"./outputs/clinicalbert_location_phone_enhanced\")\n",
        "\n",
        "        print(\"✅ Enhanced training completed successfully!\")\n",
        "\n",
        "        # Final evaluation\n",
        "        eval_results = trainer.evaluate()\n",
        "\n",
        "        print(f\"\\n📈 Enhanced Results:\")\n",
        "        print(f\"   • Overall F1: {eval_results.get('eval_f1', 0):.4f}\")\n",
        "        print(f\"   • Overall Precision: {eval_results.get('eval_precision', 0):.4f}\")\n",
        "        print(f\"   • Overall Recall: {eval_results.get('eval_recall', 0):.4f}\")\n",
        "        print(f\"   • LOCATION F1: {eval_results.get('eval_location_f1', 0):.4f}\")\n",
        "        print(f\"   • PHONE F1: {eval_results.get('eval_phone_f1', 0):.4f}\")\n",
        "\n",
        "        return trainer, eval_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Enhanced training failed: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# -------------------------\n",
        "# 10) Run Enhanced Training\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    trainer, results = train_enhanced_model()\n",
        "\n",
        "    print(f\"\\n🎯 LOCATION & PHONE Enhancement Results:\")\n",
        "    print(f\"   📊 Expected improvements in rare entity detection\")\n",
        "    print(f\"   🚀 Model saved for enhanced PHI detection capabilities\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "756c20460b7e40d1b98d745790b11d08",
            "2025cc5f00e94a538e27650c9e97bf24",
            "b4d61828098d4b9896df2382d025ef12",
            "1947788d4a5c4c5a896191af2e2663ca",
            "631a20e46f834288b1ed4860d70fd32d",
            "70137857e7944aba9cc86d55f99d1b58",
            "5742c76066f04b2eaf086768296a366b",
            "7f63f13bfd4c42829dc5fe8503de7148",
            "265377e687ea439e86b871db6dfe5876",
            "44ac7093534f412cbbb3fb7bedfac1e2",
            "79796e4b8557457eb8bfe69a1674d69b",
            "176ca1349ff94979b12b933a0ec0dc14",
            "71c7fe0c772140dba19bca15cee41644",
            "dc7039a0c90444909a25cec2e440f1b4",
            "847f26ad7c90497ca232498fc935a3dc",
            "373ff990cbeb4a7b849dc2dc0d9867ee",
            "11871c97b780477dbe903af16ff03063",
            "bc053dda28924386acf6ccbd1883d72b",
            "139bc287ca654bf99384af62f72c4455",
            "bc7bdecfc07c4879af8c4193ee523c85",
            "0f0505f5bee34f3387b5d62577e049a1",
            "668eae2c2572404ca784c9af4c4cdded",
            "cecebb426e1d40ccad39069efe6a1f00",
            "85c0b1e01ca94de0ac2dd4f4f5e65abd",
            "f3dc2527aca24e548ecfdb0943489170",
            "3daa5b7e0e9048369c37b145ac30b980",
            "627f6d1032f84081ade71fe894c72e85",
            "1d9d0984ef8b41faaa31bc2036288115",
            "2e1c8145a44045c99617c590b9d92fe7",
            "ed89f92dcce64ab296f509177a4d8e6f",
            "ef7eafb321b04719b292f684d4bcdcf1",
            "b6d711eb9c9647c3b35a9db0d1a07fa7",
            "555859519f04456091f56a14570f2490",
            "e509448c025544228463266d0a5ba85a",
            "c424177280204ff29e87660302050165",
            "941f206b8d894d148c70e12f65b6d29e",
            "1f86def15a7848e8bc8463acd44cf685",
            "892f62f01f8c46a6ab5df1b448a2997b",
            "9cec3dca14d4414b8a196a7be6a2613b",
            "41f492d122cc4c488849b520874843f0",
            "106648618223433183d434f635fd52a9",
            "86210416c17841b381cc6621ac23ecda",
            "82656fb0f68644c1a2543972a56e06b0",
            "fbdb0e7da91642da81ba9038763b797f"
          ]
        },
        "id": "oMFIqM4pOnfc",
        "outputId": "2ff1e67f-de2d-41be-937e-b41ba09ac7c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Using device: cuda\n",
            "   GPU: Tesla T4\n",
            "   Memory: 14GB\n",
            "✅ Data loaded - Train: 669 | Val: 220 | Test: 220\n",
            "📊 Label cleaning statistics:\n",
            "   PATIENT_to_NAME: 1796\n",
            "   DOCTOR_to_NAME: 6363\n",
            "   AGE_removed: 13\n",
            "🔍 Analyzing rare entities...\n",
            "   LOCATION: 360 instances\n",
            "   Sample contexts: ['SOCIAL HISTORY : Lives in Merca . Drinks ginger brandy to', ': The patient lives in Jer by herself . However ,', 'Lives with her husband in Bayont . PHYSICAL EXAMINATION : She']\n",
            "   PHONE: 236 instances\n",
            "   Sample contexts: [\"Dr. Stable 's office , 495-3401 . Goal INR should be\", 'need additional information please call 605-304-8547 . PCP Name : SC', ', Georgia 97746 . Phone# (139) 667-6656 . Dictated By :']\n",
            "\n",
            "🚀 Applying aggressive oversampling for LOCATION & PHONE...\n",
            "🎯 Targeting LOCATION:\n",
            "   Current instances: 360\n",
            "   Samples with LOCATION: 90\n",
            "   📈 Oversampling LOCATION: 90 samples × 20\n",
            "🎯 Targeting PHONE:\n",
            "   Current instances: 236\n",
            "   Samples with PHONE: 148\n",
            "   📈 Oversampling PHONE: 148 samples × 20\n",
            "✅ Aggressive oversampling complete: +4760 samples\n",
            "   Total training samples: 5429\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "756c20460b7e40d1b98d745790b11d08"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "176ca1349ff94979b12b933a0ec0dc14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 Extreme weight for B-LOCATION: 25.00\n",
            "🎯 Extreme weight for I-LOCATION: 25.00\n",
            "🎯 Extreme weight for B-PHONE: 25.00\n",
            "🎯 Extreme weight for I-PHONE: 25.00\n",
            "\n",
            "⚖️ Enhanced class weights (LOCATION & PHONE focus):\n",
            "   B-DATE: 6.00\n",
            "   I-DATE: 6.00\n",
            "   B-HOSPITAL: 6.00\n",
            "   I-HOSPITAL: 6.00\n",
            "   B-ID: 6.00\n",
            "   I-ID: 6.00\n",
            "   🎯 B-LOCATION: 25.00 (BOOSTED)\n",
            "   🎯 I-LOCATION: 25.00 (BOOSTED)\n",
            "   B-NAME: 6.00\n",
            "   I-NAME: 6.00\n",
            "   🎯 B-PHONE: 25.00 (BOOSTED)\n",
            "   🎯 I-PHONE: 25.00 (BOOSTED)\n",
            "   O: 0.30\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cecebb426e1d40ccad39069efe6a1f00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting LOCATION & PHONE enhanced training...\n",
            "📊 Enhanced Configuration:\n",
            "   • Learning rate: 1.5e-5 (stable)\n",
            "   • Epochs: 12 (extended)\n",
            "   • Batch size: 2 (frequent updates)\n",
            "   • Focal loss gamma: 3.0 (extreme focus)\n",
            "   • LOCATION/PHONE samples: 4760 additional\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e509448c025544228463266d0a5ba85a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4080' max='4080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4080/4080 33:44, Epoch 12/12]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Location F1</th>\n",
              "      <th>Phone F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.201500</td>\n",
              "      <td>0.164293</td>\n",
              "      <td>0.536398</td>\n",
              "      <td>0.387114</td>\n",
              "      <td>0.873090</td>\n",
              "      <td>0.032587</td>\n",
              "      <td>0.494382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.006200</td>\n",
              "      <td>0.089405</td>\n",
              "      <td>0.824645</td>\n",
              "      <td>0.747137</td>\n",
              "      <td>0.920094</td>\n",
              "      <td>0.178947</td>\n",
              "      <td>0.807018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.004200</td>\n",
              "      <td>0.086143</td>\n",
              "      <td>0.888273</td>\n",
              "      <td>0.840321</td>\n",
              "      <td>0.942029</td>\n",
              "      <td>0.273504</td>\n",
              "      <td>0.807018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.002300</td>\n",
              "      <td>0.077828</td>\n",
              "      <td>0.911190</td>\n",
              "      <td>0.868346</td>\n",
              "      <td>0.958480</td>\n",
              "      <td>0.377358</td>\n",
              "      <td>0.867925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.088493</td>\n",
              "      <td>0.908681</td>\n",
              "      <td>0.873239</td>\n",
              "      <td>0.947121</td>\n",
              "      <td>0.404762</td>\n",
              "      <td>0.846154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.077320</td>\n",
              "      <td>0.934426</td>\n",
              "      <td>0.910137</td>\n",
              "      <td>0.960047</td>\n",
              "      <td>0.493151</td>\n",
              "      <td>0.938776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.083756</td>\n",
              "      <td>0.936300</td>\n",
              "      <td>0.909830</td>\n",
              "      <td>0.964356</td>\n",
              "      <td>0.457831</td>\n",
              "      <td>0.936170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.088507</td>\n",
              "      <td>0.926811</td>\n",
              "      <td>0.898199</td>\n",
              "      <td>0.957305</td>\n",
              "      <td>0.450704</td>\n",
              "      <td>0.938776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.083578</td>\n",
              "      <td>0.941424</td>\n",
              "      <td>0.920629</td>\n",
              "      <td>0.963181</td>\n",
              "      <td>0.507042</td>\n",
              "      <td>0.936170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>0.081854</td>\n",
              "      <td>0.940681</td>\n",
              "      <td>0.919566</td>\n",
              "      <td>0.962789</td>\n",
              "      <td>0.507042</td>\n",
              "      <td>0.936170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.085092</td>\n",
              "      <td>0.937512</td>\n",
              "      <td>0.915299</td>\n",
              "      <td>0.960830</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.936170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.085491</td>\n",
              "      <td>0.937512</td>\n",
              "      <td>0.915299</td>\n",
              "      <td>0.960830</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.936170</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 LOCATION F1 during training: 0.0326\n",
            "📊 PHONE F1 during training: 0.4944\n",
            "📊 LOCATION F1 during training: 0.1789\n",
            "📊 PHONE F1 during training: 0.8070\n",
            "📊 LOCATION F1 during training: 0.2735\n",
            "📊 PHONE F1 during training: 0.8070\n",
            "📊 LOCATION F1 during training: 0.3774\n",
            "📊 PHONE F1 during training: 0.8679\n",
            "📊 LOCATION F1 during training: 0.4048\n",
            "📊 PHONE F1 during training: 0.8462\n",
            "📊 LOCATION F1 during training: 0.4932\n",
            "📊 PHONE F1 during training: 0.9388\n",
            "📊 LOCATION F1 during training: 0.4578\n",
            "📊 PHONE F1 during training: 0.9362\n",
            "📊 LOCATION F1 during training: 0.4507\n",
            "📊 PHONE F1 during training: 0.9388\n",
            "📊 LOCATION F1 during training: 0.5070\n",
            "📊 PHONE F1 during training: 0.9362\n",
            "📊 LOCATION F1 during training: 0.5070\n",
            "📊 PHONE F1 during training: 0.9362\n",
            "📊 LOCATION F1 during training: 0.4800\n",
            "📊 PHONE F1 during training: 0.9362\n",
            "📊 LOCATION F1 during training: 0.4800\n",
            "📊 PHONE F1 during training: 0.9362\n",
            "✅ Enhanced training completed successfully!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [55/55 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 LOCATION F1 during training: 0.5070\n",
            "📊 PHONE F1 during training: 0.9362\n",
            "\n",
            "📈 Enhanced Results:\n",
            "   • Overall F1: 0.9414\n",
            "   • Overall Precision: 0.9206\n",
            "   • Overall Recall: 0.9632\n",
            "   • LOCATION F1: 0.5070\n",
            "   • PHONE F1: 0.9362\n",
            "\n",
            "🎯 LOCATION & PHONE Enhancement Results:\n",
            "   📊 Expected improvements in rare entity detection\n",
            "   🚀 Model saved for enhanced PHI detection capabilities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# FIXED ClinicalBERT Evaluation Suite\n",
        "# =========================\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import Counter, defaultdict\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# -------------------------\n",
        "# 1) Safe Evaluation Functions (Handle Length Mismatches)\n",
        "# -------------------------\n",
        "def safe_sequence_metrics(true_labels, pred_labels):\n",
        "    \"\"\"Calculate metrics safely handling sequence length mismatches\"\"\"\n",
        "\n",
        "    # Ensure sequences have same length\n",
        "    aligned_true = []\n",
        "    aligned_pred = []\n",
        "\n",
        "    for true_seq, pred_seq in zip(true_labels, pred_labels):\n",
        "        min_len = min(len(true_seq), len(pred_seq))\n",
        "        if min_len > 0:\n",
        "            aligned_true.append(true_seq[:min_len])\n",
        "            aligned_pred.append(pred_seq[:min_len])\n",
        "\n",
        "    if not aligned_true:\n",
        "        return {\"f1\": 0.0, \"precision\": 0.0, \"recall\": 0.0}\n",
        "\n",
        "    # Calculate token-level metrics\n",
        "    all_true_flat = [label for seq in aligned_true for label in seq]\n",
        "    all_pred_flat = [label for seq in aligned_pred for label in seq]\n",
        "\n",
        "    # Entity-level metrics (safer approach)\n",
        "    true_entities = set()\n",
        "    pred_entities = set()\n",
        "\n",
        "    for seq_idx, (true_seq, pred_seq) in enumerate(zip(aligned_true, aligned_pred)):\n",
        "        # Extract entities from true sequence\n",
        "        current_entity = None\n",
        "        entity_start = None\n",
        "\n",
        "        for pos, label in enumerate(true_seq):\n",
        "            if label.startswith('B-'):\n",
        "                if current_entity is not None:\n",
        "                    true_entities.add((seq_idx, entity_start, pos-1, current_entity))\n",
        "                current_entity = label[2:]\n",
        "                entity_start = pos\n",
        "            elif label.startswith('I-') and current_entity is not None:\n",
        "                continue  # Continue current entity\n",
        "            else:  # 'O' or different entity\n",
        "                if current_entity is not None:\n",
        "                    true_entities.add((seq_idx, entity_start, pos-1, current_entity))\n",
        "                current_entity = None\n",
        "                entity_start = None\n",
        "\n",
        "        # Handle entity at end of sequence\n",
        "        if current_entity is not None:\n",
        "            true_entities.add((seq_idx, entity_start, len(true_seq)-1, current_entity))\n",
        "\n",
        "        # Extract entities from predicted sequence\n",
        "        current_entity = None\n",
        "        entity_start = None\n",
        "\n",
        "        for pos, label in enumerate(pred_seq):\n",
        "            if label.startswith('B-'):\n",
        "                if current_entity is not None:\n",
        "                    pred_entities.add((seq_idx, entity_start, pos-1, current_entity))\n",
        "                current_entity = label[2:]\n",
        "                entity_start = pos\n",
        "            elif label.startswith('I-') and current_entity is not None:\n",
        "                continue\n",
        "            else:\n",
        "                if current_entity is not None:\n",
        "                    pred_entities.add((seq_idx, entity_start, pos-1, current_entity))\n",
        "                current_entity = None\n",
        "                entity_start = None\n",
        "\n",
        "        if current_entity is not None:\n",
        "            pred_entities.add((seq_idx, entity_start, len(pred_seq)-1, current_entity))\n",
        "\n",
        "    # Calculate metrics\n",
        "    tp = len(true_entities & pred_entities)\n",
        "    fp = len(pred_entities - true_entities)\n",
        "    fn = len(true_entities - pred_entities)\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    return {\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"true_entities\": len(true_entities),\n",
        "        \"pred_entities\": len(pred_entities),\n",
        "        \"tp\": tp,\n",
        "        \"fp\": fp,\n",
        "        \"fn\": fn\n",
        "    }\n",
        "\n",
        "# -------------------------\n",
        "# 2) Fixed Prediction Function\n",
        "# -------------------------\n",
        "def predict_entities_fixed(tokens_list, model, tokenizer, max_len=256):\n",
        "    \"\"\"Generate predictions with better alignment\"\"\"\n",
        "    predictions = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for tokens in tokens_list:\n",
        "            try:\n",
        "                # Limit sequence length\n",
        "                if len(tokens) > max_len - 2:\n",
        "                    tokens = tokens[:max_len - 2]\n",
        "\n",
        "                # Tokenize\n",
        "                encoding = tokenizer(\n",
        "                    tokens,\n",
        "                    is_split_into_words=True,\n",
        "                    truncation=True,\n",
        "                    max_length=max_len,\n",
        "                    padding=\"max_length\",\n",
        "                    return_tensors=\"pt\"\n",
        "                )\n",
        "\n",
        "                # Get word IDs for alignment\n",
        "                word_ids = encoding.word_ids()\n",
        "\n",
        "                # Move to device\n",
        "                device = next(model.parameters()).device\n",
        "                encoding = {k: v.to(device) for k, v in encoding.items()}\n",
        "\n",
        "                # Predict\n",
        "                outputs = model(**encoding)\n",
        "                logits = outputs.logits\n",
        "                preds = torch.argmax(logits, dim=-1).cpu().numpy()[0]\n",
        "\n",
        "                # Align predictions with original tokens\n",
        "                aligned_preds = []\n",
        "                prev_word_id = None\n",
        "\n",
        "                for i, word_id in enumerate(word_ids):\n",
        "                    if word_id is None:\n",
        "                        continue  # Skip special tokens\n",
        "                    elif word_id != prev_word_id:\n",
        "                        # First subword of a word\n",
        "                        if word_id < len(tokens):\n",
        "                            pred_id = preds[i]\n",
        "                            pred_label = id_to_label.get(pred_id, \"O\")\n",
        "                            aligned_preds.append(pred_label)\n",
        "                    prev_word_id = word_id\n",
        "\n",
        "                # Ensure same length as input tokens\n",
        "                while len(aligned_preds) < len(tokens):\n",
        "                    aligned_preds.append(\"O\")\n",
        "                aligned_preds = aligned_preds[:len(tokens)]\n",
        "\n",
        "                predictions.append(aligned_preds)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing sequence: {e}\")\n",
        "                # Fallback: all O labels\n",
        "                predictions.append([\"O\"] * len(tokens))\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# -------------------------\n",
        "# 3) Load Model and Data (Fixed Path)\n",
        "# -------------------------\n",
        "print(\"🔄 Loading trained model and tokenizer...\")\n",
        "\n",
        "# Try multiple possible model paths - UPDATED for enhanced model\n",
        "possible_paths = [\n",
        "    \"./outputs/clinicalbert_location_phone_enhanced\",  # NEW enhanced model\n",
        "    \"./outputs/clinicalbert_optimized\",                # Previous optimized model\n",
        "    \"./outputs/clinicalbert_max_recall\",               # Original model\n",
        "    \"/content/outputs/clinicalbert_location_phone_enhanced\",\n",
        "    \"/content/outputs/clinicalbert_optimized\",\n",
        "    \"/content/outputs/clinicalbert_max_recall\"\n",
        "]\n",
        "\n",
        "model = None\n",
        "model_path = None\n",
        "\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\", use_fast=True)\n",
        "    print(\"✅ Tokenizer loaded\")\n",
        "\n",
        "    # Try to find the model\n",
        "    for path in possible_paths:\n",
        "        try:\n",
        "            print(f\"🔍 Trying to load model from: {path}\")\n",
        "            model = AutoModelForTokenClassification.from_pretrained(path)\n",
        "            model_path = path\n",
        "            print(f\"✅ Model loaded from: {path}\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to load from {path}: {str(e)[:50]}...\")\n",
        "            continue\n",
        "\n",
        "    if model is None:\n",
        "        print(\"❌ Could not find trained model. Please check if training completed successfully.\")\n",
        "        print(\"💡 Available files in current directory:\")\n",
        "        import os\n",
        "        if os.path.exists(\"outputs\"):\n",
        "            print(f\"   outputs/ contents: {os.listdir('outputs')}\")\n",
        "        else:\n",
        "            print(\"   No outputs/ directory found\")\n",
        "        exit()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"✅ Model ready on {device}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading model: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Load data\n",
        "try:\n",
        "    with open('/content/test.json') as f:\n",
        "        test_data = json.load(f)\n",
        "    test_tokens = [entry[\"tokens\"] for entry in test_data]\n",
        "\n",
        "    with open('/content/val.json') as f:\n",
        "        gt_data = json.load(f)\n",
        "    gt_tokens = [entry[\"tokens\"] for entry in gt_data]\n",
        "    gt_labels = [entry[\"labels\"] for entry in gt_data]\n",
        "\n",
        "    print(f\"✅ Data loaded: Test={len(test_tokens)}, GT={len(gt_tokens)} samples\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading data: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Clean labels (same as training)\n",
        "def clean_and_normalize_labels(labels):\n",
        "    out = []\n",
        "    for l in labels:\n",
        "        if l in [\"B-AGE\", \"I-AGE\"]:\n",
        "            out.append(\"O\")\n",
        "        elif l in [\"B-DOCTOR\", \"I-DOCTOR\"]:\n",
        "            out.append(l.replace(\"DOCTOR\", \"NAME\"))\n",
        "        elif l in [\"B-PATIENT\", \"I-PATIENT\"]:\n",
        "            out.append(l.replace(\"PATIENT\", \"NAME\"))\n",
        "        else:\n",
        "            out.append(l)\n",
        "    return out\n",
        "\n",
        "gt_labels_clean = [clean_and_normalize_labels(labels) for labels in gt_labels]\n",
        "\n",
        "# Label mappings\n",
        "target_labels = [\n",
        "    \"B-DATE\", \"I-DATE\", \"B-HOSPITAL\", \"I-HOSPITAL\", \"B-ID\", \"I-ID\",\n",
        "    \"B-LOCATION\", \"I-LOCATION\", \"B-NAME\", \"I-NAME\", \"B-PHONE\", \"I-PHONE\", \"O\"\n",
        "]\n",
        "label_to_id = {l: i for i, l in enumerate(target_labels)}\n",
        "id_to_label = {i: l for l, i in label_to_id.items()}\n",
        "\n",
        "# -------------------------\n",
        "# 4) Generate Predictions with Fixed Function\n",
        "# -------------------------\n",
        "print(\"🔄 Generating predictions...\")\n",
        "gt_predictions = predict_entities_fixed(gt_tokens, model, tokenizer)\n",
        "print(f\"✅ Generated predictions for {len(gt_predictions)} samples\")\n",
        "\n",
        "# -------------------------\n",
        "# 5) Safe Evaluation\n",
        "# -------------------------\n",
        "print(\"🔄 Evaluating predictions...\")\n",
        "evaluation_results = safe_sequence_metrics(gt_labels_clean, gt_predictions)\n",
        "\n",
        "# Per-entity evaluation\n",
        "entity_metrics = {}\n",
        "entities = [\"DATE\", \"HOSPITAL\", \"ID\", \"LOCATION\", \"NAME\", \"PHONE\"]\n",
        "\n",
        "for entity in entities:\n",
        "    # Filter sequences for this entity\n",
        "    entity_true = []\n",
        "    entity_pred = []\n",
        "\n",
        "    for true_seq, pred_seq in zip(gt_labels_clean, gt_predictions):\n",
        "        et = [label if entity in label else 'O' for label in true_seq]\n",
        "        ep = [label if entity in label else 'O' for label in pred_seq]\n",
        "        entity_true.append(et)\n",
        "        entity_pred.append(ep)\n",
        "\n",
        "    entity_result = safe_sequence_metrics(entity_true, entity_pred)\n",
        "    entity_metrics[entity] = {\n",
        "        'f1': entity_result['f1'],\n",
        "        'precision': entity_result['precision'],\n",
        "        'recall': entity_result['recall']\n",
        "    }\n",
        "\n",
        "# -------------------------\n",
        "# 6) Save Results\n",
        "# -------------------------\n",
        "results_data = {\n",
        "    'model_path': model_path,\n",
        "    'test_samples': len(gt_tokens),\n",
        "    'overall_metrics': {\n",
        "        'f1': evaluation_results['f1'],\n",
        "        'precision': evaluation_results['precision'],\n",
        "        'recall': evaluation_results['recall']\n",
        "    },\n",
        "    'entity_metrics': entity_metrics,\n",
        "    'detailed_stats': {\n",
        "        'true_entities': evaluation_results['true_entities'],\n",
        "        'pred_entities': evaluation_results['pred_entities'],\n",
        "        'tp': evaluation_results['tp'],\n",
        "        'fp': evaluation_results['fp'],\n",
        "        'fn': evaluation_results['fn']\n",
        "    },\n",
        "    'predictions': gt_predictions,\n",
        "    'true_labels': gt_labels_clean,\n",
        "    'tokens': gt_tokens\n",
        "}\n",
        "\n",
        "# Save results\n",
        "with open('evaluation_results_clincalbert.json', 'w') as f:\n",
        "    json.dump(results_data, f, indent=2)\n",
        "\n",
        "# Create entity DataFrame\n",
        "entity_df = pd.DataFrame(entity_metrics).T\n",
        "entity_df.to_csv('entity_performance_clincalbert.csv')\n",
        "\n",
        "print(\"✅ Results saved successfully!\")\n",
        "\n",
        "# -------------------------\n",
        "# 7) Print Summary\n",
        "# -------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🎯 EVALUATION RESULTS (FIXED)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n📊 Overall Performance:\")\n",
        "print(f\"   • F1-Score:  {evaluation_results['f1']:.4f}\")\n",
        "print(f\"   • Precision: {evaluation_results['precision']:.4f}\")\n",
        "print(f\"   • Recall:    {evaluation_results['recall']:.4f}\")\n",
        "\n",
        "print(f\"\\n📈 Entity Counts:\")\n",
        "print(f\"   • True entities found: {evaluation_results['true_entities']}\")\n",
        "print(f\"   • Predicted entities: {evaluation_results['pred_entities']}\")\n",
        "print(f\"   • True Positives: {evaluation_results['tp']}\")\n",
        "print(f\"   • False Positives: {evaluation_results['fp']}\")\n",
        "print(f\"   • False Negatives: {evaluation_results['fn']}\")\n",
        "\n",
        "print(f\"\\n🎯 Entity-Level Performance:\")\n",
        "for entity, metrics in entity_metrics.items():\n",
        "    print(f\"   • {entity:10s}: F1={metrics['f1']:.3f}, P={metrics['precision']:.3f}, R={metrics['recall']:.3f}\")\n",
        "\n",
        "print(f\"\\n✅ Evaluation completed successfully!\")\n",
        "print(f\"📁 Files saved:\")\n",
        "print(f\"   • evaluation_results.json\")\n",
        "print(f\"   • entity_performance.csv\")"
      ],
      "metadata": {
        "id": "cnMChJBHQEYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d26df37e-aba3-4ffc-c1cb-e469c611b32a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Loading trained model and tokenizer...\n",
            "✅ Tokenizer loaded\n",
            "🔍 Trying to load model from: ./outputs/clinicalbert_location_phone_enhanced\n",
            "✅ Model loaded from: ./outputs/clinicalbert_location_phone_enhanced\n",
            "✅ Model ready on cuda\n",
            "✅ Data loaded: Test=220, GT=220 samples\n",
            "🔄 Generating predictions...\n",
            "✅ Generated predictions for 220 samples\n",
            "🔄 Evaluating predictions...\n",
            "✅ Results saved successfully!\n",
            "\n",
            "============================================================\n",
            "🎯 EVALUATION RESULTS (FIXED)\n",
            "============================================================\n",
            "\n",
            "📊 Overall Performance:\n",
            "   • F1-Score:  0.8852\n",
            "   • Precision: 0.9271\n",
            "   • Recall:    0.8468\n",
            "\n",
            "📈 Entity Counts:\n",
            "   • True entities found: 2899\n",
            "   • Predicted entities: 2648\n",
            "   • True Positives: 2455\n",
            "   • False Positives: 193\n",
            "   • False Negatives: 444\n",
            "\n",
            "🎯 Entity-Level Performance:\n",
            "   • DATE      : F1=0.894, P=0.962, R=0.835\n",
            "   • HOSPITAL  : F1=0.780, P=0.804, R=0.758\n",
            "   • ID        : F1=0.984, P=0.996, R=0.973\n",
            "   • LOCATION  : F1=0.450, P=0.419, R=0.486\n",
            "   • NAME      : F1=0.761, P=0.845, R=0.692\n",
            "   • PHONE     : F1=0.880, P=0.957, R=0.815\n",
            "\n",
            "✅ Evaluation completed successfully!\n",
            "📁 Files saved:\n",
            "   • evaluation_results.json\n",
            "   • entity_performance.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# FIXED MODEL DOWNLOAD CODE\n",
        "# ===========================\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "print(\"📦 Preparing ClinicalBERT model for download...\")\n",
        "\n",
        "# Check what files exist in the outputs directory\n",
        "if os.path.exists('./outputs'):\n",
        "    print(\"✅ Found outputs directory\")\n",
        "\n",
        "    # List contents of outputs directory\n",
        "    print(\"\\n📂 Contents of ./outputs/:\")\n",
        "    for root, dirs, files_list in os.walk('./outputs'):\n",
        "        level = root.replace('./outputs', '').count(os.sep)\n",
        "        indent = ' ' * 2 * level\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        subindent = ' ' * 2 * (level + 1)\n",
        "        for file in files_list:\n",
        "            file_size = os.path.getsize(os.path.join(root, file))\n",
        "            file_size_mb = file_size / (1024 * 1024)\n",
        "            print(f\"{subindent}{file} ({file_size_mb:.1f} MB)\")\n",
        "else:\n",
        "    print(\"❌ outputs directory not found\")\n",
        "\n",
        "    # Check for alternative locations\n",
        "    print(\"\\n🔍 Checking alternative model save locations...\")\n",
        "\n",
        "    # Check current directory\n",
        "    current_files = [f for f in os.listdir('.') if 'clinicalbert' in f.lower() or 'model' in f.lower()]\n",
        "    if current_files:\n",
        "        print(f\"✅ Found model files in current directory: {current_files}\")\n",
        "\n",
        "    # Check if trainer saved model elsewhere\n",
        "    if 'trainer' in globals():\n",
        "        print(f\"✅ Trainer output directory: {trainer.args.output_dir}\")\n",
        "        if os.path.exists(trainer.args.output_dir):\n",
        "            print(\"✅ Trainer output directory exists\")\n",
        "        else:\n",
        "            print(\"❌ Trainer output directory not found\")\n",
        "\n",
        "# Method 1: Try original path\n",
        "if os.path.exists('./outputs/clinicalbert'):\n",
        "    print(\"\\n📦 Creating zip file from ./outputs/clinicalbert...\")\n",
        "    !zip -rq clinicalbert_model.zip ./outputs/clinicalbert\n",
        "\n",
        "    if os.path.exists('clinicalbert_model.zip'):\n",
        "        print(\"✅ Zip file created successfully\")\n",
        "\n",
        "        # Check zip file size\n",
        "        zip_size = os.path.getsize('clinicalbert_model.zip')\n",
        "        zip_size_mb = zip_size / (1024 * 1024)\n",
        "        print(f\"📦 Zip file size: {zip_size_mb:.1f} MB\")\n",
        "\n",
        "        # Download the file\n",
        "        print(\"⬇️ Starting download...\")\n",
        "        files.download('clinicalbert_model.zip')\n",
        "        print(\"✅ Download initiated!\")\n",
        "    else:\n",
        "        print(\"❌ Failed to create zip file\")\n",
        "\n",
        "# Method 2: Try trainer output directory\n",
        "elif 'trainer' in globals() and os.path.exists(trainer.args.output_dir):\n",
        "    print(f\"\\n📦 Creating zip file from trainer output: {trainer.args.output_dir}\")\n",
        "    !zip -rq clinicalbert_model.zip {trainer.args.output_dir}\n",
        "\n",
        "    if os.path.exists('clinicalbert_model.zip'):\n",
        "        print(\"✅ Zip file created successfully\")\n",
        "\n",
        "        # Check zip file size\n",
        "        zip_size = os.path.getsize('clinicalbert_model.zip')\n",
        "        zip_size_mb = zip_size / (1024 * 1024)\n",
        "        print(f\"📦 Zip file size: {zip_size_mb:.1f} MB\")\n",
        "\n",
        "        # Download the file\n",
        "        print(\"⬇️ Starting download...\")\n",
        "        files.download('clinicalbert_model.zip')\n",
        "        print(\"✅ Download initiated!\")\n",
        "    else:\n",
        "        print(\"❌ Failed to create zip file\")\n",
        "\n",
        "# Method 3: Manual save if trainer exists\n",
        "elif 'trainer' in globals():\n",
        "    print(\"\\n💾 Manually saving model files...\")\n",
        "\n",
        "    # Create a directory for the model\n",
        "    os.makedirs('clinicalbert_manual', exist_ok=True)\n",
        "\n",
        "    # Save the model and tokenizer\n",
        "    trainer.save_model('clinicalbert_manual')\n",
        "\n",
        "    if 'tokenizer' in globals():\n",
        "        tokenizer.save_pretrained('clinicalbert_manual')\n",
        "        print(\"✅ Tokenizer saved\")\n",
        "\n",
        "    # Save additional files\n",
        "    import json\n",
        "\n",
        "    # Save label mappings\n",
        "    if 'id_to_label' in globals():\n",
        "        with open('clinicalbert_manual/id_to_label.json', 'w') as f:\n",
        "            json.dump(id_to_label, f, indent=2)\n",
        "        print(\"✅ Label mappings saved\")\n",
        "\n",
        "    if 'label_to_id' in globals():\n",
        "        with open('clinicalbert_manual/label_to_id.json', 'w') as f:\n",
        "            json.dump(label_to_id, f, indent=2)\n",
        "\n",
        "    # Save training args\n",
        "    if hasattr(trainer, 'args'):\n",
        "        trainer.args.save_to_json('clinicalbert_manual/training_args.json')\n",
        "        print(\"✅ Training arguments saved\")\n",
        "\n",
        "    # Create zip file\n",
        "    print(\"📦 Creating zip file...\")\n",
        "    !zip -rq clinicalbert_model.zip clinicalbert_manual/\n",
        "\n",
        "    if os.path.exists('clinicalbert_model.zip'):\n",
        "        zip_size = os.path.getsize('clinicalbert_model.zip')\n",
        "        zip_size_mb = zip_size / (1024 * 1024)\n",
        "        print(f\"✅ Zip file created: {zip_size_mb:.1f} MB\")\n",
        "\n",
        "        # Download the file\n",
        "        print(\"⬇️ Starting download...\")\n",
        "        files.download('clinicalbert_model.zip')\n",
        "        print(\"✅ Download initiated!\")\n",
        "    else:\n",
        "        print(\"❌ Failed to create zip file\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ No model found to download\")\n",
        "    print(\"\\n🔧 Troubleshooting steps:\")\n",
        "    print(\"1. Make sure your model training completed successfully\")\n",
        "    print(\"2. Check if trainer.save_model() was called\")\n",
        "    print(\"3. Verify the output directory path\")\n",
        "    print(\"4. Try running: trainer.save_model('./clinicalbert_download')\")\n",
        "\n",
        "print(\"\\n📋 What's included in the model zip:\")\n",
        "print(\"✅ Model weights (pytorch_model.bin)\")\n",
        "print(\"✅ Model configuration (config.json)\")\n",
        "print(\"✅ Tokenizer files\")\n",
        "print(\"✅ Label mappings (id_to_label.json)\")\n",
        "print(\"✅ Training arguments\")\n",
        "print(\"\\n🚀 You can load this model later with:\")\n",
        "print(\"   from transformers import AutoModelForTokenClassification, AutoTokenizer\")\n",
        "print(\"   model = AutoModelForTokenClassification.from_pretrained('./path_to_unzipped_model')\")\n",
        "print(\"   tokenizer = AutoTokenizer.from_pretrained('./path_to_unzipped_model')\")"
      ],
      "metadata": {
        "id": "k4DgrozRMtFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7AlfyORz9jrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# BIOBERT TRAINING FOR PHI DETECTION\n",
        "# =========================\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "from collections import Counter, defaultdict\n",
        "from transformers import (AutoTokenizer, AutoModelForTokenClassification,\n",
        "                         TrainingArguments, Trainer, EarlyStoppingCallback)\n",
        "from torch.utils.data import Dataset as TorchDataset\n",
        "from seqeval.metrics import f1_score, precision_score, recall_score\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"🧬 Starting BioBERT Training for PHI Detection\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# -------------------------\n",
        "# 1) Setup and Data Loading (Same as previous)\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"✅ Using device: {device}\")\n",
        "\n",
        "# Load and clean data (reuse previous functions)\n",
        "def load_and_validate_data(filepath):\n",
        "    with open(filepath) as f:\n",
        "        data = json.load(f)\n",
        "    return [entry for entry in data if len(entry[\"tokens\"]) == len(entry[\"labels\"])]\n",
        "\n",
        "def clean_and_normalize_labels(labels):\n",
        "    out = []\n",
        "    for l in labels:\n",
        "        if l in [\"B-AGE\", \"I-AGE\"]:\n",
        "            out.append(\"O\")\n",
        "        elif l in [\"B-DOCTOR\", \"I-DOCTOR\"]:\n",
        "            out.append(l.replace(\"DOCTOR\", \"NAME\"))\n",
        "        elif l in [\"B-PATIENT\", \"I-PATIENT\"]:\n",
        "            out.append(l.replace(\"PATIENT\", \"NAME\"))\n",
        "        else:\n",
        "            out.append(l)\n",
        "    return out\n",
        "\n",
        "# Load data\n",
        "train_data = load_and_validate_data('/content/train.json')\n",
        "val_data = load_and_validate_data('/content/val.json')\n",
        "test_data = load_and_validate_data('/content/test.json')\n",
        "\n",
        "train_tokens = [e[\"tokens\"] for e in train_data]\n",
        "train_labels = [clean_and_normalize_labels(e[\"labels\"]) for e in train_data]\n",
        "val_tokens = [e[\"tokens\"] for e in val_data]\n",
        "val_labels = [clean_and_normalize_labels(e[\"labels\"]) for e in val_data]\n",
        "\n",
        "print(f\"✅ Data loaded - Train: {len(train_tokens)} | Val: {len(val_tokens)}\")\n",
        "\n",
        "# Label setup\n",
        "target_labels = [\n",
        "    \"B-DATE\", \"I-DATE\", \"B-HOSPITAL\", \"I-HOSPITAL\", \"B-ID\", \"I-ID\",\n",
        "    \"B-LOCATION\", \"I-LOCATION\", \"B-NAME\", \"I-NAME\", \"B-PHONE\", \"I-PHONE\", \"O\"\n",
        "]\n",
        "label_to_id = {l: i for i, l in enumerate(target_labels)}\n",
        "id_to_label = {i: l for l, i in label_to_id.items()}\n",
        "\n",
        "# -------------------------\n",
        "# 2) BioBERT-Specific Enhancements\n",
        "# -------------------------\n",
        "def analyze_biobert_suitability(tokens_list, labels_list):\n",
        "    \"\"\"Analyze dataset for BioBERT-specific characteristics\"\"\"\n",
        "    print(\"🔬 Analyzing dataset for BioBERT training...\")\n",
        "\n",
        "    medical_terms = ['patient', 'hospital', 'doctor', 'medical', 'clinic', 'physician',\n",
        "                    'diagnosis', 'treatment', 'medicine', 'therapy', 'surgery']\n",
        "\n",
        "    medical_term_count = 0\n",
        "    total_tokens = 0\n",
        "\n",
        "    for tokens in tokens_list:\n",
        "        for token in tokens:\n",
        "            total_tokens += 1\n",
        "            if any(term in token.lower() for term in medical_terms):\n",
        "                medical_term_count += 1\n",
        "\n",
        "    medical_density = medical_term_count / total_tokens * 100\n",
        "    print(f\"   📊 Medical term density: {medical_density:.2f}%\")\n",
        "    print(f\"   🎯 BioBERT advantage: Biomedical vocabulary pre-training\")\n",
        "\n",
        "    return medical_density\n",
        "\n",
        "medical_density = analyze_biobert_suitability(train_tokens, train_labels)\n",
        "\n",
        "# -------------------------\n",
        "# 3) BioBERT Dataset Class\n",
        "# -------------------------\n",
        "class BioBERTNERDataset(TorchDataset):\n",
        "    def __init__(self, tokens, labels, tokenizer, label_to_id, max_len=256):\n",
        "        self.tokens, self.labels = tokens, labels\n",
        "        self.tok, self.l2id, self.max_len = tokenizer, label_to_id, max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        words, labs = self.tokens[idx], self.labels[idx]\n",
        "\n",
        "        # Ensure consistency\n",
        "        min_len = min(len(words), len(labs))\n",
        "        words = words[:min_len]\n",
        "        labs = labs[:min_len]\n",
        "\n",
        "        # Handle long sequences\n",
        "        if len(words) > self.max_len - 2:\n",
        "            words = words[:self.max_len - 2]\n",
        "            labs = labs[:self.max_len - 2]\n",
        "\n",
        "        # BioBERT tokenization (similar to BERT but with biomedical vocabulary)\n",
        "        enc = self.tok(words, is_split_into_words=True, truncation=True,\n",
        "                       max_length=self.max_len, padding=\"max_length\")\n",
        "\n",
        "        # Align labels with subword tokens\n",
        "        wids = enc.word_ids()\n",
        "        aligned = []\n",
        "        prev_wid = None\n",
        "\n",
        "        for wid in wids:\n",
        "            if wid is None:\n",
        "                aligned.append(-100)\n",
        "            elif wid != prev_wid:\n",
        "                if wid < len(labs):\n",
        "                    label = labs[wid]\n",
        "                    aligned.append(self.l2id.get(label, self.l2id[\"O\"]))\n",
        "                else:\n",
        "                    aligned.append(self.l2id[\"O\"])\n",
        "            else:\n",
        "                aligned.append(-100)\n",
        "            prev_wid = wid\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(enc[\"input_ids\"], dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(enc[\"attention_mask\"], dtype=torch.long),\n",
        "            \"labels\": torch.tensor(aligned, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# -------------------------\n",
        "# 4) BioBERT Training Configuration\n",
        "# -------------------------\n",
        "def calculate_balanced_weights(labels_list):\n",
        "    \"\"\"Calculate balanced class weights for BioBERT\"\"\"\n",
        "    flat_labels = [lbl for seq in labels_list for lbl in seq]\n",
        "    counts = Counter(flat_labels)\n",
        "    total = len(flat_labels)\n",
        "\n",
        "    weights = {}\n",
        "    for label in target_labels:\n",
        "        count = counts.get(label, 1)\n",
        "        if label == \"O\":\n",
        "            weights[label] = 0.5\n",
        "        else:\n",
        "            base_weight = total / (len(target_labels) * count)\n",
        "            weights[label] = min(base_weight * 1.5, 8.0)\n",
        "\n",
        "    return weights\n",
        "\n",
        "# -------------------------\n",
        "# 5) BioBERT Metrics\n",
        "# -------------------------\n",
        "def compute_biobert_metrics(p):\n",
        "    \"\"\"Compute comprehensive metrics for BioBERT\"\"\"\n",
        "    predictions = np.argmax(p.predictions, axis=-1)\n",
        "    labels = p.label_ids\n",
        "\n",
        "    true_labels, pred_labels = [], []\n",
        "\n",
        "    for pred_seq, label_seq in zip(predictions, labels):\n",
        "        true_seq, pred_seq_clean = [], []\n",
        "        for pred, label in zip(pred_seq, label_seq):\n",
        "            if label != -100:\n",
        "                true_seq.append(id_to_label[label])\n",
        "                pred_seq_clean.append(id_to_label[pred])\n",
        "        if true_seq:\n",
        "            true_labels.append(true_seq)\n",
        "            pred_labels.append(pred_seq_clean)\n",
        "\n",
        "    if not true_labels:\n",
        "        return {\"f1\": 0.0, \"precision\": 0.0, \"recall\": 0.0}\n",
        "\n",
        "    f1 = f1_score(true_labels, pred_labels)\n",
        "    precision = precision_score(true_labels, pred_labels)\n",
        "    recall = recall_score(true_labels, pred_labels)\n",
        "\n",
        "    return {\"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
        "\n",
        "# -------------------------\n",
        "# 6) BioBERT Training\n",
        "# -------------------------\n",
        "def train_biobert_model():\n",
        "    \"\"\"Train BioBERT for PHI detection\"\"\"\n",
        "\n",
        "    print(\"\\n🧬 Initializing BioBERT...\")\n",
        "\n",
        "    # Load BioBERT tokenizer and model\n",
        "    model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "\n",
        "    print(f\"✅ BioBERT tokenizer loaded\")\n",
        "    print(f\"   Vocab size: {tokenizer.vocab_size}\")\n",
        "    print(f\"   Model: {model_name}\")\n",
        "\n",
        "    model = AutoModelForTokenClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=len(target_labels),\n",
        "        id2label=id_to_label,\n",
        "        label2id=label_to_id,\n",
        "        hidden_dropout_prob=0.1,\n",
        "        attention_probs_dropout_prob=0.1\n",
        "    )\n",
        "\n",
        "    # Calculate class weights\n",
        "    weight_dict = calculate_balanced_weights(train_labels)\n",
        "    class_weights = torch.tensor([weight_dict[label] for label in target_labels],\n",
        "                               dtype=torch.float).to(device)\n",
        "\n",
        "    print(\"\\n⚖️ BioBERT class weights:\")\n",
        "    for label, weight in zip(target_labels, class_weights.cpu().numpy()):\n",
        "        if \"LOCATION\" in label or \"PHONE\" in label:\n",
        "            print(f\"   🎯 {label}: {weight:.2f}\")\n",
        "        else:\n",
        "            print(f\"   {label}: {weight:.2f}\")\n",
        "\n",
        "    # Create datasets\n",
        "    train_ds = BioBERTNERDataset(train_tokens, train_labels, tokenizer, label_to_id)\n",
        "    val_ds = BioBERTNERDataset(val_tokens, val_labels, tokenizer, label_to_id)\n",
        "\n",
        "    # Training arguments optimized for BioBERT\n",
        "    args = TrainingArguments(\n",
        "        output_dir=\"./outputs/biobert_phi_detection\",\n",
        "        learning_rate=2e-5,                # Standard BERT learning rate\n",
        "        per_device_train_batch_size=4,\n",
        "        gradient_accumulation_steps=4,\n",
        "        per_device_eval_batch_size=8,\n",
        "        num_train_epochs=8,\n",
        "        warmup_ratio=0.1,\n",
        "        lr_scheduler_type=\"cosine_with_restarts\",\n",
        "        weight_decay=0.01,\n",
        "        max_grad_norm=1.0,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"eval_f1\",\n",
        "        greater_is_better=True,\n",
        "        fp16=True,\n",
        "        dataloader_pin_memory=True,\n",
        "        dataloader_num_workers=2,\n",
        "        seed=SEED,\n",
        "        report_to=\"none\",\n",
        "        logging_steps=50,\n",
        "        save_total_limit=3,\n",
        "        eval_accumulation_steps=4,\n",
        "        prediction_loss_only=False\n",
        "    )\n",
        "\n",
        "    # Custom trainer with class weights\n",
        "    class BioBERTTrainer(Trainer):\n",
        "        def __init__(self, class_weights=None, **kwargs):\n",
        "            super().__init__(**kwargs)\n",
        "            self.class_weights = class_weights\n",
        "\n",
        "        def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "            labels = inputs.pop(\"labels\")\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Filter active positions\n",
        "            active_loss = labels.view(-1) != -100\n",
        "            active_logits = logits.view(-1, logits.size(-1))[active_loss]\n",
        "            active_labels = labels.view(-1)[active_loss]\n",
        "\n",
        "            if len(active_labels) == 0:\n",
        "                return torch.tensor(0.0, requires_grad=True, device=logits.device)\n",
        "\n",
        "            # Weighted cross-entropy loss\n",
        "            loss = F.cross_entropy(active_logits, active_labels, weight=self.class_weights)\n",
        "            return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    # Create trainer\n",
        "    trainer = BioBERTTrainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_ds,\n",
        "        eval_dataset=val_ds,\n",
        "        processing_class=tokenizer,\n",
        "        compute_metrics=compute_biobert_metrics,\n",
        "        class_weights=class_weights,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        "    )\n",
        "\n",
        "    print(\"\\n🚀 Starting BioBERT training...\")\n",
        "    print(f\"📊 Configuration:\")\n",
        "    print(f\"   • Model: BioBERT (biomedical pre-trained)\")\n",
        "    print(f\"   • Learning rate: 2e-5\")\n",
        "    print(f\"   • Epochs: 8\")\n",
        "    print(f\"   • Batch size: 4\")\n",
        "    print(f\"   • Medical term density: {medical_density:.2f}%\")\n",
        "\n",
        "    try:\n",
        "        train_results = trainer.train()\n",
        "        trainer.save_model(\"./outputs/biobert_phi_detection\")\n",
        "\n",
        "        print(\"✅ BioBERT training completed successfully!\")\n",
        "\n",
        "        # Final evaluation\n",
        "        eval_results = trainer.evaluate()\n",
        "\n",
        "        print(f\"\\n📈 BioBERT Results:\")\n",
        "        print(f\"   • F1-Score: {eval_results.get('eval_f1', 0):.4f}\")\n",
        "        print(f\"   • Precision: {eval_results.get('eval_precision', 0):.4f}\")\n",
        "        print(f\"   • Recall: {eval_results.get('eval_recall', 0):.4f}\")\n",
        "\n",
        "        # Save results for comparison\n",
        "        biobert_results = {\n",
        "            'model': 'BioBERT',\n",
        "            'model_name': model_name,\n",
        "            'f1': eval_results.get('eval_f1', 0),\n",
        "            'precision': eval_results.get('eval_precision', 0),\n",
        "            'recall': eval_results.get('eval_recall', 0),\n",
        "            'medical_density': medical_density\n",
        "        }\n",
        "\n",
        "        with open('biobert_results.json', 'w') as f:\n",
        "            json.dump(biobert_results, f, indent=2)\n",
        "\n",
        "        print(f\"\\n🧬 BioBERT advantages observed:\")\n",
        "        print(f\"   • Biomedical vocabulary alignment\")\n",
        "        print(f\"   • PubMed/PMC pre-training benefits\")\n",
        "        print(f\"   • Medical terminology understanding\")\n",
        "\n",
        "        return trainer, eval_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ BioBERT training failed: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Run BioBERT training\n",
        "trainer, results = train_biobert_model()\n",
        "\n",
        "print(f\"\\n🎯 BioBERT Training Complete!\")\n",
        "print(f\"📁 Model saved to: ./outputs/biobert_phi_detection\")\n",
        "print(f\"📊 Results saved to: biobert_results.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7060f25e1b534a988ffd3feb2b96308f",
            "cdf2ce0957224045971cf62ffd76d8b4",
            "55a6833c42cd49abb249f26d7683f7ec",
            "f1236f6c75f8496d81bbd8ea1c4b7131",
            "2bb79c52a9e24e019f6d61794486423d",
            "08b1b3acebdd4667bf5f66f822e8da24",
            "79f2001fae29429b939e7cff03bf3777",
            "3af82634ab1042a48ef1d677bdf120b2",
            "0a8a36a9009745e482e6311d09aa4085",
            "94cd8012674d4f538166b0cb7f4b29a7",
            "5d1f3a30c63e4ac7b0f1f86e9f5f5148",
            "3e790ae874bf40c594d11a988e920dae",
            "d4d5e15793e1493bacb3dfd957ad176a",
            "87f567cf1e9d482ebd05796f88d4a0ac",
            "8224f8b43a7d4dd7b1cd1875533e2cde",
            "6d5babb6111e4402a0fc688938ae42b1",
            "d79bdb92ccf840edae1c15d3d11218ac",
            "23b93e545614463ba22d2b1b2a179338",
            "03432e998c7247d1ab2d055d58a77a6f",
            "16d50a0ddff64d70b737d579771302cc",
            "0a2e50fee595402da8bb8d292623d6af",
            "77ab0795b2e748d7970fadb835f1f946",
            "278ab93deb5644e7ab2822d5e6b300c7",
            "8c991996ec7343d9bbe99cdad45f4438",
            "170af0a0ccc7497da7bec26732e9d61e",
            "2dc57a3402ea4658b8a599a192ee3b0c",
            "9293125ce439480cae47e0eecb2b21c9",
            "5262ea7261d445d5802db2972a27e978",
            "44ad21276ce54c09bc4a75d4d1961107",
            "6c0c27b44c5a461eac70744d90ef2bee",
            "a39400d7f5994c1fb356db394f06c7ab",
            "af605a154cbb4883ab6463067960a219",
            "218cee290434448e8920301afad7e555",
            "fd98354f512546309171d00e3a1f7809",
            "1b0c1cffddcb4feba95d5c6525a729e5",
            "de0f1ab282d3420d9781450c1cc32a8a",
            "bcc6c95f8b1d486fac02fa18fc139a44",
            "fbd0a0947cbd4d26b9ebcd292abee8e9",
            "eb0eb6b26d344d639d7d61a4f0424a1c",
            "c3e0dded00224d2e8da43a631b8b75eb",
            "5c925cc3ffc34eb1ade406e18799ec75",
            "d3b1dceac692477480e5b22acf4e0e59",
            "7e969c84cf1e4c21a248f142a1d1d1b0",
            "17e81d64f9e145f5855948020ac24f2a"
          ]
        },
        "id": "TwP9mbmNHa5E",
        "outputId": "ae69236f-3686-4df8-d8bd-9aa5b356fce4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧬 Starting BioBERT Training for PHI Detection\n",
            "============================================================\n",
            "✅ Using device: cuda\n",
            "✅ Data loaded - Train: 669 | Val: 220\n",
            "🔬 Analyzing dataset for BioBERT training...\n",
            "   📊 Medical term density: 2.22%\n",
            "   🎯 BioBERT advantage: Biomedical vocabulary pre-training\n",
            "\n",
            "🧬 Initializing BioBERT...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7060f25e1b534a988ffd3feb2b96308f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e790ae874bf40c594d11a988e920dae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ BioBERT tokenizer loaded\n",
            "   Vocab size: 28996\n",
            "   Model: dmis-lab/biobert-base-cased-v1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "278ab93deb5644e7ab2822d5e6b300c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⚖️ BioBERT class weights:\n",
            "   B-DATE: 8.00\n",
            "   I-DATE: 8.00\n",
            "   B-HOSPITAL: 8.00\n",
            "   I-HOSPITAL: 8.00\n",
            "   B-ID: 8.00\n",
            "   I-ID: 8.00\n",
            "   🎯 B-LOCATION: 8.00\n",
            "   🎯 I-LOCATION: 8.00\n",
            "   B-NAME: 8.00\n",
            "   I-NAME: 8.00\n",
            "   🎯 B-PHONE: 8.00\n",
            "   🎯 I-PHONE: 8.00\n",
            "   O: 0.50\n",
            "\n",
            "🚀 Starting BioBERT training...\n",
            "📊 Configuration:\n",
            "   • Model: BioBERT (biomedical pre-trained)\n",
            "   • Learning rate: 2e-5\n",
            "   • Epochs: 8\n",
            "   • Batch size: 4\n",
            "   • Medical term density: 2.22%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd98354f512546309171d00e3a1f7809"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='336' max='336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [336/336 04:20, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.446588</td>\n",
              "      <td>0.777634</td>\n",
              "      <td>0.737360</td>\n",
              "      <td>0.822562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.443100</td>\n",
              "      <td>0.124913</td>\n",
              "      <td>0.917647</td>\n",
              "      <td>0.889952</td>\n",
              "      <td>0.947121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.129100</td>\n",
              "      <td>0.086421</td>\n",
              "      <td>0.948989</td>\n",
              "      <td>0.933005</td>\n",
              "      <td>0.965531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.040500</td>\n",
              "      <td>0.068307</td>\n",
              "      <td>0.952253</td>\n",
              "      <td>0.936388</td>\n",
              "      <td>0.968664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.021700</td>\n",
              "      <td>0.068188</td>\n",
              "      <td>0.963538</td>\n",
              "      <td>0.954284</td>\n",
              "      <td>0.972973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.014500</td>\n",
              "      <td>0.061473</td>\n",
              "      <td>0.962260</td>\n",
              "      <td>0.951033</td>\n",
              "      <td>0.973756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.014500</td>\n",
              "      <td>0.059301</td>\n",
              "      <td>0.962089</td>\n",
              "      <td>0.950325</td>\n",
              "      <td>0.974148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.012500</td>\n",
              "      <td>0.059626</td>\n",
              "      <td>0.961501</td>\n",
              "      <td>0.949924</td>\n",
              "      <td>0.973365</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ BioBERT training completed successfully!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [28/28 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📈 BioBERT Results:\n",
            "   • F1-Score: 0.9635\n",
            "   • Precision: 0.9543\n",
            "   • Recall: 0.9730\n",
            "\n",
            "🧬 BioBERT advantages observed:\n",
            "   • Biomedical vocabulary alignment\n",
            "   • PubMed/PMC pre-training benefits\n",
            "   • Medical terminology understanding\n",
            "\n",
            "🎯 BioBERT Training Complete!\n",
            "📁 Model saved to: ./outputs/biobert_phi_detection\n",
            "📊 Results saved to: biobert_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# FIXED BioBERT Evaluation Suite\n",
        "# =========================\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import Counter, defaultdict\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# -------------------------\n",
        "# 1) Safe Evaluation Functions (Handle Length Mismatches)\n",
        "# -------------------------\n",
        "def safe_sequence_metrics(true_labels, pred_labels):\n",
        "    \"\"\"Calculate metrics safely handling sequence length mismatches\"\"\"\n",
        "\n",
        "    # Ensure sequences have same length\n",
        "    aligned_true = []\n",
        "    aligned_pred = []\n",
        "\n",
        "    for true_seq, pred_seq in zip(true_labels, pred_labels):\n",
        "        min_len = min(len(true_seq), len(pred_seq))\n",
        "        if min_len > 0:\n",
        "            aligned_true.append(true_seq[:min_len])\n",
        "            aligned_pred.append(pred_seq[:min_len])\n",
        "\n",
        "    if not aligned_true:\n",
        "        return {\"f1\": 0.0, \"precision\": 0.0, \"recall\": 0.0}\n",
        "\n",
        "    # Calculate token-level metrics\n",
        "    all_true_flat = [label for seq in aligned_true for label in seq]\n",
        "    all_pred_flat = [label for seq in aligned_pred for label in seq]\n",
        "\n",
        "    # Entity-level metrics (safer approach)\n",
        "    true_entities = set()\n",
        "    pred_entities = set()\n",
        "\n",
        "    for seq_idx, (true_seq, pred_seq) in enumerate(zip(aligned_true, aligned_pred)):\n",
        "        # Extract entities from true sequence\n",
        "        current_entity = None\n",
        "        entity_start = None\n",
        "\n",
        "        for pos, label in enumerate(true_seq):\n",
        "            if label.startswith('B-'):\n",
        "                if current_entity is not None:\n",
        "                    true_entities.add((seq_idx, entity_start, pos-1, current_entity))\n",
        "                current_entity = label[2:]\n",
        "                entity_start = pos\n",
        "            elif label.startswith('I-') and current_entity is not None:\n",
        "                continue  # Continue current entity\n",
        "            else:  # 'O' or different entity\n",
        "                if current_entity is not None:\n",
        "                    true_entities.add((seq_idx, entity_start, pos-1, current_entity))\n",
        "                current_entity = None\n",
        "                entity_start = None\n",
        "\n",
        "        # Handle entity at end of sequence\n",
        "        if current_entity is not None:\n",
        "            true_entities.add((seq_idx, entity_start, len(true_seq)-1, current_entity))\n",
        "\n",
        "        # Extract entities from predicted sequence\n",
        "        current_entity = None\n",
        "        entity_start = None\n",
        "\n",
        "        for pos, label in enumerate(pred_seq):\n",
        "            if label.startswith('B-'):\n",
        "                if current_entity is not None:\n",
        "                    pred_entities.add((seq_idx, entity_start, pos-1, current_entity))\n",
        "                current_entity = label[2:]\n",
        "                entity_start = pos\n",
        "            elif label.startswith('I-') and current_entity is not None:\n",
        "                continue\n",
        "            else:\n",
        "                if current_entity is not None:\n",
        "                    pred_entities.add((seq_idx, entity_start, pos-1, current_entity))\n",
        "                current_entity = None\n",
        "                entity_start = None\n",
        "\n",
        "        if current_entity is not None:\n",
        "            pred_entities.add((seq_idx, entity_start, len(pred_seq)-1, current_entity))\n",
        "\n",
        "    # Calculate metrics\n",
        "    tp = len(true_entities & pred_entities)\n",
        "    fp = len(pred_entities - true_entities)\n",
        "    fn = len(true_entities - pred_entities)\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    return {\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"true_entities\": len(true_entities),\n",
        "        \"pred_entities\": len(pred_entities),\n",
        "        \"tp\": tp,\n",
        "        \"fp\": fp,\n",
        "        \"fn\": fn\n",
        "    }\n",
        "\n",
        "# -------------------------\n",
        "# 2) Fixed Prediction Function\n",
        "# -------------------------\n",
        "def predict_entities_fixed(tokens_list, model, tokenizer, max_len=256):\n",
        "    \"\"\"Generate predictions with better alignment\"\"\"\n",
        "    predictions = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for tokens in tokens_list:\n",
        "            try:\n",
        "                # Limit sequence length\n",
        "                if len(tokens) > max_len - 2:\n",
        "                    tokens = tokens[:max_len - 2]\n",
        "\n",
        "                # Tokenize\n",
        "                encoding = tokenizer(\n",
        "                    tokens,\n",
        "                    is_split_into_words=True,\n",
        "                    truncation=True,\n",
        "                    max_length=max_len,\n",
        "                    padding=\"max_length\",\n",
        "                    return_tensors=\"pt\"\n",
        "                )\n",
        "\n",
        "                # Get word IDs for alignment\n",
        "                word_ids = encoding.word_ids()\n",
        "\n",
        "                # Move to device\n",
        "                device = next(model.parameters()).device\n",
        "                encoding = {k: v.to(device) for k, v in encoding.items()}\n",
        "\n",
        "                # Predict\n",
        "                outputs = model(**encoding)\n",
        "                logits = outputs.logits\n",
        "                preds = torch.argmax(logits, dim=-1).cpu().numpy()[0]\n",
        "\n",
        "                # Align predictions with original tokens\n",
        "                aligned_preds = []\n",
        "                prev_word_id = None\n",
        "\n",
        "                for i, word_id in enumerate(word_ids):\n",
        "                    if word_id is None:\n",
        "                        continue  # Skip special tokens\n",
        "                    elif word_id != prev_word_id:\n",
        "                        # First subword of a word\n",
        "                        if word_id < len(tokens):\n",
        "                            pred_id = preds[i]\n",
        "                            pred_label = id_to_label.get(pred_id, \"O\")\n",
        "                            aligned_preds.append(pred_label)\n",
        "                    prev_word_id = word_id\n",
        "\n",
        "                # Ensure same length as input tokens\n",
        "                while len(aligned_preds) < len(tokens):\n",
        "                    aligned_preds.append(\"O\")\n",
        "                aligned_preds = aligned_preds[:len(tokens)]\n",
        "\n",
        "                predictions.append(aligned_preds)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing sequence: {e}\")\n",
        "                # Fallback: all O labels\n",
        "                predictions.append([\"O\"] * len(tokens))\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# -------------------------\n",
        "# 3) Load Model and Data\n",
        "# -------------------------\n",
        "print(\"🧬 Loading BioBERT trained model and tokenizer...\")\n",
        "\n",
        "# Try multiple possible BioBERT model paths\n",
        "possible_paths = [\n",
        "    \"./outputs/biobert_phi_detection\",\n",
        "    \"/content/outputs/biobert_phi_detection\",\n",
        "    \"./biobert_phi_detection\",\n",
        "    \"/content/biobert_phi_detection\"\n",
        "]\n",
        "\n",
        "model = None\n",
        "model_path = None\n",
        "\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\", use_fast=True)\n",
        "    print(\"✅ BioBERT tokenizer loaded\")\n",
        "\n",
        "    # Try to find the model\n",
        "    for path in possible_paths:\n",
        "        try:\n",
        "            print(f\"🔍 Trying to load BioBERT model from: {path}\")\n",
        "            model = AutoModelForTokenClassification.from_pretrained(path)\n",
        "            model_path = path\n",
        "            print(f\"✅ BioBERT model loaded from: {path}\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to load from {path}: {str(e)[:50]}...\")\n",
        "            continue\n",
        "\n",
        "    if model is None:\n",
        "        print(\"❌ Could not find trained BioBERT model. Please check if training completed successfully.\")\n",
        "        print(\"💡 Available files in current directory:\")\n",
        "        import os\n",
        "        if os.path.exists(\"outputs\"):\n",
        "            print(f\"   outputs/ contents: {os.listdir('outputs')}\")\n",
        "        else:\n",
        "            print(\"   No outputs/ directory found\")\n",
        "        exit()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"✅ BioBERT model ready on {device}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading BioBERT model: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Load data\n",
        "try:\n",
        "    with open('/content/test.json') as f:\n",
        "        test_data = json.load(f)\n",
        "    test_tokens = [entry[\"tokens\"] for entry in test_data]\n",
        "\n",
        "    with open('/content/val.json') as f:\n",
        "        gt_data = json.load(f)\n",
        "    gt_tokens = [entry[\"tokens\"] for entry in gt_data]\n",
        "    gt_labels = [entry[\"labels\"] for entry in gt_data]\n",
        "\n",
        "    print(f\"✅ Data loaded: Test={len(test_tokens)}, GT={len(gt_tokens)} samples\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading data: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Clean labels (same as training)\n",
        "def clean_and_normalize_labels(labels):\n",
        "    out = []\n",
        "    for l in labels:\n",
        "        if l in [\"B-AGE\", \"I-AGE\"]:\n",
        "            out.append(\"O\")\n",
        "        elif l in [\"B-DOCTOR\", \"I-DOCTOR\"]:\n",
        "            out.append(l.replace(\"DOCTOR\", \"NAME\"))\n",
        "        elif l in [\"B-PATIENT\", \"I-PATIENT\"]:\n",
        "            out.append(l.replace(\"PATIENT\", \"NAME\"))\n",
        "        else:\n",
        "            out.append(l)\n",
        "    return out\n",
        "\n",
        "gt_labels_clean = [clean_and_normalize_labels(labels) for labels in gt_labels]\n",
        "\n",
        "# Label mappings\n",
        "target_labels = [\n",
        "    \"B-DATE\", \"I-DATE\", \"B-HOSPITAL\", \"I-HOSPITAL\", \"B-ID\", \"I-ID\",\n",
        "    \"B-LOCATION\", \"I-LOCATION\", \"B-NAME\", \"I-NAME\", \"B-PHONE\", \"I-PHONE\", \"O\"\n",
        "]\n",
        "label_to_id = {l: i for i, l in enumerate(target_labels)}\n",
        "id_to_label = {i: l for l, i in label_to_id.items()}\n",
        "\n",
        "# -------------------------\n",
        "# 4) Generate Predictions with Fixed Function\n",
        "# -------------------------\n",
        "print(\"🔄 Generating BioBERT predictions...\")\n",
        "gt_predictions = predict_entities_fixed(gt_tokens, model, tokenizer)\n",
        "print(f\"✅ Generated predictions for {len(gt_predictions)} samples\")\n",
        "\n",
        "# -------------------------\n",
        "# 5) Safe Evaluation\n",
        "# -------------------------\n",
        "print(\"🔄 Evaluating BioBERT predictions...\")\n",
        "evaluation_results = safe_sequence_metrics(gt_labels_clean, gt_predictions)\n",
        "\n",
        "# Per-entity evaluation\n",
        "entity_metrics = {}\n",
        "entities = [\"DATE\", \"HOSPITAL\", \"ID\", \"LOCATION\", \"NAME\", \"PHONE\"]\n",
        "\n",
        "for entity in entities:\n",
        "    # Filter sequences for this entity\n",
        "    entity_true = []\n",
        "    entity_pred = []\n",
        "\n",
        "    for true_seq, pred_seq in zip(gt_labels_clean, gt_predictions):\n",
        "        et = [label if entity in label else 'O' for label in true_seq]\n",
        "        ep = [label if entity in label else 'O' for label in pred_seq]\n",
        "        entity_true.append(et)\n",
        "        entity_pred.append(ep)\n",
        "\n",
        "    entity_result = safe_sequence_metrics(entity_true, entity_pred)\n",
        "    entity_metrics[entity] = {\n",
        "        'f1': entity_result['f1'],\n",
        "        'precision': entity_result['precision'],\n",
        "        'recall': entity_result['recall']\n",
        "    }\n",
        "\n",
        "# -------------------------\n",
        "# 6) Save Results\n",
        "# -------------------------\n",
        "results_data = {\n",
        "    'model_path': model_path,\n",
        "    'model_type': 'BioBERT',\n",
        "    'base_model': 'dmis-lab/biobert-base-cased-v1.1',\n",
        "    'test_samples': len(gt_tokens),\n",
        "    'overall_metrics': {\n",
        "        'f1': evaluation_results['f1'],\n",
        "        'precision': evaluation_results['precision'],\n",
        "        'recall': evaluation_results['recall']\n",
        "    },\n",
        "    'entity_metrics': entity_metrics,\n",
        "    'detailed_stats': {\n",
        "        'true_entities': evaluation_results['true_entities'],\n",
        "        'pred_entities': evaluation_results['pred_entities'],\n",
        "        'tp': evaluation_results['tp'],\n",
        "        'fp': evaluation_results['fp'],\n",
        "        'fn': evaluation_results['fn']\n",
        "    },\n",
        "    'predictions': gt_predictions,\n",
        "    'true_labels': gt_labels_clean,\n",
        "    'tokens': gt_tokens\n",
        "}\n",
        "\n",
        "# Save results\n",
        "with open('biobert_evaluation_results.json', 'w') as f:\n",
        "    json.dump(results_data, f, indent=2)\n",
        "\n",
        "# Create entity DataFrame\n",
        "entity_df = pd.DataFrame(entity_metrics).T\n",
        "entity_df.to_csv('biobert_entity_performance.csv')\n",
        "\n",
        "print(\"✅ BioBERT results saved successfully!\")\n",
        "\n",
        "# -------------------------\n",
        "# 7) Print Summary\n",
        "# -------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🧬 BIOBERT EVALUATION RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n📊 Overall Performance:\")\n",
        "print(f\"   • F1-Score:  {evaluation_results['f1']:.4f}\")\n",
        "print(f\"   • Precision: {evaluation_results['precision']:.4f}\")\n",
        "print(f\"   • Recall:    {evaluation_results['recall']:.4f}\")\n",
        "\n",
        "print(f\"\\n📈 Entity Counts:\")\n",
        "print(f\"   • True entities found: {evaluation_results['true_entities']}\")\n",
        "print(f\"   • Predicted entities: {evaluation_results['pred_entities']}\")\n",
        "print(f\"   • True Positives: {evaluation_results['tp']}\")\n",
        "print(f\"   • False Positives: {evaluation_results['fp']}\")\n",
        "print(f\"   • False Negatives: {evaluation_results['fn']}\")\n",
        "\n",
        "print(f\"\\n🎯 Entity-Level Performance:\")\n",
        "for entity, metrics in entity_metrics.items():\n",
        "    print(f\"   • {entity:10s}: F1={metrics['f1']:.3f}, P={metrics['precision']:.3f}, R={metrics['recall']:.3f}\")\n",
        "\n",
        "print(f\"\\n🧬 BioBERT Model Information:\")\n",
        "print(f\"   • Base Model: dmis-lab/biobert-base-cased-v1.1\")\n",
        "print(f\"   • Domain: Biomedical Literature (PubMed + PMC)\")\n",
        "print(f\"   • Specialization: Medical terminology understanding\")\n",
        "print(f\"   • Model Path: {model_path}\")\n",
        "\n",
        "print(f\"\\n✅ BioBERT evaluation completed successfully!\")\n",
        "print(f\"📁 Files saved:\")\n",
        "print(f\"   • biobert_evaluation_results.json\")\n",
        "print(f\"   • biobert_entity_performance.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpNqtcTXJD78",
        "outputId": "cfaff5da-7863-4454-baed-9705a6de9e88"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧬 Loading BioBERT trained model and tokenizer...\n",
            "✅ BioBERT tokenizer loaded\n",
            "🔍 Trying to load BioBERT model from: ./outputs/biobert_phi_detection\n",
            "✅ BioBERT model loaded from: ./outputs/biobert_phi_detection\n",
            "✅ BioBERT model ready on cuda\n",
            "✅ Data loaded: Test=220, GT=220 samples\n",
            "🔄 Generating BioBERT predictions...\n",
            "✅ Generated predictions for 220 samples\n",
            "🔄 Evaluating BioBERT predictions...\n",
            "✅ BioBERT results saved successfully!\n",
            "\n",
            "============================================================\n",
            "🧬 BIOBERT EVALUATION RESULTS\n",
            "============================================================\n",
            "\n",
            "📊 Overall Performance:\n",
            "   • F1-Score:  0.9042\n",
            "   • Precision: 0.9601\n",
            "   • Recall:    0.8544\n",
            "\n",
            "📈 Entity Counts:\n",
            "   • True entities found: 2899\n",
            "   • Predicted entities: 2580\n",
            "   • True Positives: 2477\n",
            "   • False Positives: 103\n",
            "   • False Negatives: 422\n",
            "\n",
            "🎯 Entity-Level Performance:\n",
            "   • DATE      : F1=0.900, P=0.971, R=0.839\n",
            "   • HOSPITAL  : F1=0.861, P=0.919, R=0.811\n",
            "   • ID        : F1=0.983, P=0.995, R=0.972\n",
            "   • LOCATION  : F1=0.240, P=0.462, R=0.162\n",
            "   • NAME      : F1=0.787, P=0.882, R=0.711\n",
            "   • PHONE     : F1=0.875, P=1.000, R=0.778\n",
            "\n",
            "🧬 BioBERT Model Information:\n",
            "   • Base Model: dmis-lab/biobert-base-cased-v1.1\n",
            "   • Domain: Biomedical Literature (PubMed + PMC)\n",
            "   • Specialization: Medical terminology understanding\n",
            "   • Model Path: ./outputs/biobert_phi_detection\n",
            "\n",
            "✅ BioBERT evaluation completed successfully!\n",
            "📁 Files saved:\n",
            "   • biobert_evaluation_results.json\n",
            "   • biobert_entity_performance.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# BIOBERT PHI DETECTION MODEL DOWNLOAD\n",
        "# ===========================\n",
        "\n",
        "import os\n",
        "import json\n",
        "from google.colab import files\n",
        "\n",
        "print(\"🧬 Preparing BioBERT PHI Detection model for download...\")\n",
        "\n",
        "# Check what files exist in the outputs directory\n",
        "if os.path.exists('./outputs'):\n",
        "    print(\"✅ Found outputs directory\")\n",
        "\n",
        "    # List contents of outputs directory\n",
        "    print(\"\\n📂 Contents of ./outputs/:\")\n",
        "    for root, dirs, files_list in os.walk('./outputs'):\n",
        "        level = root.replace('./outputs', '').count(os.sep)\n",
        "        indent = ' ' * 2 * level\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        subindent = ' ' * 2 * (level + 1)\n",
        "        for file in files_list:\n",
        "            file_size = os.path.getsize(os.path.join(root, file))\n",
        "            file_size_mb = file_size / (1024 * 1024)\n",
        "            print(f\"{subindent}{file} ({file_size_mb:.1f} MB)\")\n",
        "else:\n",
        "    print(\"❌ outputs directory not found\")\n",
        "\n",
        "    # Check for alternative locations\n",
        "    print(\"\\n🔍 Checking alternative model save locations...\")\n",
        "\n",
        "    # Check current directory for biobert files\n",
        "    current_files = [f for f in os.listdir('.') if 'biobert' in f.lower() or 'model' in f.lower()]\n",
        "    if current_files:\n",
        "        print(f\"✅ Found model files in current directory: {current_files}\")\n",
        "\n",
        "    # Check if trainer saved model elsewhere\n",
        "    if 'trainer' in globals():\n",
        "        print(f\"✅ Trainer output directory: {trainer.args.output_dir}\")\n",
        "        if os.path.exists(trainer.args.output_dir):\n",
        "            print(\"✅ Trainer output directory exists\")\n",
        "        else:\n",
        "            print(\"❌ Trainer output directory not found\")\n",
        "\n",
        "# Method 1: Try BioBERT specific path\n",
        "if os.path.exists('./outputs/biobert_phi_detection'):\n",
        "    print(\"\\n📦 Creating zip file from ./outputs/biobert_phi_detection...\")\n",
        "    !zip -rq biobert_phi_detection_model.zip ./outputs/biobert_phi_detection\n",
        "\n",
        "    if os.path.exists('biobert_phi_detection_model.zip'):\n",
        "        print(\"✅ BioBERT zip file created successfully\")\n",
        "\n",
        "        # Check zip file size\n",
        "        zip_size = os.path.getsize('biobert_phi_detection_model.zip')\n",
        "        zip_size_mb = zip_size / (1024 * 1024)\n",
        "        print(f\"📦 Zip file size: {zip_size_mb:.1f} MB\")\n",
        "\n",
        "        # Download the file\n",
        "        print(\"⬇️ Starting BioBERT model download...\")\n",
        "        files.download('biobert_phi_detection_model.zip')\n",
        "        print(\"✅ BioBERT download initiated!\")\n",
        "    else:\n",
        "        print(\"❌ Failed to create BioBERT zip file\")\n",
        "\n",
        "# Method 2: Try trainer output directory\n",
        "elif 'trainer' in globals() and os.path.exists(trainer.args.output_dir):\n",
        "    print(f\"\\n📦 Creating zip file from trainer output: {trainer.args.output_dir}\")\n",
        "    !zip -rq biobert_phi_detection_model.zip {trainer.args.output_dir}\n",
        "\n",
        "    if os.path.exists('biobert_phi_detection_model.zip'):\n",
        "        print(\"✅ BioBERT zip file created successfully\")\n",
        "\n",
        "        # Check zip file size\n",
        "        zip_size = os.path.getsize('biobert_phi_detection_model.zip')\n",
        "        zip_size_mb = zip_size / (1024 * 1024)\n",
        "        print(f\"📦 Zip file size: {zip_size_mb:.1f} MB\")\n",
        "\n",
        "        # Download the file\n",
        "        print(\"⬇️ Starting BioBERT model download...\")\n",
        "        files.download('biobert_phi_detection_model.zip')\n",
        "        print(\"✅ BioBERT download initiated!\")\n",
        "    else:\n",
        "        print(\"❌ Failed to create BioBERT zip file\")\n",
        "\n",
        "# Method 3: Manual save if trainer exists\n",
        "elif 'trainer' in globals():\n",
        "    print(\"\\n💾 Manually saving BioBERT model files...\")\n",
        "\n",
        "    # Create a directory for the BioBERT model\n",
        "    os.makedirs('biobert_phi_detection_manual', exist_ok=True)\n",
        "\n",
        "    # Save the model and tokenizer\n",
        "    trainer.save_model('biobert_phi_detection_manual')\n",
        "    print(\"✅ BioBERT model saved\")\n",
        "\n",
        "    if 'tokenizer' in globals():\n",
        "        tokenizer.save_pretrained('biobert_phi_detection_manual')\n",
        "        print(\"✅ BioBERT tokenizer saved\")\n",
        "\n",
        "    # Save BioBERT-specific files\n",
        "\n",
        "    # Save label mappings\n",
        "    if 'id_to_label' in globals():\n",
        "        with open('biobert_phi_detection_manual/id_to_label.json', 'w') as f:\n",
        "            json.dump(id_to_label, f, indent=2)\n",
        "        print(\"✅ PHI label mappings saved\")\n",
        "\n",
        "    if 'label_to_id' in globals():\n",
        "        with open('biobert_phi_detection_manual/label_to_id.json', 'w') as f:\n",
        "            json.dump(label_to_id, f, indent=2)\n",
        "\n",
        "    # Save target labels for PHI detection\n",
        "    if 'target_labels' in globals():\n",
        "        with open('biobert_phi_detection_manual/target_labels.json', 'w') as f:\n",
        "            json.dump(target_labels, f, indent=2)\n",
        "        print(\"✅ PHI target labels saved\")\n",
        "\n",
        "    # Save training arguments\n",
        "    if hasattr(trainer, 'args'):\n",
        "        trainer.args.save_to_json('biobert_phi_detection_manual/training_args.json')\n",
        "        print(\"✅ BioBERT training arguments saved\")\n",
        "\n",
        "    # Save BioBERT results if available\n",
        "    if os.path.exists('biobert_results.json'):\n",
        "        !cp biobert_results.json biobert_phi_detection_manual/\n",
        "        print(\"✅ BioBERT training results saved\")\n",
        "\n",
        "    # Save model info and usage instructions\n",
        "    model_info = {\n",
        "        \"model_name\": \"BioBERT PHI Detection\",\n",
        "        \"base_model\": \"dmis-lab/biobert-base-cased-v1.1\",\n",
        "        \"task\": \"Named Entity Recognition (NER) for PHI Detection\",\n",
        "        \"target_entities\": [\n",
        "            \"DATE\", \"HOSPITAL\", \"ID\", \"LOCATION\", \"NAME\", \"PHONE\"\n",
        "        ],\n",
        "        \"medical_term_density\": globals().get('medical_density', 'N/A'),\n",
        "        \"training_config\": {\n",
        "            \"learning_rate\": \"2e-5\",\n",
        "            \"epochs\": 8,\n",
        "            \"batch_size\": 4,\n",
        "            \"model_type\": \"BioBERT (biomedical pre-trained)\"\n",
        "        },\n",
        "        \"usage_instructions\": {\n",
        "            \"load_model\": \"AutoModelForTokenClassification.from_pretrained('./biobert_phi_detection')\",\n",
        "            \"load_tokenizer\": \"AutoTokenizer.from_pretrained('./biobert_phi_detection')\",\n",
        "            \"preprocessing\": \"Use is_split_into_words=True for tokenization\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open('biobert_phi_detection_manual/model_info.json', 'w') as f:\n",
        "        json.dump(model_info, f, indent=2)\n",
        "    print(\"✅ BioBERT model info saved\")\n",
        "\n",
        "    # Create README file\n",
        "    readme_content = \"\"\"# BioBERT PHI Detection Model\n",
        "\n",
        "## Overview\n",
        "This is a fine-tuned BioBERT model for detecting Protected Health Information (PHI) in medical texts.\n",
        "\n",
        "## Base Model\n",
        "- **Model**: dmis-lab/biobert-base-cased-v1.1\n",
        "- **Type**: BERT-based model pre-trained on biomedical texts (PubMed and PMC)\n",
        "- **Task**: Named Entity Recognition (NER)\n",
        "\n",
        "## Detected PHI Types\n",
        "- **DATE**: Dates and temporal information\n",
        "- **HOSPITAL**: Hospital and healthcare facility names\n",
        "- **ID**: Patient/medical identifiers\n",
        "- **LOCATION**: Geographic locations\n",
        "- **NAME**: Person names (patients, doctors)\n",
        "- **PHONE**: Phone numbers\n",
        "\n",
        "## Usage\n",
        "\n",
        "```python\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import torch\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = AutoModelForTokenClassification.from_pretrained('./biobert_phi_detection')\n",
        "tokenizer = AutoTokenizer.from_pretrained('./biobert_phi_detection')\n",
        "\n",
        "# Example usage\n",
        "text = [\"Patient\", \"John\", \"Smith\", \"visited\", \"City\", \"Hospital\"]\n",
        "inputs = tokenizer(text, is_split_into_words=True, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "# Load label mappings\n",
        "import json\n",
        "with open('./biobert_phi_detection/id_to_label.json') as f:\n",
        "    id_to_label = json.load(f)\n",
        "\n",
        "# Convert predictions to labels\n",
        "pred_labels = [id_to_label[str(pred.item())] for pred in predictions[0]]\n",
        "```\n",
        "\n",
        "## Model Performance\n",
        "Check `biobert_results.json` for detailed performance metrics.\n",
        "\n",
        "## BioBERT Advantages\n",
        "- Pre-trained on biomedical literature (PubMed/PMC)\n",
        "- Better understanding of medical terminology\n",
        "- Optimized for healthcare text processing\n",
        "\"\"\"\n",
        "\n",
        "    with open('biobert_phi_detection_manual/README.md', 'w') as f:\n",
        "        f.write(readme_content)\n",
        "    print(\"✅ README file created\")\n",
        "\n",
        "    # Create zip file\n",
        "    print(\"📦 Creating BioBERT model zip file...\")\n",
        "    !zip -rq biobert_phi_detection_model.zip biobert_phi_detection_manual/\n",
        "\n",
        "    if os.path.exists('biobert_phi_detection_model.zip'):\n",
        "        zip_size = os.path.getsize('biobert_phi_detection_model.zip')\n",
        "        zip_size_mb = zip_size / (1024 * 1024)\n",
        "        print(f\"✅ BioBERT zip file created: {zip_size_mb:.1f} MB\")\n",
        "\n",
        "        # Download the file\n",
        "        print(\"⬇️ Starting BioBERT model download...\")\n",
        "        files.download('biobert_phi_detection_model.zip')\n",
        "        print(\"✅ BioBERT download initiated!\")\n",
        "    else:\n",
        "        print(\"❌ Failed to create BioBERT zip file\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ No BioBERT model found to download\")\n",
        "    print(\"\\n🔧 BioBERT Troubleshooting steps:\")\n",
        "    print(\"1. Make sure your BioBERT training completed successfully\")\n",
        "    print(\"2. Check if trainer.save_model() was called\")\n",
        "    print(\"3. Verify the output directory path: './outputs/biobert_phi_detection'\")\n",
        "    print(\"4. Try running: trainer.save_model('./biobert_phi_detection_download')\")\n",
        "\n",
        "print(\"\\n📋 What's included in the BioBERT model zip:\")\n",
        "print(\"🧬 BioBERT model weights (pytorch_model.bin)\")\n",
        "print(\"🧬 BioBERT configuration (config.json)\")\n",
        "print(\"🧬 BioBERT tokenizer files (vocab.txt, tokenizer.json, etc.)\")\n",
        "print(\"🧬 PHI label mappings (id_to_label.json, label_to_id.json)\")\n",
        "print(\"🧬 Target PHI labels (target_labels.json)\")\n",
        "print(\"🧬 Training arguments and results\")\n",
        "print(\"🧬 Model information and usage guide\")\n",
        "print(\"🧬 README with setup instructions\")\n",
        "\n",
        "print(\"\\n🚀 Load your BioBERT PHI Detection model later with:\")\n",
        "print(\"   from transformers import AutoModelForTokenClassification, AutoTokenizer\")\n",
        "print(\"   model = AutoModelForTokenClassification.from_pretrained('./biobert_phi_detection')\")\n",
        "print(\"   tokenizer = AutoTokenizer.from_pretrained('./biobert_phi_detection')\")\n",
        "\n",
        "print(\"\\n🧬 BioBERT Advantages:\")\n",
        "print(\"   ✅ Pre-trained on PubMed and PMC biomedical literature\")\n",
        "print(\"   ✅ Superior performance on medical text understanding\")\n",
        "print(\"   ✅ Optimized vocabulary for healthcare terminology\")\n",
        "print(\"   ✅ Better PHI detection in clinical contexts\")\n",
        "\n",
        "# Clean up temporary files\n",
        "print(\"\\n🧹 Cleaning up temporary files...\")\n",
        "if os.path.exists('biobert_phi_detection_manual'):\n",
        "    !rm -rf biobert_phi_detection_manual\n",
        "    print(\"✅ Temporary directory cleaned\")\n",
        "\n",
        "print(\"\\n✅ BioBERT PHI Detection model download complete!\")"
      ],
      "metadata": {
        "id": "K17c67sDHYJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eLh0FJYiZCud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROBERTA training\n"
      ],
      "metadata": {
        "id": "gQ251AuRZDTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# ROBERTA-LARGE TRAINING FOR PHI DETECTION - FIXED\n",
        "# =========================\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "from collections import Counter, defaultdict\n",
        "from transformers import (AutoTokenizer, AutoModelForTokenClassification,\n",
        "                         TrainingArguments, Trainer, EarlyStoppingCallback)\n",
        "from torch.utils.data import Dataset as TorchDataset\n",
        "from seqeval.metrics import f1_score, precision_score, recall_score\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"🤖 Starting RoBERTa-Large Training for PHI Detection (Fixed)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# -------------------------\n",
        "# 1) Setup and Configuration\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"✅ Using device: {device}\")\n",
        "\n",
        "# Memory check\n",
        "def check_gpu_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        total_memory = torch.cuda.get_device_properties(0).total_memory // 1024**3\n",
        "        print(f\"🧠 GPU Memory: {total_memory}GB\")\n",
        "        return total_memory\n",
        "    return 0\n",
        "\n",
        "gpu_memory = check_gpu_memory()\n",
        "\n",
        "# Data loading functions\n",
        "def load_and_validate_data(filepath):\n",
        "    with open(filepath) as f:\n",
        "        data = json.load(f)\n",
        "    return [entry for entry in data if len(entry[\"tokens\"]) == len(entry[\"labels\"])]\n",
        "\n",
        "def clean_and_normalize_labels(labels):\n",
        "    out = []\n",
        "    for l in labels:\n",
        "        if l in [\"B-AGE\", \"I-AGE\"]:\n",
        "            out.append(\"O\")\n",
        "        elif l in [\"B-DOCTOR\", \"I-DOCTOR\"]:\n",
        "            out.append(l.replace(\"DOCTOR\", \"NAME\"))\n",
        "        elif l in [\"B-PATIENT\", \"I-PATIENT\"]:\n",
        "            out.append(l.replace(\"PATIENT\", \"NAME\"))\n",
        "        else:\n",
        "            out.append(l)\n",
        "    return out\n",
        "\n",
        "# Load data\n",
        "train_data = load_and_validate_data('/content/train.json')\n",
        "val_data = load_and_validate_data('/content/val.json')\n",
        "\n",
        "train_tokens = [e[\"tokens\"] for e in train_data]\n",
        "train_labels = [clean_and_normalize_labels(e[\"labels\"]) for e in train_data]\n",
        "val_tokens = [e[\"tokens\"] for e in val_data]\n",
        "val_labels = [clean_and_normalize_labels(e[\"labels\"]) for e in val_data]\n",
        "\n",
        "print(f\"✅ Data loaded - Train: {len(train_tokens)} | Val: {len(val_tokens)}\")\n",
        "\n",
        "# Label setup\n",
        "target_labels = [\n",
        "    \"B-DATE\", \"I-DATE\", \"B-HOSPITAL\", \"I-HOSPITAL\", \"B-ID\", \"I-ID\",\n",
        "    \"B-LOCATION\", \"I-LOCATION\", \"B-NAME\", \"I-NAME\", \"B-PHONE\", \"I-PHONE\", \"O\"\n",
        "]\n",
        "label_to_id = {l: i for i, l in enumerate(target_labels)}\n",
        "id_to_label = {i: l for l, i in label_to_id.items()}\n",
        "\n",
        "print(f\"📋 Target labels: {len(target_labels)} classes\")\n",
        "\n",
        "# -------------------------\n",
        "# 2) Fixed RoBERTa Dataset Class\n",
        "# -------------------------\n",
        "class RoBERTaNERDataset(TorchDataset):\n",
        "    def __init__(self, tokens, labels, tokenizer, label_to_id, max_len=256):\n",
        "        self.tokens = tokens\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label_to_id = label_to_id\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        words = self.tokens[idx]\n",
        "        labs = self.labels[idx]\n",
        "\n",
        "        # Ensure consistency\n",
        "        min_len = min(len(words), len(labs))\n",
        "        words = words[:min_len]\n",
        "        labs = labs[:min_len]\n",
        "\n",
        "        # Handle long sequences\n",
        "        if len(words) > self.max_len - 2:\n",
        "            words = words[:self.max_len - 2]\n",
        "            labs = labs[:self.max_len - 2]\n",
        "\n",
        "        # Tokenize with RoBERTa (add_prefix_space handled in tokenizer init)\n",
        "        encoding = self.tokenizer(\n",
        "            words,\n",
        "            is_split_into_words=True,\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Get word IDs for label alignment\n",
        "        word_ids = encoding.word_ids()\n",
        "\n",
        "        # Align labels\n",
        "        aligned_labels = []\n",
        "        prev_word_id = None\n",
        "\n",
        "        for word_id in word_ids:\n",
        "            if word_id is None:\n",
        "                aligned_labels.append(-100)  # Special tokens\n",
        "            elif word_id != prev_word_id:\n",
        "                if word_id < len(labs):\n",
        "                    label = labs[word_id]\n",
        "                    aligned_labels.append(self.label_to_id.get(label, self.label_to_id[\"O\"]))\n",
        "                else:\n",
        "                    aligned_labels.append(self.label_to_id[\"O\"])\n",
        "            else:\n",
        "                aligned_labels.append(-100)  # Subword continuation\n",
        "            prev_word_id = word_id\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": torch.tensor(aligned_labels, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# -------------------------\n",
        "# 3) Calculate Class Weights\n",
        "# -------------------------\n",
        "def calculate_class_weights(labels_list):\n",
        "    \"\"\"Calculate balanced class weights\"\"\"\n",
        "    flat_labels = [lbl for seq in labels_list for lbl in seq]\n",
        "    counts = Counter(flat_labels)\n",
        "    total = len(flat_labels)\n",
        "\n",
        "    weights = {}\n",
        "    for label in target_labels:\n",
        "        count = counts.get(label, 1)\n",
        "        if label == \"O\":\n",
        "            weights[label] = 0.5  # Lower weight for O class\n",
        "        else:\n",
        "            base_weight = total / (len(target_labels) * count)\n",
        "            weights[label] = min(base_weight * 1.5, 8.0)  # Cap weights\n",
        "\n",
        "    return weights\n",
        "\n",
        "# -------------------------\n",
        "# 4) Metrics Function\n",
        "# -------------------------\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute F1, precision, recall\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=-1)\n",
        "\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "\n",
        "    for pred_seq, label_seq in zip(predictions, labels):\n",
        "        true_seq = []\n",
        "        pred_seq_clean = []\n",
        "\n",
        "        for pred, label in zip(pred_seq, label_seq):\n",
        "            if label != -100:\n",
        "                true_seq.append(id_to_label[label])\n",
        "                pred_seq_clean.append(id_to_label[pred])\n",
        "\n",
        "        if true_seq:\n",
        "            true_labels.append(true_seq)\n",
        "            pred_labels.append(pred_seq_clean)\n",
        "\n",
        "    if not true_labels:\n",
        "        return {\"f1\": 0.0, \"precision\": 0.0, \"recall\": 0.0}\n",
        "\n",
        "    f1 = f1_score(true_labels, pred_labels)\n",
        "    precision = precision_score(true_labels, pred_labels)\n",
        "    recall = recall_score(true_labels, pred_labels)\n",
        "\n",
        "    return {\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall\n",
        "    }\n",
        "\n",
        "# -------------------------\n",
        "# 5) Custom Trainer with Weighted Loss\n",
        "# -------------------------\n",
        "class WeightedRoBERTaTrainer(Trainer):\n",
        "    def __init__(self, class_weights=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Active loss calculation\n",
        "        active_loss = labels.view(-1) != -100\n",
        "        active_logits = logits.view(-1, logits.size(-1))[active_loss]\n",
        "        active_labels = labels.view(-1)[active_loss]\n",
        "\n",
        "        if len(active_labels) == 0:\n",
        "            return torch.tensor(0.0, requires_grad=True, device=logits.device)\n",
        "\n",
        "        # Weighted cross-entropy\n",
        "        loss = F.cross_entropy(active_logits, active_labels, weight=self.class_weights)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# -------------------------\n",
        "# 6) Main Training Function\n",
        "# -------------------------\n",
        "def train_roberta_large():\n",
        "    \"\"\"Train RoBERTa-Large with proper configuration\"\"\"\n",
        "\n",
        "    print(\"\\n🤖 Loading RoBERTa-Large...\")\n",
        "\n",
        "    try:\n",
        "        # Load tokenizer and model\n",
        "        model_name = \"roberta-large\"\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, add_prefix_space=True)\n",
        "        print(f\"✅ Tokenizer loaded (vocab: {tokenizer.vocab_size})\")\n",
        "        print(f\"   • RoBERTa tokenizer configured for pretokenized inputs\")\n",
        "\n",
        "        model = AutoModelForTokenClassification.from_pretrained(\n",
        "            model_name,\n",
        "            num_labels=len(target_labels),\n",
        "            id2label=id_to_label,\n",
        "            label2id=label_to_id,\n",
        "            hidden_dropout_prob=0.1,\n",
        "            attention_probs_dropout_prob=0.1\n",
        "        )\n",
        "\n",
        "        print(f\"✅ Model loaded (355M parameters)\")\n",
        "        model.to(device)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to load RoBERTa-Large: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    # Calculate class weights\n",
        "    weight_dict = calculate_class_weights(train_labels)\n",
        "    class_weights = torch.tensor([weight_dict[label] for label in target_labels],\n",
        "                               dtype=torch.float).to(device)\n",
        "\n",
        "    print(f\"\\n⚖️ Class weights calculated\")\n",
        "    for i, (label, weight) in enumerate(zip(target_labels, class_weights.cpu().numpy())):\n",
        "        if \"LOCATION\" in label or \"PHONE\" in label:\n",
        "            print(f\"   🎯 {label}: {weight:.2f}\")\n",
        "\n",
        "    # Create datasets\n",
        "    print(f\"\\n📊 Creating datasets...\")\n",
        "    train_dataset = RoBERTaNERDataset(train_tokens, train_labels, tokenizer, label_to_id)\n",
        "    val_dataset = RoBERTaNERDataset(val_tokens, val_labels, tokenizer, label_to_id)\n",
        "\n",
        "    # Configure training based on GPU memory\n",
        "    if gpu_memory >= 12:\n",
        "        batch_size = 4\n",
        "        gradient_accumulation = 4\n",
        "    elif gpu_memory >= 8:\n",
        "        batch_size = 2\n",
        "        gradient_accumulation = 8\n",
        "    else:\n",
        "        batch_size = 1\n",
        "        gradient_accumulation = 16\n",
        "\n",
        "    print(f\"🔧 Training configuration:\")\n",
        "    print(f\"   • Batch size: {batch_size}\")\n",
        "    print(f\"   • Gradient accumulation: {gradient_accumulation}\")\n",
        "    print(f\"   • Effective batch size: {batch_size * gradient_accumulation}\")\n",
        "\n",
        "    # Training arguments - FIXED VERSION\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./outputs/roberta_large_phi_detection\",\n",
        "        learning_rate=1e-5,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=2,\n",
        "        gradient_accumulation_steps=gradient_accumulation,\n",
        "        num_train_epochs=4,\n",
        "        warmup_ratio=0.1,\n",
        "        weight_decay=0.01,\n",
        "        max_grad_norm=1.0,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"eval_f1\",\n",
        "        greater_is_better=True,\n",
        "        fp16=True,\n",
        "        dataloader_pin_memory=False,\n",
        "        dataloader_num_workers=0,\n",
        "        seed=SEED,\n",
        "        logging_steps=50,\n",
        "        save_total_limit=2,\n",
        "        report_to=\"none\",\n",
        "        remove_unused_columns=True,\n",
        "    )\n",
        "\n",
        "    # Create trainer\n",
        "    trainer = WeightedRoBERTaTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics,\n",
        "        class_weights=class_weights,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "    )\n",
        "\n",
        "    print(f\"\\n🚀 Starting RoBERTa-Large training...\")\n",
        "    print(f\"⏱️ Estimated time: 30-60 minutes\")\n",
        "\n",
        "    try:\n",
        "        # Clear cache\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Train\n",
        "        train_result = trainer.train()\n",
        "\n",
        "        # Save model\n",
        "        trainer.save_model()\n",
        "        tokenizer.save_pretrained(\"./outputs/roberta_large_phi_detection\")\n",
        "\n",
        "        print(f\"✅ Training completed successfully!\")\n",
        "\n",
        "        # Evaluate\n",
        "        eval_results = trainer.evaluate()\n",
        "\n",
        "        print(f\"\\n📈 RoBERTa-Large Results:\")\n",
        "        print(f\"   • F1-Score: {eval_results['eval_f1']:.4f}\")\n",
        "        print(f\"   • Precision: {eval_results['eval_precision']:.4f}\")\n",
        "        print(f\"   • Recall: {eval_results['eval_recall']:.4f}\")\n",
        "\n",
        "        # Save results\n",
        "        roberta_results = {\n",
        "            'model': 'RoBERTa-Large',\n",
        "            'parameters': '355M',\n",
        "            'overall_metrics': {\n",
        "                'f1': eval_results['eval_f1'],\n",
        "                'precision': eval_results['eval_precision'],\n",
        "                'recall': eval_results['eval_recall']\n",
        "            },\n",
        "            'training_config': {\n",
        "                'batch_size': batch_size,\n",
        "                'gradient_accumulation': gradient_accumulation,\n",
        "                'learning_rate': 1e-5,\n",
        "                'epochs': 4\n",
        "            }\n",
        "        }\n",
        "\n",
        "        with open('roberta_large_results.json', 'w') as f:\n",
        "            json.dump(roberta_results, f, indent=2)\n",
        "\n",
        "        print(f\"📁 Model saved to: ./outputs/roberta_large_phi_detection\")\n",
        "        print(f\"📊 Results saved to: roberta_large_results.json\")\n",
        "\n",
        "        return trainer, eval_results\n",
        "\n",
        "    except RuntimeError as e:\n",
        "        if \"out of memory\" in str(e).lower():\n",
        "            print(f\"❌ GPU out of memory\")\n",
        "            print(f\"💡 Try reducing batch_size to 1 or max_length to 128\")\n",
        "        else:\n",
        "            print(f\"❌ Training error: {e}\")\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        return None, None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Unexpected error: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# -------------------------\n",
        "# 7) Execute Training\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"\\n🎯 Starting RoBERTa-Large PHI Detection Training\")\n",
        "\n",
        "    try:\n",
        "        trainer, results = train_roberta_large()\n",
        "\n",
        "        if trainer is not None and results is not None:\n",
        "            print(f\"\\n🎉 RoBERTa-Large Training Successful!\")\n",
        "            print(f\"🚀 Ready for comparison with BioBERT and ClinicalBERT!\")\n",
        "        else:\n",
        "            print(f\"\\n⚠️ RoBERTa-Large training encountered issues\")\n",
        "            print(f\"💡 Check GPU memory and try reducing batch size\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Training failed: {e}\")\n",
        "\n",
        "    finally:\n",
        "        # Clean up\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        print(f\"\\n✅ Training process completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "056d9c7eed3c4496adc555b0801d5432",
            "d9233486bced4ecfbce29be9fee70e65",
            "e654fe9276fb4711b1c50846567b941f",
            "e4fc6c12d48449ee9c56e63fc4ed020b",
            "d437cfd510284a28b8d5fba2ae7617bd",
            "70839a3cc4e84a79a4656738d2e00277",
            "a2d2d1958d1346248e69eea941848b15",
            "4b48883c438c4e35b6ef0e9690085a68",
            "c6c6cf4ec9b04cddbc61c0cb146b06a6",
            "6ea7ef98387f43639438c5baf9c60adc",
            "15aabb785e9d43f9bb12e6a75a8beab9",
            "56c79bbf88cd407eb53f9a3f21e1dfa6",
            "4ae4381c782241b9aabe9b8a70226734",
            "76fbc04b528346c8a2fdb6aa358c261f",
            "61ea90d0f3c343b8be703d240d608acf",
            "95bf3a1791e74452b2579c008499fe29",
            "fac8a16a41a243e789997f2cb834f07f",
            "930cc6c2f13c465280dfad5ae9611ce2",
            "6ebcaaa67c35491c8fc507a06b2d051e",
            "db6878db60b6445ea3f9a8fe24f4a663",
            "38724773137e40f0bca1e448ca383fcb",
            "606b5f45a2964632bbf5142f73acc7de",
            "4d6ad8ba0e6546ecaf9bb4e2b94908da",
            "dae606f0d42543d7941ddf1d48cefd77",
            "b61b90a3066e4e92b2a1c38952342261",
            "68a76fa291da46f2834e7c33f9b8d3ca",
            "3e981b4aad684dfb81b5e4c1d8401994",
            "4f340c15c6ca4660ac1a47eb649e885f",
            "1b81f65b9bff474fb493327dd378c9d0",
            "8ac6767c38e24a66bbb68ee3107c51c9",
            "a51c401c85f24a1eadc7963d37b5a362",
            "d3660f6147dc49aea2faf96b5cdfa3b8",
            "5065d2cb1fbb424cad20a669dfe788cf",
            "cf065832626a4dbeb7c22ec70418b28e",
            "6b60b94fcb7c4d69a9f13591fbf2c2ad",
            "9cd7ea096bfc49e3b5140c4a8700b787",
            "13309b6b6e15447e881298f78cd0cbd5",
            "6cbfa495807746f0a0d4f104674ff6a9",
            "f6b3df4c1e7140e199ff996ff56cf965",
            "6cdd42fb99d746a3b158dfada9431aab",
            "8041ddd57f8a465d84c8385911aeb7b6",
            "6e2b65cbd5af42d281aa90325075ea69",
            "ec98586036e94144bba34e12708ec01b",
            "ff55dd2391324048a8acd131498f118e",
            "8475ad31d49d412ea9e4425058fcca1f",
            "bd707dcd856f4ad58940a98244fedccd",
            "99513b776c6749168da25f34a98ac602",
            "72daf3bf1b7f4f6bb95f3cbdd59b7034",
            "fa6bdb685a3c4d8cb3b5625ce9020016",
            "126057c2f56840c19dea4060b5d4b7b5",
            "9adc4ae24fc94b4d9804b56f5dd2169e",
            "f842b533fbe84c2aba70b3b76fddccd7",
            "94522c9d53bc4ef7923641064203f3b9",
            "110208b2927a458b92b6366931b2e910",
            "a68075ef19e34305a5f726e62ad2ee1f",
            "43ba427b52914ddca8a64aa896832c0d",
            "d3fc80adf6954a3c91492247500e7165",
            "30cb17eb203a4181a688ab62a59210e1",
            "0ef0627666d64a328328afaacc3c0aef",
            "3e870db6ba2045a3948dccebc1fc5b74",
            "573c8fb781b448fd9b20938c14916b4b",
            "adcf595557dd45b0a0e1e519a133b3df",
            "2b6322e70a2840f08d610c37d8e2f0d9",
            "c6ac830427b74ef9af5bf89d0a1d4e95",
            "78b6aedefd49473896caeaefe3480d4d",
            "a7357b0117384f319a011b17651c191c"
          ]
        },
        "id": "twU-QGYEJFZ2",
        "outputId": "014c9370-96ea-4fea-9866-fa757474e5e2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 Starting RoBERTa-Large Training for PHI Detection (Fixed)\n",
            "============================================================\n",
            "✅ Using device: cuda\n",
            "🧠 GPU Memory: 14GB\n",
            "✅ Data loaded - Train: 669 | Val: 220\n",
            "📋 Target labels: 13 classes\n",
            "\n",
            "🎯 Starting RoBERTa-Large PHI Detection Training\n",
            "\n",
            "🤖 Loading RoBERTa-Large...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "056d9c7eed3c4496adc555b0801d5432"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56c79bbf88cd407eb53f9a3f21e1dfa6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d6ad8ba0e6546ecaf9bb4e2b94908da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf065832626a4dbeb7c22ec70418b28e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8475ad31d49d412ea9e4425058fcca1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tokenizer loaded (vocab: 50265)\n",
            "   • RoBERTa tokenizer configured for pretokenized inputs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43ba427b52914ddca8a64aa896832c0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded (355M parameters)\n",
            "\n",
            "⚖️ Class weights calculated\n",
            "   🎯 B-LOCATION: 8.00\n",
            "   🎯 I-LOCATION: 8.00\n",
            "   🎯 B-PHONE: 8.00\n",
            "   🎯 I-PHONE: 8.00\n",
            "\n",
            "📊 Creating datasets...\n",
            "🔧 Training configuration:\n",
            "   • Batch size: 4\n",
            "   • Gradient accumulation: 4\n",
            "   • Effective batch size: 16\n",
            "\n",
            "🚀 Starting RoBERTa-Large training...\n",
            "⏱️ Estimated time: 30-60 minutes\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='168' max='168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [168/168 06:19, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.178089</td>\n",
              "      <td>0.871679</td>\n",
              "      <td>0.828735</td>\n",
              "      <td>0.919316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.113200</td>\n",
              "      <td>0.070108</td>\n",
              "      <td>0.968425</td>\n",
              "      <td>0.955865</td>\n",
              "      <td>0.981320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.058700</td>\n",
              "      <td>0.048700</td>\n",
              "      <td>0.973601</td>\n",
              "      <td>0.965234</td>\n",
              "      <td>0.982114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.026600</td>\n",
              "      <td>0.041203</td>\n",
              "      <td>0.973016</td>\n",
              "      <td>0.964467</td>\n",
              "      <td>0.981717</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training completed successfully!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [110/110 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📈 RoBERTa-Large Results:\n",
            "   • F1-Score: 0.9736\n",
            "   • Precision: 0.9652\n",
            "   • Recall: 0.9821\n",
            "📁 Model saved to: ./outputs/roberta_large_phi_detection\n",
            "📊 Results saved to: roberta_large_results.json\n",
            "\n",
            "🎉 RoBERTa-Large Training Successful!\n",
            "🚀 Ready for comparison with BioBERT and ClinicalBERT!\n",
            "\n",
            "✅ Training process completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# FIXED RoBERTa-Large Evaluation Suite\n",
        "# =========================\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import Counter, defaultdict\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# -------------------------\n",
        "# 1) Safe Evaluation Functions (Handle Length Mismatches)\n",
        "# -------------------------\n",
        "def safe_sequence_metrics(true_labels, pred_labels):\n",
        "    \"\"\"Calculate metrics safely handling sequence length mismatches\"\"\"\n",
        "\n",
        "    # Ensure sequences have same length\n",
        "    aligned_true = []\n",
        "    aligned_pred = []\n",
        "\n",
        "    for true_seq, pred_seq in zip(true_labels, pred_labels):\n",
        "        min_len = min(len(true_seq), len(pred_seq))\n",
        "        if min_len > 0:\n",
        "            aligned_true.append(true_seq[:min_len])\n",
        "            aligned_pred.append(pred_seq[:min_len])\n",
        "\n",
        "    if not aligned_true:\n",
        "        return {\"f1\": 0.0, \"precision\": 0.0, \"recall\": 0.0}\n",
        "\n",
        "    # Calculate token-level metrics\n",
        "    all_true_flat = [label for seq in aligned_true for label in seq]\n",
        "    all_pred_flat = [label for seq in aligned_pred for label in seq]\n",
        "\n",
        "    # Entity-level metrics (safer approach)\n",
        "    true_entities = set()\n",
        "    pred_entities = set()\n",
        "\n",
        "    for seq_idx, (true_seq, pred_seq) in enumerate(zip(aligned_true, aligned_pred)):\n",
        "        # Extract entities from true sequence\n",
        "        current_entity = None\n",
        "        entity_start = None\n",
        "\n",
        "        for pos, label in enumerate(true_seq):\n",
        "            if label.startswith('B-'):\n",
        "                if current_entity is not None:\n",
        "                    true_entities.add((seq_idx, entity_start, pos-1, current_entity))\n",
        "                current_entity = label[2:]\n",
        "                entity_start = pos\n",
        "            elif label.startswith('I-') and current_entity is not None:\n",
        "                continue  # Continue current entity\n",
        "            else:  # 'O' or different entity\n",
        "                if current_entity is not None:\n",
        "                    true_entities.add((seq_idx, entity_start, pos-1, current_entity))\n",
        "                current_entity = None\n",
        "                entity_start = None\n",
        "\n",
        "        # Handle entity at end of sequence\n",
        "        if current_entity is not None:\n",
        "            true_entities.add((seq_idx, entity_start, len(true_seq)-1, current_entity))\n",
        "\n",
        "        # Extract entities from predicted sequence\n",
        "        current_entity = None\n",
        "        entity_start = None\n",
        "\n",
        "        for pos, label in enumerate(pred_seq):\n",
        "            if label.startswith('B-'):\n",
        "                if current_entity is not None:\n",
        "                    pred_entities.add((seq_idx, entity_start, pos-1, current_entity))\n",
        "                current_entity = label[2:]\n",
        "                entity_start = pos\n",
        "            elif label.startswith('I-') and current_entity is not None:\n",
        "                continue\n",
        "            else:\n",
        "                if current_entity is not None:\n",
        "                    pred_entities.add((seq_idx, entity_start, pos-1, current_entity))\n",
        "                current_entity = None\n",
        "                entity_start = None\n",
        "\n",
        "        if current_entity is not None:\n",
        "            pred_entities.add((seq_idx, entity_start, len(pred_seq)-1, current_entity))\n",
        "\n",
        "    # Calculate metrics\n",
        "    tp = len(true_entities & pred_entities)\n",
        "    fp = len(pred_entities - true_entities)\n",
        "    fn = len(true_entities - pred_entities)\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    return {\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"true_entities\": len(true_entities),\n",
        "        \"pred_entities\": len(pred_entities),\n",
        "        \"tp\": tp,\n",
        "        \"fp\": fp,\n",
        "        \"fn\": fn\n",
        "    }\n",
        "\n",
        "# -------------------------\n",
        "# 2) Fixed Prediction Function\n",
        "# -------------------------\n",
        "def predict_entities_fixed(tokens_list, model, tokenizer, max_len=256):\n",
        "    \"\"\"Generate predictions with better alignment\"\"\"\n",
        "    predictions = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for tokens in tokens_list:\n",
        "            try:\n",
        "                # Limit sequence length\n",
        "                if len(tokens) > max_len - 2:\n",
        "                    tokens = tokens[:max_len - 2]\n",
        "\n",
        "                # Tokenize (RoBERTa specific with add_prefix_space)\n",
        "                encoding = tokenizer(\n",
        "                    tokens,\n",
        "                    is_split_into_words=True,\n",
        "                    truncation=True,\n",
        "                    max_length=max_len,\n",
        "                    padding=\"max_length\",\n",
        "                    return_tensors=\"pt\"\n",
        "                )\n",
        "\n",
        "                # Get word IDs for alignment\n",
        "                word_ids = encoding.word_ids()\n",
        "\n",
        "                # Move to device\n",
        "                device = next(model.parameters()).device\n",
        "                encoding = {k: v.to(device) for k, v in encoding.items()}\n",
        "\n",
        "                # Predict\n",
        "                outputs = model(**encoding)\n",
        "                logits = outputs.logits\n",
        "                preds = torch.argmax(logits, dim=-1).cpu().numpy()[0]\n",
        "\n",
        "                # Align predictions with original tokens\n",
        "                aligned_preds = []\n",
        "                prev_word_id = None\n",
        "\n",
        "                for i, word_id in enumerate(word_ids):\n",
        "                    if word_id is None:\n",
        "                        continue  # Skip special tokens\n",
        "                    elif word_id != prev_word_id:\n",
        "                        # First subword of a word\n",
        "                        if word_id < len(tokens):\n",
        "                            pred_id = preds[i]\n",
        "                            pred_label = id_to_label.get(pred_id, \"O\")\n",
        "                            aligned_preds.append(pred_label)\n",
        "                    prev_word_id = word_id\n",
        "\n",
        "                # Ensure same length as input tokens\n",
        "                while len(aligned_preds) < len(tokens):\n",
        "                    aligned_preds.append(\"O\")\n",
        "                aligned_preds = aligned_preds[:len(tokens)]\n",
        "\n",
        "                predictions.append(aligned_preds)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing sequence: {e}\")\n",
        "                # Fallback: all O labels\n",
        "                predictions.append([\"O\"] * len(tokens))\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# -------------------------\n",
        "# 3) Load Model and Data\n",
        "# -------------------------\n",
        "print(\"🤖 Loading RoBERTa-Large trained model and tokenizer...\")\n",
        "\n",
        "# Try multiple possible RoBERTa model paths\n",
        "possible_paths = [\n",
        "    \"./outputs/roberta_large_phi_detection\",\n",
        "    \"/content/outputs/roberta_large_phi_detection\",\n",
        "    \"./roberta_large_phi_detection\",\n",
        "    \"/content/roberta_large_phi_detection\"\n",
        "]\n",
        "\n",
        "model = None\n",
        "model_path = None\n",
        "\n",
        "try:\n",
        "    # Load RoBERTa tokenizer with add_prefix_space=True\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\", use_fast=True, add_prefix_space=True)\n",
        "    print(\"✅ RoBERTa-Large tokenizer loaded\")\n",
        "\n",
        "    # Try to find the model\n",
        "    for path in possible_paths:\n",
        "        try:\n",
        "            print(f\"🔍 Trying to load RoBERTa-Large model from: {path}\")\n",
        "            model = AutoModelForTokenClassification.from_pretrained(path)\n",
        "            model_path = path\n",
        "            print(f\"✅ RoBERTa-Large model loaded from: {path}\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to load from {path}: {str(e)[:50]}...\")\n",
        "            continue\n",
        "\n",
        "    if model is None:\n",
        "        print(\"❌ Could not find trained RoBERTa-Large model. Please check if training completed successfully.\")\n",
        "        print(\"💡 Available files in current directory:\")\n",
        "        import os\n",
        "        if os.path.exists(\"outputs\"):\n",
        "            print(f\"   outputs/ contents: {os.listdir('outputs')}\")\n",
        "        else:\n",
        "            print(\"   No outputs/ directory found\")\n",
        "        exit()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"✅ RoBERTa-Large model ready on {device}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading RoBERTa-Large model: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Load data\n",
        "try:\n",
        "    with open('/content/test.json') as f:\n",
        "        test_data = json.load(f)\n",
        "    test_tokens = [entry[\"tokens\"] for entry in test_data]\n",
        "\n",
        "    with open('/content/val.json') as f:\n",
        "        gt_data = json.load(f)\n",
        "    gt_tokens = [entry[\"tokens\"] for entry in gt_data]\n",
        "    gt_labels = [entry[\"labels\"] for entry in gt_data]\n",
        "\n",
        "    print(f\"✅ Data loaded: Test={len(test_tokens)}, GT={len(gt_tokens)} samples\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading data: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Clean labels (same as training)\n",
        "def clean_and_normalize_labels(labels):\n",
        "    out = []\n",
        "    for l in labels:\n",
        "        if l in [\"B-AGE\", \"I-AGE\"]:\n",
        "            out.append(\"O\")\n",
        "        elif l in [\"B-DOCTOR\", \"I-DOCTOR\"]:\n",
        "            out.append(l.replace(\"DOCTOR\", \"NAME\"))\n",
        "        elif l in [\"B-PATIENT\", \"I-PATIENT\"]:\n",
        "            out.append(l.replace(\"PATIENT\", \"NAME\"))\n",
        "        else:\n",
        "            out.append(l)\n",
        "    return out\n",
        "\n",
        "gt_labels_clean = [clean_and_normalize_labels(labels) for labels in gt_labels]\n",
        "\n",
        "# Label mappings\n",
        "target_labels = [\n",
        "    \"B-DATE\", \"I-DATE\", \"B-HOSPITAL\", \"I-HOSPITAL\", \"B-ID\", \"I-ID\",\n",
        "    \"B-LOCATION\", \"I-LOCATION\", \"B-NAME\", \"I-NAME\", \"B-PHONE\", \"I-PHONE\", \"O\"\n",
        "]\n",
        "label_to_id = {l: i for i, l in enumerate(target_labels)}\n",
        "id_to_label = {i: l for l, i in label_to_id.items()}\n",
        "\n",
        "# -------------------------\n",
        "# 4) Generate Predictions with Fixed Function\n",
        "# -------------------------\n",
        "print(\"🔄 Generating RoBERTa-Large predictions...\")\n",
        "gt_predictions = predict_entities_fixed(gt_tokens, model, tokenizer)\n",
        "print(f\"✅ Generated predictions for {len(gt_predictions)} samples\")\n",
        "\n",
        "# -------------------------\n",
        "# 5) Safe Evaluation\n",
        "# -------------------------\n",
        "print(\"🔄 Evaluating RoBERTa-Large predictions...\")\n",
        "evaluation_results = safe_sequence_metrics(gt_labels_clean, gt_predictions)\n",
        "\n",
        "# Per-entity evaluation\n",
        "entity_metrics = {}\n",
        "entities = [\"DATE\", \"HOSPITAL\", \"ID\", \"LOCATION\", \"NAME\", \"PHONE\"]\n",
        "\n",
        "for entity in entities:\n",
        "    # Filter sequences for this entity\n",
        "    entity_true = []\n",
        "    entity_pred = []\n",
        "\n",
        "    for true_seq, pred_seq in zip(gt_labels_clean, gt_predictions):\n",
        "        et = [label if entity in label else 'O' for label in true_seq]\n",
        "        ep = [label if entity in label else 'O' for label in pred_seq]\n",
        "        entity_true.append(et)\n",
        "        entity_pred.append(ep)\n",
        "\n",
        "    entity_result = safe_sequence_metrics(entity_true, entity_pred)\n",
        "    entity_metrics[entity] = {\n",
        "        'f1': entity_result['f1'],\n",
        "        'precision': entity_result['precision'],\n",
        "        'recall': entity_result['recall']\n",
        "    }\n",
        "\n",
        "# -------------------------\n",
        "# 6) Save Results\n",
        "# -------------------------\n",
        "results_data = {\n",
        "    'model_path': model_path,\n",
        "    'model_type': 'RoBERTa-Large',\n",
        "    'base_model': 'roberta-large',\n",
        "    'parameters': '355M',\n",
        "    'test_samples': len(gt_tokens),\n",
        "    'overall_metrics': {\n",
        "        'f1': evaluation_results['f1'],\n",
        "        'precision': evaluation_results['precision'],\n",
        "        'recall': evaluation_results['recall']\n",
        "    },\n",
        "    'entity_metrics': entity_metrics,\n",
        "    'detailed_stats': {\n",
        "        'true_entities': evaluation_results['true_entities'],\n",
        "        'pred_entities': evaluation_results['pred_entities'],\n",
        "        'tp': evaluation_results['tp'],\n",
        "        'fp': evaluation_results['fp'],\n",
        "        'fn': evaluation_results['fn']\n",
        "    },\n",
        "    'predictions': gt_predictions,\n",
        "    'true_labels': gt_labels_clean,\n",
        "    'tokens': gt_tokens\n",
        "}\n",
        "\n",
        "# Save results\n",
        "with open('roberta_large_evaluation_results.json', 'w') as f:\n",
        "    json.dump(results_data, f, indent=2)\n",
        "\n",
        "# Create entity DataFrame\n",
        "entity_df = pd.DataFrame(entity_metrics).T\n",
        "entity_df.to_csv('roberta_large_entity_performance.csv')\n",
        "\n",
        "print(\"✅ RoBERTa-Large results saved successfully!\")\n",
        "\n",
        "# -------------------------\n",
        "# 7) Print Summary\n",
        "# -------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🤖 ROBERTA-LARGE EVALUATION RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n📊 Overall Performance:\")\n",
        "print(f\"   • F1-Score:  {evaluation_results['f1']:.4f}\")\n",
        "print(f\"   • Precision: {evaluation_results['precision']:.4f}\")\n",
        "print(f\"   • Recall:    {evaluation_results['recall']:.4f}\")\n",
        "\n",
        "print(f\"\\n📈 Entity Counts:\")\n",
        "print(f\"   • True entities found: {evaluation_results['true_entities']}\")\n",
        "print(f\"   • Predicted entities: {evaluation_results['pred_entities']}\")\n",
        "print(f\"   • True Positives: {evaluation_results['tp']}\")\n",
        "print(f\"   • False Positives: {evaluation_results['fp']}\")\n",
        "print(f\"   • False Negatives: {evaluation_results['fn']}\")\n",
        "\n",
        "print(f\"\\n🎯 Entity-Level Performance:\")\n",
        "for entity, metrics in entity_metrics.items():\n",
        "    print(f\"   • {entity:10s}: F1={metrics['f1']:.3f}, P={metrics['precision']:.3f}, R={metrics['recall']:.3f}\")\n",
        "\n",
        "print(f\"\\n🤖 RoBERTa-Large Model Information:\")\n",
        "print(f\"   • Base Model: roberta-large\")\n",
        "print(f\"   • Parameters: 355M\")\n",
        "print(f\"   • Domain: General Text (BookCorpus + Wikipedia)\")\n",
        "print(f\"   • Architecture: RoBERTa (Robustly Optimized BERT)\")\n",
        "print(f\"   • Specialization: Advanced transformer with improved training\")\n",
        "print(f\"   • Model Path: {model_path}\")\n",
        "\n",
        "print(f\"\\n🤖 RoBERTa-Large Advantages:\")\n",
        "print(f\"   • Large parameter count (355M) for complex pattern recognition\")\n",
        "print(f\"   • Improved training methodology over BERT\")\n",
        "print(f\"   • Dynamic masking and larger batch sizes\")\n",
        "print(f\"   • Robust optimization techniques\")\n",
        "print(f\"   • Advanced attention mechanisms\")\n",
        "\n",
        "print(f\"\\n✅ RoBERTa-Large evaluation completed successfully!\")\n",
        "print(f\"📁 Files saved:\")\n",
        "print(f\"   • roberta_large_evaluation_results.json\")\n",
        "print(f\"   • roberta_large_entity_performance.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBsqBUjJIEPg",
        "outputId": "e847cfc3-8410-4c72-ca25-29c9b7f957b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 Loading RoBERTa-Large trained model and tokenizer...\n",
            "✅ RoBERTa-Large tokenizer loaded\n",
            "🔍 Trying to load RoBERTa-Large model from: ./outputs/roberta_large_phi_detection\n",
            "✅ RoBERTa-Large model loaded from: ./outputs/roberta_large_phi_detection\n",
            "✅ RoBERTa-Large model ready on cuda\n",
            "✅ Data loaded: Test=220, GT=220 samples\n",
            "🔄 Generating RoBERTa-Large predictions...\n",
            "✅ Generated predictions for 220 samples\n",
            "🔄 Evaluating RoBERTa-Large predictions...\n",
            "✅ RoBERTa-Large results saved successfully!\n",
            "\n",
            "============================================================\n",
            "🤖 ROBERTA-LARGE EVALUATION RESULTS\n",
            "============================================================\n",
            "\n",
            "📊 Overall Performance:\n",
            "   • F1-Score:  0.9060\n",
            "   • Precision: 0.9701\n",
            "   • Recall:    0.8499\n",
            "\n",
            "📈 Entity Counts:\n",
            "   • True entities found: 2899\n",
            "   • Predicted entities: 2540\n",
            "   • True Positives: 2464\n",
            "   • False Positives: 76\n",
            "   • False Negatives: 435\n",
            "\n",
            "🎯 Entity-Level Performance:\n",
            "   • DATE      : F1=0.906, P=0.985, R=0.838\n",
            "   • HOSPITAL  : F1=0.855, P=0.898, R=0.815\n",
            "   • ID        : F1=0.981, P=0.994, R=0.968\n",
            "   • LOCATION  : F1=0.000, P=0.000, R=0.000\n",
            "   • NAME      : F1=0.812, P=0.950, R=0.708\n",
            "   • PHONE     : F1=0.840, P=0.913, R=0.778\n",
            "\n",
            "🤖 RoBERTa-Large Model Information:\n",
            "   • Base Model: roberta-large\n",
            "   • Parameters: 355M\n",
            "   • Domain: General Text (BookCorpus + Wikipedia)\n",
            "   • Architecture: RoBERTa (Robustly Optimized BERT)\n",
            "   • Specialization: Advanced transformer with improved training\n",
            "   • Model Path: ./outputs/roberta_large_phi_detection\n",
            "\n",
            "🤖 RoBERTa-Large Advantages:\n",
            "   • Large parameter count (355M) for complex pattern recognition\n",
            "   • Improved training methodology over BERT\n",
            "   • Dynamic masking and larger batch sizes\n",
            "   • Robust optimization techniques\n",
            "   • Advanced attention mechanisms\n",
            "\n",
            "✅ RoBERTa-Large evaluation completed successfully!\n",
            "📁 Files saved:\n",
            "   • roberta_large_evaluation_results.json\n",
            "   • roberta_large_entity_performance.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# ROBERTA-LARGE PHI DETECTION MODEL DOWNLOAD\n",
        "# ===========================\n",
        "\n",
        "import os\n",
        "import json\n",
        "from google.colab import files\n",
        "\n",
        "print(\"🤖 Preparing RoBERTa-Large PHI Detection model for download...\")\n",
        "\n",
        "# Check what files exist in the outputs directory\n",
        "if os.path.exists('./outputs'):\n",
        "    print(\"✅ Found outputs directory\")\n",
        "\n",
        "    # List contents of outputs directory\n",
        "    print(\"\\n📂 Contents of ./outputs/:\")\n",
        "    for root, dirs, files_list in os.walk('./outputs'):\n",
        "        level = root.replace('./outputs', '').count(os.sep)\n",
        "        indent = ' ' * 2 * level\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        subindent = ' ' * 2 * (level + 1)\n",
        "        for file in files_list:\n",
        "            file_size = os.path.getsize(os.path.join(root, file))\n",
        "            file_size_mb = file_size / (1024 * 1024)\n",
        "            print(f\"{subindent}{file} ({file_size_mb:.1f} MB)\")\n",
        "else:\n",
        "    print(\"❌ outputs directory not found\")\n",
        "\n",
        "    # Check for alternative locations\n",
        "    print(\"\\n🔍 Checking alternative model save locations...\")\n",
        "\n",
        "    # Check current directory for roberta files\n",
        "    current_files = [f for f in os.listdir('.') if 'roberta' in f.lower() or 'model' in f.lower()]\n",
        "    if current_files:\n",
        "        print(f\"✅ Found model files in current directory: {current_files}\")\n",
        "\n",
        "    # Check if trainer saved model elsewhere\n",
        "    if 'trainer' in globals():\n",
        "        print(f\"✅ Trainer output directory: {trainer.args.output_dir}\")\n",
        "        if os.path.exists(trainer.args.output_dir):\n",
        "            print(\"✅ Trainer output directory exists\")\n",
        "        else:\n",
        "            print(\"❌ Trainer output directory not found\")\n",
        "\n",
        "# Method 1: Try RoBERTa specific path\n",
        "if os.path.exists('./outputs/roberta_large_phi_detection'):\n",
        "    print(\"\\n📦 Creating zip file from ./outputs/roberta_large_phi_detection...\")\n",
        "    !zip -rq roberta_large_phi_detection_model.zip ./outputs/roberta_large_phi_detection\n",
        "\n",
        "    if os.path.exists('roberta_large_phi_detection_model.zip'):\n",
        "        print(\"✅ RoBERTa-Large zip file created successfully\")\n",
        "\n",
        "        # Check zip file size\n",
        "        zip_size = os.path.getsize('roberta_large_phi_detection_model.zip')\n",
        "        zip_size_mb = zip_size / (1024 * 1024)\n",
        "        print(f\"📦 Zip file size: {zip_size_mb:.1f} MB\")\n",
        "\n",
        "        # Download the file\n",
        "        print(\"⬇️ Starting RoBERTa-Large model download...\")\n",
        "        files.download('roberta_large_phi_detection_model.zip')\n",
        "        print(\"✅ RoBERTa-Large download initiated!\")\n",
        "    else:\n",
        "        print(\"❌ Failed to create RoBERTa-Large zip file\")\n",
        "\n",
        "# Method 2: Try trainer output directory\n",
        "elif 'trainer' in globals() and os.path.exists(trainer.args.output_dir):\n",
        "    print(f\"\\n📦 Creating zip file from trainer output: {trainer.args.output_dir}\")\n",
        "    !zip -rq roberta_large_phi_detection_model.zip {trainer.args.output_dir}\n",
        "\n",
        "    if os.path.exists('roberta_large_phi_detection_model.zip'):\n",
        "        print(\"✅ RoBERTa-Large zip file created successfully\")\n",
        "\n",
        "        # Check zip file size\n",
        "        zip_size = os.path.getsize('roberta_large_phi_detection_model.zip')\n",
        "        zip_size_mb = zip_size / (1024 * 1024)\n",
        "        print(f\"📦 Zip file size: {zip_size_mb:.1f} MB\")\n",
        "\n",
        "        # Download the file\n",
        "        print(\"⬇️ Starting RoBERTa-Large model download...\")\n",
        "        files.download('roberta_large_phi_detection_model.zip')\n",
        "        print(\"✅ RoBERTa-Large download initiated!\")\n",
        "    else:\n",
        "        print(\"❌ Failed to create RoBERTa-Large zip file\")\n",
        "\n",
        "# Method 3: Manual save if trainer exists\n",
        "elif 'trainer' in globals():\n",
        "    print(\"\\n💾 Manually saving RoBERTa-Large model files...\")\n",
        "\n",
        "    # Create a directory for the RoBERTa model\n",
        "    os.makedirs('roberta_large_phi_detection_manual', exist_ok=True)\n",
        "\n",
        "    # Save the model and tokenizer\n",
        "    trainer.save_model('roberta_large_phi_detection_manual')\n",
        "    print(\"✅ RoBERTa-Large model saved\")\n",
        "\n",
        "    if 'tokenizer' in globals():\n",
        "        tokenizer.save_pretrained('roberta_large_phi_detection_manual')\n",
        "        print(\"✅ RoBERTa-Large tokenizer saved\")\n",
        "\n",
        "    # Save RoBERTa-specific files\n",
        "\n",
        "    # Save label mappings\n",
        "    if 'id_to_label' in globals():\n",
        "        with open('roberta_large_phi_detection_manual/id_to_label.json', 'w') as f:\n",
        "            json.dump(id_to_label, f, indent=2)\n",
        "        print(\"✅ PHI label mappings saved\")\n",
        "\n",
        "    if 'label_to_id' in globals():\n",
        "        with open('roberta_large_phi_detection_manual/label_to_id.json', 'w') as f:\n",
        "            json.dump(label_to_id, f, indent=2)\n",
        "\n",
        "    # Save target labels for PHI detection\n",
        "    if 'target_labels' in globals():\n",
        "        with open('roberta_large_phi_detection_manual/target_labels.json', 'w') as f:\n",
        "            json.dump(target_labels, f, indent=2)\n",
        "        print(\"✅ PHI target labels saved\")\n",
        "\n",
        "    # Save training arguments\n",
        "    if hasattr(trainer, 'args'):\n",
        "        trainer.args.save_to_json('roberta_large_phi_detection_manual/training_args.json')\n",
        "        print(\"✅ RoBERTa-Large training arguments saved\")\n",
        "\n",
        "    # Save RoBERTa results if available\n",
        "    if os.path.exists('roberta_large_results.json'):\n",
        "        !cp roberta_large_results.json roberta_large_phi_detection_manual/\n",
        "        print(\"✅ RoBERTa-Large training results saved\")\n",
        "\n",
        "    # Save GPU memory info if available\n",
        "    gpu_info = {}\n",
        "    if 'gpu_memory' in globals():\n",
        "        gpu_info['gpu_memory_gb'] = gpu_memory\n",
        "    if 'batch_size' in locals() or 'batch_size' in globals():\n",
        "        gpu_info['optimal_batch_size'] = globals().get('batch_size', 'Unknown')\n",
        "    if 'gradient_accumulation' in locals() or 'gradient_accumulation' in globals():\n",
        "        gpu_info['gradient_accumulation_steps'] = globals().get('gradient_accumulation', 'Unknown')\n",
        "\n",
        "    if gpu_info:\n",
        "        with open('roberta_large_phi_detection_manual/gpu_optimization.json', 'w') as f:\n",
        "            json.dump(gpu_info, f, indent=2)\n",
        "        print(\"✅ GPU optimization settings saved\")\n",
        "\n",
        "    # Save model info and usage instructions\n",
        "    model_info = {\n",
        "        \"model_name\": \"RoBERTa-Large PHI Detection\",\n",
        "        \"base_model\": \"roberta-large\",\n",
        "        \"parameters\": \"355M\",\n",
        "        \"task\": \"Named Entity Recognition (NER) for PHI Detection\",\n",
        "        \"target_entities\": [\n",
        "            \"DATE\", \"HOSPITAL\", \"ID\", \"LOCATION\", \"NAME\", \"PHONE\"\n",
        "        ],\n",
        "        \"training_config\": {\n",
        "            \"learning_rate\": \"1e-5\",\n",
        "            \"epochs\": 4,\n",
        "            \"effective_batch_size\": \"Variable based on GPU memory\",\n",
        "            \"model_type\": \"RoBERTa-Large (355M parameters)\"\n",
        "        },\n",
        "        \"advantages\": [\n",
        "            \"Large parameter count (355M) for complex pattern recognition\",\n",
        "            \"Robustly optimized BERT pretraining approach\",\n",
        "            \"Superior performance on downstream NLP tasks\",\n",
        "            \"Advanced attention mechanisms\"\n",
        "        ],\n",
        "        \"usage_instructions\": {\n",
        "            \"load_model\": \"AutoModelForTokenClassification.from_pretrained('./roberta_large_phi_detection')\",\n",
        "            \"load_tokenizer\": \"AutoTokenizer.from_pretrained('./roberta_large_phi_detection', add_prefix_space=True)\",\n",
        "            \"preprocessing\": \"Use is_split_into_words=True and add_prefix_space=True for tokenization\",\n",
        "            \"memory_requirements\": \"Requires substantial GPU memory for training and inference\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open('roberta_large_phi_detection_manual/model_info.json', 'w') as f:\n",
        "        json.dump(model_info, f, indent=2)\n",
        "    print(\"✅ RoBERTa-Large model info saved\")\n",
        "\n",
        "    # Create README file\n",
        "    readme_content = \"\"\"# RoBERTa-Large PHI Detection Model\n",
        "\n",
        "## Overview\n",
        "This is a fine-tuned RoBERTa-Large model (355M parameters) for detecting Protected Health Information (PHI) in medical texts.\n",
        "\n",
        "## Base Model\n",
        "- **Model**: roberta-large\n",
        "- **Parameters**: 355M\n",
        "- **Type**: RoBERTa (Robustly Optimized BERT Pretraining Approach)\n",
        "- **Task**: Named Entity Recognition (NER)\n",
        "\n",
        "## Detected PHI Types\n",
        "- **DATE**: Dates and temporal information\n",
        "- **HOSPITAL**: Hospital and healthcare facility names\n",
        "- **ID**: Patient/medical identifiers\n",
        "- **LOCATION**: Geographic locations\n",
        "- **NAME**: Person names (patients, doctors)\n",
        "- **PHONE**: Phone numbers\n",
        "\n",
        "## Model Advantages\n",
        "- **Large Scale**: 355M parameters for complex pattern recognition\n",
        "- **Robust Training**: RoBERTa's improved training methodology\n",
        "- **High Performance**: Superior results on downstream NLP tasks\n",
        "- **Advanced Architecture**: State-of-the-art transformer design\n",
        "\n",
        "## Usage\n",
        "\n",
        "```python\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import torch\n",
        "\n",
        "# Load model and tokenizer (Note: add_prefix_space=True for RoBERTa)\n",
        "model = AutoModelForTokenClassification.from_pretrained('./roberta_large_phi_detection')\n",
        "tokenizer = AutoTokenizer.from_pretrained('./roberta_large_phi_detection', add_prefix_space=True)\n",
        "\n",
        "# Example usage\n",
        "text = [\"Patient\", \"John\", \"Smith\", \"visited\", \"City\", \"Hospital\"]\n",
        "inputs = tokenizer(text, is_split_into_words=True, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "# Load label mappings\n",
        "import json\n",
        "with open('./roberta_large_phi_detection/id_to_label.json') as f:\n",
        "    id_to_label = json.load(f)\n",
        "\n",
        "# Convert predictions to labels\n",
        "pred_labels = [id_to_label[str(pred.item())] for pred in predictions[0]]\n",
        "```\n",
        "\n",
        "## Memory Requirements\n",
        "- **Training**: Requires high-end GPU (12GB+ recommended)\n",
        "- **Inference**: Can run on smaller GPUs with reduced batch sizes\n",
        "- **Optimization**: Gradient accumulation used for memory efficiency\n",
        "\n",
        "## Performance\n",
        "Check `roberta_large_results.json` for detailed performance metrics.\n",
        "\n",
        "## GPU Optimization\n",
        "Check `gpu_optimization.json` for optimal batch sizes and settings based on your hardware.\n",
        "\n",
        "## RoBERTa Advantages\n",
        "- Improved training methodology over BERT\n",
        "- Better handling of subword tokenization\n",
        "- Enhanced performance on complex NLP tasks\n",
        "- Robust optimization techniques\n",
        "\"\"\"\n",
        "\n",
        "    with open('roberta_large_phi_detection_manual/README.md', 'w') as f:\n",
        "        f.write(readme_content)\n",
        "    print(\"✅ README file created\")\n",
        "\n",
        "    # Create zip file\n",
        "    print(\"📦 Creating RoBERTa-Large model zip file...\")\n",
        "    !zip -rq roberta_large_phi_detection_model.zip roberta_large_phi_detection_manual/\n",
        "\n",
        "    if os.path.exists('roberta_large_phi_detection_model.zip'):\n",
        "        zip_size = os.path.getsize('roberta_large_phi_detection_model.zip')\n",
        "        zip_size_mb = zip_size / (1024 * 1024)\n",
        "        print(f\"✅ RoBERTa-Large zip file created: {zip_size_mb:.1f} MB\")\n",
        "\n",
        "        # Download the file\n",
        "        print(\"⬇️ Starting RoBERTa-Large model download...\")\n",
        "        files.download('roberta_large_phi_detection_model.zip')\n",
        "        print(\"✅ RoBERTa-Large download initiated!\")\n",
        "    else:\n",
        "        print(\"❌ Failed to create RoBERTa-Large zip file\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ No RoBERTa-Large model found to download\")\n",
        "    print(\"\\n🔧 RoBERTa-Large Troubleshooting steps:\")\n",
        "    print(\"1. Make sure your RoBERTa-Large training completed successfully\")\n",
        "    print(\"2. Check if trainer.save_model() was called\")\n",
        "    print(\"3. Verify the output directory path: './outputs/roberta_large_phi_detection'\")\n",
        "    print(\"4. Try running: trainer.save_model('./roberta_large_phi_detection_download')\")\n",
        "\n",
        "print(\"\\n📋 What's included in the RoBERTa-Large model zip:\")\n",
        "print(\"🤖 RoBERTa-Large model weights (pytorch_model.bin) - 355M parameters\")\n",
        "print(\"🤖 RoBERTa-Large configuration (config.json)\")\n",
        "print(\"🤖 RoBERTa tokenizer files (vocab.json, merges.txt, tokenizer.json, etc.)\")\n",
        "print(\"🤖 PHI label mappings (id_to_label.json, label_to_id.json)\")\n",
        "print(\"🤖 Target PHI labels (target_labels.json)\")\n",
        "print(\"🤖 Training arguments and results\")\n",
        "print(\"🤖 GPU optimization settings\")\n",
        "print(\"🤖 Model information and usage guide\")\n",
        "print(\"🤖 README with setup instructions\")\n",
        "\n",
        "print(\"\\n🚀 Load your RoBERTa-Large PHI Detection model later with:\")\n",
        "print(\"   from transformers import AutoModelForTokenClassification, AutoTokenizer\")\n",
        "print(\"   model = AutoModelForTokenClassification.from_pretrained('./roberta_large_phi_detection')\")\n",
        "print(\"   tokenizer = AutoTokenizer.from_pretrained('./roberta_large_phi_detection', add_prefix_space=True)\")\n",
        "\n",
        "print(\"\\n🤖 RoBERTa-Large Advantages:\")\n",
        "print(\"   ✅ 355M parameters for superior pattern recognition\")\n",
        "print(\"   ✅ Robustly optimized BERT pretraining approach\")\n",
        "print(\"   ✅ State-of-the-art transformer architecture\")\n",
        "print(\"   ✅ Excellent performance on complex NLP tasks\")\n",
        "print(\"   ✅ Advanced attention mechanisms\")\n",
        "\n",
        "# Clean up temporary files\n",
        "print(\"\\n🧹 Cleaning up temporary files...\")\n",
        "if os.path.exists('roberta_large_phi_detection_manual'):\n",
        "    !rm -rf roberta_large_phi_detection_manual\n",
        "    print(\"✅ Temporary directory cleaned\")\n",
        "\n",
        "print(\"\\n✅ RoBERTa-Large PHI Detection model download complete!\")"
      ],
      "metadata": {
        "id": "2dvO3jE_MsRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# COMPREHENSIVE PHI MODEL COMPARISON & VISUALIZATION\n",
        "# =========================\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.patches import Rectangle\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"🔬 Comprehensive PHI Detection Model Comparison\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# -------------------------\n",
        "# 1) Load All Model Results\n",
        "# -------------------------\n",
        "def load_all_model_results():\n",
        "    \"\"\"Load results from all three models\"\"\"\n",
        "\n",
        "    models_data = {}\n",
        "\n",
        "    # Try to load ClinicalBERT results\n",
        "    try:\n",
        "        with open('evaluation_results_clincalbert.json', 'r') as f:\n",
        "            clinical_data = json.load(f)\n",
        "        models_data['ClinicalBERT'] = {\n",
        "            'name': 'ClinicalBERT Enhanced',\n",
        "            'type': 'Clinical BERT',\n",
        "            'domain': 'Clinical Notes (MIMIC-III)',\n",
        "            'parameters': '110M',\n",
        "            'base_model': 'emilyalsentzer/Bio_ClinicalBERT',\n",
        "            'overall': clinical_data['overall_metrics'],\n",
        "            'entities': clinical_data['entity_metrics'],\n",
        "            'details': clinical_data['detailed_stats'],\n",
        "            'color': '#1f77b4'\n",
        "        }\n",
        "        print(\"✅ ClinicalBERT results loaded\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"⚠️ ClinicalBERT results not found\")\n",
        "\n",
        "    # Try to load BioBERT results\n",
        "    try:\n",
        "        with open('biobert_evaluation_results.json', 'r') as f:\n",
        "            biobert_data = json.load(f)\n",
        "        models_data['BioBERT'] = {\n",
        "            'name': 'BioBERT',\n",
        "            'type': 'Biomedical BERT',\n",
        "            'domain': 'Biomedical Literature (PubMed + PMC)',\n",
        "            'parameters': '110M',\n",
        "            'base_model': 'dmis-lab/biobert-base-cased-v1.1',\n",
        "            'overall': biobert_data['overall_metrics'],\n",
        "            'entities': biobert_data['entity_metrics'],\n",
        "            'details': biobert_data['detailed_stats'],\n",
        "            'color': '#ff7f0e'\n",
        "        }\n",
        "        print(\"✅ BioBERT results loaded\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"⚠️ BioBERT results not found\")\n",
        "\n",
        "    # Try to load RoBERTa results\n",
        "    try:\n",
        "        with open('roberta_large_evaluation_results.json', 'r') as f:\n",
        "            roberta_data = json.load(f)\n",
        "        models_data['RoBERTa-Large'] = {\n",
        "            'name': 'RoBERTa-Large',\n",
        "            'type': 'General Transformer',\n",
        "            'domain': 'General Text (BookCorpus + Wikipedia)',\n",
        "            'parameters': '355M',\n",
        "            'base_model': 'roberta-large',\n",
        "            'overall': roberta_data['overall_metrics'],\n",
        "            'entities': roberta_data['entity_metrics'],\n",
        "            'details': roberta_data['detailed_stats'],\n",
        "            'color': '#2ca02c'\n",
        "        }\n",
        "        print(\"✅ RoBERTa-Large results loaded\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"⚠️ RoBERTa-Large results not found\")\n",
        "\n",
        "    return models_data\n",
        "\n",
        "# -------------------------\n",
        "# 2) Create Comprehensive Comparison DataFrames\n",
        "# -------------------------\n",
        "def create_comparison_dataframes(models_data):\n",
        "    \"\"\"Create detailed comparison DataFrames\"\"\"\n",
        "\n",
        "    if not models_data:\n",
        "        print(\"❌ No model data available for comparison\")\n",
        "        return None, None\n",
        "\n",
        "    # Overall performance comparison\n",
        "    overall_data = []\n",
        "    for model_key, model_info in models_data.items():\n",
        "        overall_data.append({\n",
        "            'Model': model_info['name'],\n",
        "            'Type': model_info['type'],\n",
        "            'Domain': model_info['domain'],\n",
        "            'Parameters': model_info['parameters'],\n",
        "            'F1-Score': model_info['overall']['f1'],\n",
        "            'Precision': model_info['overall']['precision'],\n",
        "            'Recall': model_info['overall']['recall'],\n",
        "            'True Entities': model_info['details']['true_entities'],\n",
        "            'Predicted Entities': model_info['details']['pred_entities'],\n",
        "            'True Positives': model_info['details']['tp'],\n",
        "            'False Positives': model_info['details']['fp'],\n",
        "            'False Negatives': model_info['details']['fn']\n",
        "        })\n",
        "\n",
        "    overall_df = pd.DataFrame(overall_data)\n",
        "\n",
        "    # Entity-level comparison\n",
        "    entities = [\"DATE\", \"HOSPITAL\", \"ID\", \"LOCATION\", \"NAME\", \"PHONE\"]\n",
        "    entity_data = []\n",
        "\n",
        "    for entity in entities:\n",
        "        row = {'Entity': entity}\n",
        "        for model_key, model_info in models_data.items():\n",
        "            model_name = model_info['name']\n",
        "            if entity in model_info['entities']:\n",
        "                row[f'{model_name}_F1'] = model_info['entities'][entity]['f1']\n",
        "                row[f'{model_name}_Precision'] = model_info['entities'][entity]['precision']\n",
        "                row[f'{model_name}_Recall'] = model_info['entities'][entity]['recall']\n",
        "            else:\n",
        "                row[f'{model_name}_F1'] = 0.0\n",
        "                row[f'{model_name}_Precision'] = 0.0\n",
        "                row[f'{model_name}_Recall'] = 0.0\n",
        "        entity_data.append(row)\n",
        "\n",
        "    entity_df = pd.DataFrame(entity_data)\n",
        "\n",
        "    return overall_df, entity_df\n",
        "\n",
        "# -------------------------\n",
        "# 3) Advanced Statistical Analysis\n",
        "# -------------------------\n",
        "def perform_statistical_analysis(models_data):\n",
        "    \"\"\"Perform detailed statistical analysis\"\"\"\n",
        "\n",
        "    print(\"\\n📊 Statistical Analysis Results:\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    if len(models_data) < 2:\n",
        "        print(\"⚠️ Need at least 2 models for comparison\")\n",
        "        return\n",
        "\n",
        "    # Performance ranking\n",
        "    f1_scores = [(name, info['overall']['f1']) for name, info in models_data.items()]\n",
        "    f1_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    print(\"\\n🏆 Overall Performance Ranking (F1-Score):\")\n",
        "    for i, (model, f1) in enumerate(f1_scores, 1):\n",
        "        print(f\"   {i}. {model:20s}: {f1:.4f}\")\n",
        "\n",
        "    # Statistical significance (simplified)\n",
        "    best_model = f1_scores[0][0]\n",
        "    best_f1 = f1_scores[0][1]\n",
        "\n",
        "    print(f\"\\n📈 Performance Gaps:\")\n",
        "    for model, f1 in f1_scores[1:]:\n",
        "        gap = best_f1 - f1\n",
        "        percentage_gap = (gap / best_f1) * 100\n",
        "        print(f\"   • {model}: -{gap:.4f} ({percentage_gap:.1f}% lower than best)\")\n",
        "\n",
        "    # Entity-level analysis\n",
        "    entities = [\"DATE\", \"HOSPITAL\", \"ID\", \"LOCATION\", \"NAME\", \"PHONE\"]\n",
        "    entity_winners = {entity: [] for entity in entities}\n",
        "\n",
        "    for entity in entities:\n",
        "        entity_scores = []\n",
        "        for model_name, model_info in models_data.items():\n",
        "            if entity in model_info['entities']:\n",
        "                entity_scores.append((model_name, model_info['entities'][entity]['f1']))\n",
        "\n",
        "        if entity_scores:\n",
        "            entity_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "            entity_winners[entity] = entity_scores\n",
        "\n",
        "    print(f\"\\n🎯 Entity-Level Winners:\")\n",
        "    for entity, scores in entity_winners.items():\n",
        "        if scores:\n",
        "            winner = scores[0]\n",
        "            print(f\"   • {entity:10s}: {winner[0]} ({winner[1]:.3f})\")\n",
        "\n",
        "    # Model strengths analysis\n",
        "    print(f\"\\n💪 Model Strengths Analysis:\")\n",
        "    for model_name, model_info in models_data.items():\n",
        "        strengths = []\n",
        "        for entity in entities:\n",
        "            if entity in model_info['entities']:\n",
        "                f1 = model_info['entities'][entity]['f1']\n",
        "                if f1 > 0.7:  # Good performance threshold\n",
        "                    strengths.append(f\"{entity}({f1:.2f})\")\n",
        "\n",
        "        if strengths:\n",
        "            print(f\"   • {model_name}: {', '.join(strengths)}\")\n",
        "        else:\n",
        "            print(f\"   • {model_name}: No entities above 0.7 F1\")\n",
        "\n",
        "# -------------------------\n",
        "# 4) Create Static Visualizations\n",
        "# -------------------------\n",
        "def create_static_visualizations(models_data, overall_df, entity_df):\n",
        "    \"\"\"Create comprehensive static visualizations\"\"\"\n",
        "\n",
        "    if not models_data:\n",
        "        return\n",
        "\n",
        "    # Set style\n",
        "    plt.style.use('seaborn-v0_8')\n",
        "    sns.set_palette(\"husl\")\n",
        "\n",
        "    # Create figure with subplots\n",
        "    fig = plt.figure(figsize=(20, 16))\n",
        "\n",
        "    # 1. Overall Performance Comparison\n",
        "    ax1 = plt.subplot(3, 3, 1)\n",
        "    models = [info['name'] for info in models_data.values()]\n",
        "    f1_scores = [info['overall']['f1'] for info in models_data.values()]\n",
        "    precision_scores = [info['overall']['precision'] for info in models_data.values()]\n",
        "    recall_scores = [info['overall']['recall'] for info in models_data.values()]\n",
        "    colors = [info['color'] for info in models_data.values()]\n",
        "\n",
        "    x = np.arange(len(models))\n",
        "    width = 0.25\n",
        "\n",
        "    bars1 = ax1.bar(x - width, f1_scores, width, label='F1-Score', alpha=0.8)\n",
        "    bars2 = ax1.bar(x, precision_scores, width, label='Precision', alpha=0.8)\n",
        "    bars3 = ax1.bar(x + width, recall_scores, width, label='Recall', alpha=0.8)\n",
        "\n",
        "    ax1.set_xlabel('Models')\n",
        "    ax1.set_ylabel('Score')\n",
        "    ax1.set_title('Overall Performance Metrics', fontweight='bold')\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(models, rotation=15)\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Add value labels\n",
        "    for bars in [bars1, bars2, bars3]:\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
        "                    f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "    # 2. Entity-Level F1 Comparison Heatmap\n",
        "    ax2 = plt.subplot(3, 3, 2)\n",
        "    entities = [\"DATE\", \"HOSPITAL\", \"ID\", \"LOCATION\", \"NAME\", \"PHONE\"]\n",
        "    entity_matrix = []\n",
        "\n",
        "    for model_name, model_info in models_data.items():\n",
        "        row = []\n",
        "        for entity in entities:\n",
        "            if entity in model_info['entities']:\n",
        "                row.append(model_info['entities'][entity]['f1'])\n",
        "            else:\n",
        "                row.append(0.0)\n",
        "        entity_matrix.append(row)\n",
        "\n",
        "    entity_matrix = np.array(entity_matrix)\n",
        "    im = ax2.imshow(entity_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
        "\n",
        "    ax2.set_xticks(np.arange(len(entities)))\n",
        "    ax2.set_yticks(np.arange(len(models)))\n",
        "    ax2.set_xticklabels(entities, rotation=45)\n",
        "    ax2.set_yticklabels(models)\n",
        "    ax2.set_title('Entity-Level F1 Scores Heatmap', fontweight='bold')\n",
        "\n",
        "    # Add text annotations\n",
        "    for i in range(len(models)):\n",
        "        for j in range(len(entities)):\n",
        "            text = ax2.text(j, i, f'{entity_matrix[i, j]:.2f}',\n",
        "                           ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')\n",
        "\n",
        "    plt.colorbar(im, ax=ax2, fraction=0.046, pad=0.04)\n",
        "\n",
        "    # 3. Model Parameter Comparison\n",
        "    ax3 = plt.subplot(3, 3, 3)\n",
        "    params = [355 if '355M' in info['parameters'] else 110 for info in models_data.values()]\n",
        "    bars = ax3.bar(models, params, color=colors, alpha=0.7)\n",
        "    ax3.set_ylabel('Parameters (Millions)')\n",
        "    ax3.set_title('Model Size Comparison', fontweight='bold')\n",
        "    ax3.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    for bar, param in zip(bars, params):\n",
        "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\n",
        "                f'{param}M', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "    # 4. Precision vs Recall Scatter\n",
        "    ax4 = plt.subplot(3, 3, 4)\n",
        "    scatter = ax4.scatter(precision_scores, recall_scores, s=150, c=colors, alpha=0.7)\n",
        "\n",
        "    for i, model in enumerate(models):\n",
        "        ax4.annotate(model, (precision_scores[i], recall_scores[i]),\n",
        "                    xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
        "\n",
        "    ax4.set_xlabel('Precision')\n",
        "    ax4.set_ylabel('Recall')\n",
        "    ax4.set_title('Precision vs Recall Trade-off', fontweight='bold')\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "\n",
        "    # Add diagonal lines for F1 contours\n",
        "    x_line = np.linspace(0, 1, 100)\n",
        "    for f1_line in [0.6, 0.7, 0.8, 0.9]:\n",
        "        y_line = (f1_line * x_line) / (2 * x_line - f1_line)\n",
        "        y_line = np.where(y_line > 0, y_line, np.nan)\n",
        "        ax4.plot(x_line, y_line, '--', alpha=0.3, label=f'F1={f1_line}')\n",
        "\n",
        "    # 5. Entity Performance Radar Chart\n",
        "    ax5 = plt.subplot(3, 3, 5, projection='polar')\n",
        "\n",
        "    angles = np.linspace(0, 2 * np.pi, len(entities), endpoint=False).tolist()\n",
        "    angles += angles[:1]  # Complete the circle\n",
        "\n",
        "    for model_name, model_info in models_data.items():\n",
        "        values = []\n",
        "        for entity in entities:\n",
        "            if entity in model_info['entities']:\n",
        "                values.append(model_info['entities'][entity]['f1'])\n",
        "            else:\n",
        "                values.append(0.0)\n",
        "        values += values[:1]  # Complete the circle\n",
        "\n",
        "        ax5.plot(angles, values, 'o-', linewidth=2, label=model_name, color=model_info['color'])\n",
        "        ax5.fill(angles, values, alpha=0.25, color=model_info['color'])\n",
        "\n",
        "    ax5.set_xticks(angles[:-1])\n",
        "    ax5.set_xticklabels(entities)\n",
        "    ax5.set_ylim(0, 1)\n",
        "    ax5.set_title('Entity Performance Radar Chart', fontweight='bold', pad=20)\n",
        "    ax5.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
        "\n",
        "    # 6. Error Analysis (TP, FP, FN)\n",
        "    ax6 = plt.subplot(3, 3, 6)\n",
        "    tp_values = [info['details']['tp'] for info in models_data.values()]\n",
        "    fp_values = [info['details']['fp'] for info in models_data.values()]\n",
        "    fn_values = [info['details']['fn'] for info in models_data.values()]\n",
        "\n",
        "    x = np.arange(len(models))\n",
        "    width = 0.25\n",
        "\n",
        "    ax6.bar(x - width, tp_values, width, label='True Positives', color='green', alpha=0.7)\n",
        "    ax6.bar(x, fp_values, width, label='False Positives', color='red', alpha=0.7)\n",
        "    ax6.bar(x + width, fn_values, width, label='False Negatives', color='orange', alpha=0.7)\n",
        "\n",
        "    ax6.set_xlabel('Models')\n",
        "    ax6.set_ylabel('Count')\n",
        "    ax6.set_title('Error Analysis (TP/FP/FN)', fontweight='bold')\n",
        "    ax6.set_xticks(x)\n",
        "    ax6.set_xticklabels(models, rotation=15)\n",
        "    ax6.legend()\n",
        "\n",
        "    # 7. F1 Score Distribution by Entity\n",
        "    ax7 = plt.subplot(3, 3, 7)\n",
        "    entity_f1_data = []\n",
        "    entity_labels = []\n",
        "\n",
        "    for entity in entities:\n",
        "        for model_name, model_info in models_data.items():\n",
        "            if entity in model_info['entities']:\n",
        "                entity_f1_data.append(model_info['entities'][entity]['f1'])\n",
        "                entity_labels.append(f\"{entity}\\n{model_name}\")\n",
        "\n",
        "    if entity_f1_data:\n",
        "        ax7.boxplot([entity_f1_data], labels=['All Entities'])\n",
        "        ax7.set_ylabel('F1-Score')\n",
        "        ax7.set_title('F1-Score Distribution', fontweight='bold')\n",
        "        ax7.grid(True, alpha=0.3)\n",
        "\n",
        "    # 8. Model Efficiency (F1 per Parameter)\n",
        "    ax8 = plt.subplot(3, 3, 8)\n",
        "    efficiency_scores = []\n",
        "    for info in models_data.values():\n",
        "        param_count = 355 if '355M' in info['parameters'] else 110\n",
        "        efficiency = info['overall']['f1'] / param_count * 1000  # F1 per million parameters * 1000\n",
        "        efficiency_scores.append(efficiency)\n",
        "\n",
        "    bars = ax8.bar(models, efficiency_scores, color=colors, alpha=0.7)\n",
        "    ax8.set_ylabel('F1-Score per Million Parameters (×1000)')\n",
        "    ax8.set_title('Model Efficiency', fontweight='bold')\n",
        "    ax8.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    for bar, eff in zip(bars, efficiency_scores):\n",
        "        ax8.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
        "                f'{eff:.2f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "    # 9. Summary Statistics Table\n",
        "    ax9 = plt.subplot(3, 3, 9)\n",
        "    ax9.axis('tight')\n",
        "    ax9.axis('off')\n",
        "\n",
        "    summary_data = []\n",
        "    for model_name, model_info in models_data.items():\n",
        "        summary_data.append([\n",
        "            model_name,\n",
        "            f\"{model_info['overall']['f1']:.3f}\",\n",
        "            f\"{model_info['overall']['precision']:.3f}\",\n",
        "            f\"{model_info['overall']['recall']:.3f}\",\n",
        "            model_info['parameters']\n",
        "        ])\n",
        "\n",
        "    table = ax9.table(cellText=summary_data,\n",
        "                     colLabels=['Model', 'F1', 'Precision', 'Recall', 'Parameters'],\n",
        "                     cellLoc='center',\n",
        "                     loc='center')\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(10)\n",
        "    table.scale(1.2, 1.5)\n",
        "    ax9.set_title('Summary Statistics', fontweight='bold', pad=20)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('comprehensive_model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"✅ Static visualizations saved as 'comprehensive_model_comparison.png'\")\n",
        "\n",
        "# -------------------------\n",
        "# 5) Create Interactive Visualizations\n",
        "# -------------------------\n",
        "def create_interactive_visualizations(models_data, overall_df, entity_df):\n",
        "    \"\"\"Create interactive Plotly visualizations\"\"\"\n",
        "\n",
        "    if not models_data:\n",
        "        return\n",
        "\n",
        "    # 1. Interactive Overall Performance Comparison\n",
        "    fig1 = go.Figure()\n",
        "\n",
        "    models = [info['name'] for info in models_data.values()]\n",
        "    colors = [info['color'] for info in models_data.values()]\n",
        "\n",
        "    # F1 Scores\n",
        "    fig1.add_trace(go.Bar(\n",
        "        name='F1-Score',\n",
        "        x=models,\n",
        "        y=[info['overall']['f1'] for info in models_data.values()],\n",
        "        marker_color=colors,\n",
        "        text=[f\"{info['overall']['f1']:.3f}\" for info in models_data.values()],\n",
        "        textposition='auto',\n",
        "    ))\n",
        "\n",
        "    fig1.update_layout(\n",
        "        title='Interactive Overall Performance Comparison',\n",
        "        xaxis_title='Models',\n",
        "        yaxis_title='F1-Score',\n",
        "        showlegend=False,\n",
        "        template='plotly_white'\n",
        "    )\n",
        "\n",
        "    fig1.show()\n",
        "\n",
        "    # 2. Interactive Entity-Level Heatmap\n",
        "    entities = [\"DATE\", \"HOSPITAL\", \"ID\", \"LOCATION\", \"NAME\", \"PHONE\"]\n",
        "    z_data = []\n",
        "    y_labels = []\n",
        "\n",
        "    for model_name, model_info in models_data.items():\n",
        "        row = []\n",
        "        for entity in entities:\n",
        "            if entity in model_info['entities']:\n",
        "                row.append(model_info['entities'][entity]['f1'])\n",
        "            else:\n",
        "                row.append(0.0)\n",
        "        z_data.append(row)\n",
        "        y_labels.append(model_name)\n",
        "\n",
        "    fig2 = go.Figure(data=go.Heatmap(\n",
        "        z=z_data,\n",
        "        x=entities,\n",
        "        y=y_labels,\n",
        "        colorscale='RdYlGn',\n",
        "        zmin=0,\n",
        "        zmax=1,\n",
        "        text=[[f'{val:.3f}' for val in row] for row in z_data],\n",
        "        texttemplate=\"%{text}\",\n",
        "        textfont={\"size\": 12},\n",
        "        hoverongaps=False\n",
        "    ))\n",
        "\n",
        "    fig2.update_layout(\n",
        "        title='Interactive Entity-Level F1 Scores Heatmap',\n",
        "        xaxis_title='Entity Types',\n",
        "        yaxis_title='Models',\n",
        "        template='plotly_white'\n",
        "    )\n",
        "\n",
        "    fig2.show()\n",
        "\n",
        "    # 3. Interactive 3D Performance Visualization\n",
        "    fig3 = go.Figure(data=go.Scatter3d(\n",
        "        x=[info['overall']['precision'] for info in models_data.values()],\n",
        "        y=[info['overall']['recall'] for info in models_data.values()],\n",
        "        z=[info['overall']['f1'] for info in models_data.values()],\n",
        "        mode='markers+text',\n",
        "        marker=dict(\n",
        "            size=12,\n",
        "            color=[info['color'] for info in models_data.values()],\n",
        "        ),\n",
        "        text=models,\n",
        "        textposition=\"top center\"\n",
        "    ))\n",
        "\n",
        "    fig3.update_layout(\n",
        "        title='3D Performance Space (Precision, Recall, F1)',\n",
        "        scene=dict(\n",
        "            xaxis_title='Precision',\n",
        "            yaxis_title='Recall',\n",
        "            zaxis_title='F1-Score'\n",
        "        ),\n",
        "        template='plotly_white'\n",
        "    )\n",
        "\n",
        "    fig3.show()\n",
        "\n",
        "    print(\"✅ Interactive visualizations displayed\")\n",
        "\n",
        "# -------------------------\n",
        "# 6) Generate Detailed Report\n",
        "# -------------------------\n",
        "def generate_detailed_report(models_data, overall_df, entity_df):\n",
        "    \"\"\"Generate comprehensive text report\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"📋 COMPREHENSIVE PHI DETECTION MODEL COMPARISON REPORT\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    if not models_data:\n",
        "        print(\"❌ No model data available for analysis\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n🔬 MODELS ANALYZED: {len(models_data)}\")\n",
        "    for model_name, model_info in models_data.items():\n",
        "        print(f\"   • {model_info['name']}: {model_info['type']} ({model_info['parameters']})\")\n",
        "\n",
        "    print(f\"\\n📊 OVERALL PERFORMANCE SUMMARY:\")\n",
        "    print(overall_df.round(4).to_string(index=False))\n",
        "\n",
        "    # Best performing model\n",
        "    best_f1_idx = overall_df['F1-Score'].idxmax()\n",
        "    best_model = overall_df.iloc[best_f1_idx]\n",
        "\n",
        "    print(f\"\\n🏆 BEST OVERALL PERFORMER:\")\n",
        "    print(f\"   Model: {best_model['Model']}\")\n",
        "    print(f\"   F1-Score: {best_model['F1-Score']:.4f}\")\n",
        "    print(f\"   Precision: {best_model['Precision']:.4f}\")\n",
        "    print(f\"   Recall: {best_model['Recall']:.4f}\")\n",
        "    print(f\"   Parameters: {best_model['Parameters']}\")\n",
        "\n",
        "    # Entity-level analysis\n",
        "    print(f\"\\n🎯 ENTITY-LEVEL PERFORMANCE ANALYSIS:\")\n",
        "    entities = [\"DATE\", \"HOSPITAL\", \"ID\", \"LOCATION\", \"NAME\", \"PHONE\"]\n",
        "\n",
        "    for entity in entities:\n",
        "        print(f\"\\n   {entity} Entity:\")\n",
        "        entity_scores = []\n",
        "        for model_name, model_info in models_data.items():\n",
        "            if entity in model_info['entities']:\n",
        "                f1 = model_info['entities'][entity]['f1']\n",
        "                entity_scores.append((model_name, f1))\n",
        "\n",
        "        entity_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "        for i, (model, f1) in enumerate(entity_scores, 1):\n",
        "            print(f\"      {i}. {model:15s}: {f1:.3f}\")\n",
        "\n",
        "    # Model strengths and weaknesses\n",
        "    print(f\"\\n💪 MODEL STRENGTHS AND WEAKNESSES:\")\n",
        "    for model_name, model_info in models_data.items():\n",
        "        print(f\"\\n   {model_name}:\")\n",
        "        print(f\"      Domain: {model_info['domain']}\")\n",
        "        print(f\"      Overall F1: {model_info['overall']['f1']:.4f}\")\n",
        "\n",
        "        # Find best and worst entities\n",
        "        entity_performance = []\n",
        "        for entity in entities:\n",
        "            if entity in model_info['entities']:\n",
        "                entity_performance.append((entity, model_info['entities'][entity]['f1']))\n",
        "\n",
        "        entity_performance.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        if entity_performance:\n",
        "            best_entities = [e for e, f1 in entity_performance if f1 >= 0.7]\n",
        "            weak_entities = [e for e, f1 in entity_performance if f1 < 0.5]\n",
        "\n",
        "            if best_entities:\n",
        "                print(f\"      Strengths: {', '.join(best_entities)}\")\n",
        "            if weak_entities:\n",
        "                print(f\"      Weaknesses: {', '.join(weak_entities)}\")\n",
        "\n",
        "    # Recommendations\n",
        "    print(f\"\\n🎯 RECOMMENDATIONS:\")\n",
        "\n",
        "    if len(models_data) >= 2:\n",
        "        # Find most efficient model\n",
        "        efficiency_scores = []\n",
        "        for model_name, model_info in models_data.items():\n",
        "            param_count = 355 if '355M' in model_info['parameters'] else 110\n",
        "            efficiency = model_info['overall']['f1'] / param_count\n",
        "            efficiency_scores.append((model_name, efficiency, model_info['overall']['f1']))\n",
        "\n",
        "        efficiency_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "        most_efficient = efficiency_scores[0]\n",
        "\n",
        "        print(f\"   • Most Efficient: {most_efficient[0]} (F1: {most_efficient[2]:.4f})\")\n",
        "        print(f\"   • Best Overall: {best_model['Model']} (F1: {best_model['F1-Score']:.4f})\")\n",
        "\n",
        "        if best_model['Parameters'] == '355M':\n",
        "            print(f\"   • For resource-constrained environments, consider smaller models\")\n",
        "\n",
        "        print(f\"   • For production deployment, consider ensemble of top 2 models\")\n",
        "\n",
        "    print(f\"\\n✅ Report generation completed!\")\n",
        "\n",
        "# -------------------------\n",
        "# 7) Main Execution Function\n",
        "# -------------------------\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "\n",
        "    # Load all model results\n",
        "    models_data = load_all_model_results()\n",
        "\n",
        "    if not models_data:\n",
        "        print(\"❌ No model results found. Please ensure evaluation files exist:\")\n",
        "        print(\"   • evaluation_results.json (ClinicalBERT)\")\n",
        "        print(\"   • biobert_evaluation_results.json (BioBERT)\")\n",
        "        print(\"   • roberta_large_evaluation_results.json (RoBERTa-Large)\")\n",
        "        return\n",
        "\n",
        "    # Create comparison DataFrames\n",
        "    overall_df, entity_df = create_comparison_dataframes(models_data)\n",
        "\n",
        "    # Perform statistical analysis\n",
        "    perform_statistical_analysis(models_data)\n",
        "\n",
        "    # Create visualizations\n",
        "    print(f\"\\n🎨 Creating comprehensive visualizations...\")\n",
        "    create_static_visualizations(models_data, overall_df, entity_df)\n",
        "\n",
        "    print(f\"\\n🎨 Creating interactive visualizations...\")\n",
        "    create_interactive_visualizations(models_data, overall_df, entity_df)\n",
        "\n",
        "    # Generate detailed report\n",
        "    generate_detailed_report(models_data, overall_df, entity_df)\n",
        "\n",
        "    # Save comparison data\n",
        "    if overall_df is not None:\n",
        "        overall_df.to_csv('model_comparison_overall.csv', index=False)\n",
        "        print(f\"✅ Overall comparison saved to 'model_comparison_overall.csv'\")\n",
        "\n",
        "    if entity_df is not None:\n",
        "        entity_df.to_csv('model_comparison_entities.csv', index=False)\n",
        "        print(f\"✅ Entity comparison saved to 'model_comparison_entities.csv'\")\n",
        "\n",
        "    print(f\"\\n🎉 Comprehensive model comparison completed!\")\n",
        "    print(f\"📁 Files generated:\")\n",
        "    print(f\"   • comprehensive_model_comparison.png\")\n",
        "    print(f\"   • model_comparison_overall.csv\")\n",
        "    print(f\"   • model_comparison_entities.csv\")\n",
        "\n",
        "# Execute the comparison\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "0Lfo4kpHMs3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0wXnbVWuMtJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d5-QfNI7MuGt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}